{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inhaltsverzeichnis\n",
    "\n",
    "* [1. Business Understanding](#chapter1)\n",
    "    * [1.1. Projektbeschreibung](#section_1_1)\n",
    "    * [1.2. Data Dictionary des \"train\"- Datensatz](#section_1_2)\n",
    "* [2. Data Understanding](#chapter2)\n",
    "    * [2.1. Pakete importieren](#section_2_1)\n",
    "    * [2.2. Daten einlesen](#section_2_2)\n",
    "    * [2.3. Datensatz anzeigen](#section_2_3)\n",
    "    * [2.4. Spaltennamen und Datentypen](#section_2_4)\n",
    "    * [2.5. Datentypen anpassen](#section_2_5)\n",
    "        * [2.5.1 Variable Age](#section_2_5_1)\n",
    "        * [2.5.2 Variablen Driving_License, Previously_Insured und Vehicle_Damage](#section_2_5_2)\n",
    "        * [2.5.3 Variable Gender](#section_2_5_3)\n",
    "        * [2.5.4 Variable Region Code](#section_2_5_4)\n",
    "        * [2.5.5 Variable Vehicle_Age](#section_2_5_5)\n",
    "        * [2.5.6 Variable Policy_Sales_Channel](#section_2_5_6)\n",
    "        * [2.5.7 Variable Vintage](#section_2_5_7)\n",
    "        * [2.5.8 Variable Unnamed: 0](#section_2_5_8)\n",
    "        * [2.5.9 Angepasste Datentypen anzeigen](#section_2_5_9)\n",
    "    * [2.6. Deskriptive Analyse](#section_2_6)\n",
    "        * [2.6.1 Kennzahlen zur Beschreibung des Datensatz](#section_2_6_1)\n",
    "        * [2.6.2 Prüfung auf Missing Values](#section_2_6_2)\n",
    "    * [2.7. Korrelation der Variablen](#section_2_7)\n",
    "    * [2.8. Interpretation der Variablen](#section_2_8)\n",
    "        * [2.8.1 Interpretation der Variable Gender](#section_2_8_1)\n",
    "        * [2.8.2 Interpretation der Variable Age](#section_2_8_2)\n",
    "        * [2.8.3 Interpretation der Variable Driving_License](#section_2_8_3)\n",
    "        * [2.8.4 Interpretation der Variable Region_Code](#section_2_8_4)\n",
    "        * [2.8.5 Interpretation der Variable Previously_Insured](#section_2_8_5)\n",
    "        * [2.8.6 Interpretation der Variable Vehicle_Age](#section_2_8_6)\n",
    "        * [2.8.7 Interpretation der Variable Vehicle_Damage](#section_2_8_7)\n",
    "        * [2.8.8 Interpretation der Variable Annual_Premium](#section_2_8_8)\n",
    "        * [2.8.9 Interpretation der Variable Policy_Sales_Channel](#section_2_8_9)\n",
    "        * [2.8.10 Interpretation der Variable Vintage](#section_2_8_10)\n",
    "        * [2.8.11 Interpretation der Variable Response](#section_2_8_11)\n",
    "* [3. Data Preparation](#chapter3)\n",
    "    * [3.1. Ausreißer behandeln](#section_3_1)\n",
    "        * [3.1.1 Ausreißer innerhalb der Variable Age](#section_3_1_1)\n",
    "        * [3.1.2 Ausreißer innerhalb der Variable Annual_Premium](#section_3_1_2)\n",
    "    * [3.2. Analyse der nicht vorhandenen Werte](#section_3_2)\n",
    "        * [3.2.1 Löschen der 51 fehlerhaften Datensätze](#section_3_2_1)\n",
    "    * [3.3. Train/Test-Split](#section_3_3)\n",
    "    * [3.4. Imputation der fehlenden Werte](#section_3_4)\n",
    "        * [3.4.1 Ersetzung der fehlenden Werte numerischer Variablen](#section_3_4_1)\n",
    "            * [3.4.1.1 Imputation der Variable Age](#section_3_4_1_1)\n",
    "            * [3.4.1.2 Imputation der Variable Annual_Premium](#section_3_4_1_2)\n",
    "        * [3.4.2 Ersetzung der fehlenden Werte kategorialer Variablen](#section_3_4_2)\n",
    "            * [3.4.2.1 Imputation der Variable Gender](#section_3_4_2_1)\n",
    "        * [3.4.3 Überprüfung der Imputationen](#section_3_4_3)\n",
    "    * [3.5. Sampling](#section_3_5)\n",
    "        * [3.5.1. Undersampling](#section_3_5_1)\n",
    "        * [3.5.2. Oversampling](#section_3_5_2)\n",
    "        * [3.5.3. Cleanup](#section_3_5_3)\n",
    "        * [3.5.4. Under- vs. Oversampling](#section_3_5_4)\n",
    "    * [3.6. Feature Engineering](#section_3_6)\n",
    "        * [3.6.1. Altersklassen als Feature](#section_3_6_1)\n",
    "        * [3.6.2. Features durch Aggregationen, Differenzen und Verhältnisse](#section_3_6_2)\n",
    "        * [3.6.3. One-Hot-Encoding für kategoriale Variablen](#section_3_6_3)\n",
    "    * [3.7. Feature Selection](#section_3_7)\n",
    "        * [3.7.1 Feature Selection anhand von Korrelation](#section_3_7_1)\n",
    "        * [3.7.2 Feature Selection nach Feature Importance](#section_3_7_2)\n",
    "* [4. Modeling](#chapter4)\n",
    "    * [4.1. Modell: Random Forest mit Hyperparametertuning](#section_4_1)\n",
    "    * [4.2. Modell: Neuronales Netz mit Hyperparametertuning](#section_4_2)\n",
    "    * [4.3. Modell: Gradient Boosting mit Hyperparametertuning](#section_4_3)\n",
    "* [5. Evaluation](#chapter5)\n",
    "    * [5.1 Bestes Modell](#section_5_1)\n",
    "* [6. Anwendung](#chapter6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Business Understanding <a class=\"anchor\" id=\"chapter1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Projektbeschreibung <a class=\"anchor\" id=\"section_1_1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das Forschungsteam *ProInsurance* wird damit beauftragt, dass Projekt Cross-Selling-Prediction für den Kunden *NextGen Insurance* durchzuführen. \n",
    "Der Kunde benötigt Hilfe bei der Erstellung eines Modells, mit dem sich vorhersagen lässt, ob die Versicherungsnehmer des letzten Jahres auch an einer angebotenen Kfz-Versicherung interessiert sein werden.\n",
    "Der Kunde wünscht die Durchführung des Projektes innerhalb eines knapp kalkulierten Zeitraums.\n",
    "\n",
    "Zu diesem Zweck erhält das Forschungsteam von ihrem Auftraggeber einen Datenbestand bestehend aus > 350.000 Datensätzen. Zusätzlich ein Data Dictionary, welches eine kurze Beschreibung der Daten liefert.\n",
    "\n",
    "Die *NextGen Insurance* hat mehrere Forschungsteams beauftragt an einer Lösung zu arbeiten, damit Sie sich nach Ende der Präsentationen für die beste Alternative entscheiden können."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Data Dictionary des \"train\"- Datensatz <a class=\"anchor\" id=\"section_1_2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unser Auftraggeber die *NextGen Insurance* stellt uns folgendes Data Dictionary und damit verbunden folgende Beschreibungen der einzelnen Variablen zur Verfügung:\n",
    "\n",
    "| **Variable**          | **Definition**  | \n",
    "|          :-           |         :-        |\n",
    "| id                    |Unique ID for the customer| \n",
    "| gender                |Gender of the customer| \n",
    "| age                   |Age of the customer| \n",
    "| driving_license       |0 : Customer doesn't have DL, 1 : Customer has DL| \n",
    "| region_code           |Unique code for the region of the customer| \n",
    "| previously_insured    |0 : Customer doesn't have Vehicle Insurance, 1 : Customer has Vehicle Insurance| \n",
    "| vehicle_age           |Age of the Vehicle| \n",
    "| vehicle_damage        |1 : Customer got his/her vehicle damaged in the past. 0 : Customer didn't get his/her vehicle damaged in the past.| \n",
    "| annual_premium        |The amount customer needs to pay as premium in the year for Health insurance| \n",
    "| policy_sales_channel  |Anonymized Code for the channel of outreaching to the customer ie. Different Agents, Over Mail, Over Phone, In Person, etc.| \n",
    "| vintage               |Number of Days customer has been associated with the company| \n",
    "| response              |1 : Customer is interested, 0 : Customer is not interested| \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Understanding <a class=\"anchor\" id=\"chapter2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Pakete importieren <a class=\"anchor\" id=\"section_2_1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas.api.types import CategoricalDtype\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Sklearn Packages\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import PrecisionRecallDisplay\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Undersamling / Oversampling\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Daten einlesen <a class=\"anchor\" id=\"section_2_2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der Datensatz wurde von der *NextGen Insurance* bereitgestellt.\n",
    "\n",
    "Der Datensatz \"train_dataset\" wird zur Analyse eingelesen:\n",
    "- Entfernung des Trennzeichen \"$\".\n",
    "- Umwandlung von Zelleninhalten in Wahrheitswerte (Yes, yes, 1; No, no, 0).\n",
    "- Einrücken des Datensatzes.\n",
    "\n",
    "Der Datensatz \"real_dataset\" wird zur Analyse eingelesen:\n",
    "- Entfernung der Trennzeichen \"$\" und \",\".\n",
    "- Umwandlung von Zelleninhalten in Wahrheitswerte (Yes, yes, 1; No, no, 0).\n",
    "- Einrücken des Datensatzes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read train.csv\n",
    "train_dataset = pd.read_csv(\n",
    "    \"train.csv\",\n",
    "    sep=\"$\",\n",
    "    true_values=[\"Yes\", \"yes\", \"1\"],\n",
    "    false_values=[\"No\", \"no\", \"0\"],\n",
    "    index_col=False,\n",
    "    low_memory=False,\n",
    ")\n",
    "\n",
    "#Read test.csv\n",
    "real_dataset = pd.read_csv(\n",
    "    \"test.csv\",\n",
    "    sep=\"\\$|,\",  # this csv uses 2 different separators\n",
    "    true_values=[\"Yes\", \"yes\", \"1\"],\n",
    "    false_values=[\"No\", \"no\", \"0\"],\n",
    "    index_col=False,\n",
    "    engine=\"python\"  # c engine does not support regex or multiple separators\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Datensatz Anzeigen <a class=\"anchor\" id=\"section_2_3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zur Betrachtung der Variablen aus dem Datensatz werden die ersten zwanzig Einträge angezeigt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_dataset.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Spaltennamen und Datentypen <a class=\"anchor\" id=\"section_2_4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um eventuelle Korrekturen vorzunehmen betrachten wir die Datentypen der im Datensatz enthaltenen Variablen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Die Spalten `Driving_License`, `Previously_Insured`, und `Vehicle_Damage` wurden nicht in den booleschen Datentypen gecastet. Dies ist ein Indikator dafür das diese Spalten invalide oder fehlende Werte enthalten.\n",
    "- Die Spalte `Age` wurde nicht in einen Integer oder Float gecastet, auch hier ist dies ein Indikator dafür, dass diese Spalte invalide oder fehlende Werte enthält. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_dataset = real_dataset.drop(columns=[\"id\"])\n",
    "real_dataset = real_dataset.rename(columns={\"Vehicle__Damage\": \"Vehicle_Damage\", \"Annual__Premium\": \"Annual_Premium\"})\n",
    "real_dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Datentypen anpassen <a class=\"anchor\" id=\"section_2_5\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Die zum Pandas Modul zugehörige Funktion \"**.unique()**\" ermöglicht die Ausgabe aller einzigartigen Werte. Dies erleichtert das Nachvollziehen von Eingabefehlern um diese zu korrigieren.\n",
    "- Der Numpy-Datentyp `int64` unterstützt keine nullable Values (NaN), deshalb wird der Pandas-Datentyp `Int64` verwendet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5.1 Variable Age <a class=\"anchor\" id=\"section_2_5_1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset[\"Age\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aus dieser Ausgabe kann man sehen, dass einige fehlerhaften Eingaben getätigt wurden (z.B. \"29..\"). Da die Werte dieser Datensätze aber inhaltlich richtig sein könnten, sollen sie behalten werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to string\n",
    "train_dataset[\"Age\"] = train_dataset[\"Age\"].astype(pd.StringDtype())\n",
    "\n",
    "# remove .. as this is what prevents us from propper type conversion\n",
    "train_dataset[\"Age\"] = train_dataset[\"Age\"].str.replace(\".\", \"\")\n",
    "\n",
    "# convert to int (no decimals observed in train data)\n",
    "train_dataset[\"Age\"] = train_dataset[\"Age\"].astype(\"Int64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Durch das Casten in den String-Datentyp können die fehlerhaften Sonderzeichen (..) entfernt werden. Anschließend wird die Variable in den gewünschten Integer-Datentypen gecastet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5.2 Variablen Driving_License, Previously_Insured und Vehicle_Damage <a class=\"anchor\" id=\"section_2_5_2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset\n",
    "print(\"Driving_License:\", train_dataset[\"Driving_License\"].unique())\n",
    "\n",
    "print(\"Previously_Insured:\", train_dataset[\"Previously_Insured\"].unique())\n",
    "\n",
    "print(\"Vehicle_Damage:\", train_dataset[\"Vehicle_Damage\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Ausgabe weist darauf hin, dass diese Variablen richtig einglesen werden konnten und es keine (inhaltlich) falschen Ausprägungen gibt. \n",
    "- Es gibt nur `True`, `False` und Missing Values(NaN).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert each column\n",
    "# no cleanup required\n",
    "# train_dataset\n",
    "train_dataset[\"Driving_License\"] = train_dataset[\"Driving_License\"].astype(pd.BooleanDtype())\n",
    "\n",
    "train_dataset[\"Previously_Insured\"] = train_dataset[\"Previously_Insured\"].astype(pd.BooleanDtype())\n",
    "    \n",
    "train_dataset[\"Vehicle_Damage\"] = train_dataset[\"Vehicle_Damage\"].astype(pd.BooleanDtype())\n",
    "\n",
    "###\n",
    "\n",
    "# real_dataset\n",
    "real_dataset[\"Driving_License\"] = real_dataset[\"Driving_License\"].astype(pd.BooleanDtype())\n",
    "\n",
    "real_dataset[\"Previously_Insured\"] = real_dataset[\"Previously_Insured\"].astype(pd.BooleanDtype())\n",
    "\n",
    "real_dataset[\"Vehicle_Damage\"] = real_dataset[\"Vehicle_Damage\"].astype(pd.BooleanDtype())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anschließend wird die Variable in den gewünschten Boolean-Datentyp gecastet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5.3 Variable Gender <a class=\"anchor\" id=\"section_2_5_3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset[\"Gender\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Ausgabe weist darauf hin, dass diese Variablen richtig einglesen werden konnten und es keine (inhaltlich) falschen Ausprägungen gibt. \n",
    "- Es gibt nur die zwei Kategorien `Male`, `Female` und Missing Values(NaN).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no cleanup required\n",
    "# train_dataset\n",
    "train_dataset[\"Gender\"] = train_dataset[\"Gender\"].astype(pd.CategoricalDtype())\n",
    "\n",
    "###\n",
    "\n",
    "# real_dataset\n",
    "real_dataset[\"Gender\"] = real_dataset[\"Gender\"].astype(pd.CategoricalDtype())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anschließend wird die Variable in den gewünschten Category-Datentyp gecastet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5.4 Variable Region Code <a class=\"anchor\" id=\"section_2_5_4\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset[\"Region_Code\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aus dieser Ausgabe kann man sehen, dass eine fehlerhafte Eingabe getätigt wurde (\"41.0##\"). Da dieser Wert des Datensatz aber inhaltlich richtig sein könnte, soll dieser behalten werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to string\n",
    "train_dataset[\"Region_Code\"] = train_dataset[\"Region_Code\"].astype(pd.StringDtype())\n",
    "\n",
    "# remove ## as this is what prevents us from propper type conversion\n",
    "train_dataset[\"Region_Code\"] = train_dataset[\"Region_Code\"].str.replace(\"#\", \"\")\n",
    "\n",
    "# convert to category as the region codes are similar to postal codes and have no order\n",
    "train_dataset[\"Region_Code\"] = train_dataset[\"Region_Code\"].astype(pd.CategoricalDtype())\n",
    "\n",
    "###\n",
    "\n",
    "# real_dataset\n",
    "real_dataset[\"Region_Code\"] = real_dataset[\"Region_Code\"].astype(pd.CategoricalDtype())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Durch das Casten in den String-Datentyp kann das fehlerhafte Sonderzeichen (##) entfernt werden. Anschließend wird die Variable in den gewünschten Category-Datentypen gecastet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5.5 Variable Vehicle_Age <a class=\"anchor\" id=\"section_2_5_5\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset[\"Vehicle_Age\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Ausgabe weist darauf hin, dass diese Variablen richtig einglesen werden konnten und es keine (inhaltlich) falschen Ausprägungen gibt. \n",
    "- Es gibt nur die drei Kategorien `> 2 Years`, `1-2 Year`, `< 1 Year` und Missing Values(NaN).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no cleanup required\n",
    "# train_dataset\n",
    "train_dataset[\"Vehicle_Age\"] = train_dataset[\"Vehicle_Age\"].astype(pd.CategoricalDtype())\n",
    "\n",
    "###\n",
    "\n",
    "# real_dataset\n",
    "real_dataset[\"Vehicle_Age\"] = real_dataset[\"Vehicle_Age\"].astype(pd.CategoricalDtype())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anschließend wird die Variable in den gewünschten Category-Datentyp gecastet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5.6 Variable Policy_Sales_Channel <a class=\"anchor\" id=\"section_2_5_6\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset[\"Policy_Sales_Channel\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aus dieser Ausgabe kann man sehen, dass eine fehlerhafte Eingabe getätigt wurde (\"26.0##\"). Da dieser Wert des Datensatz aber inhaltlich richtig sein könnte, soll dieser behalten werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to string\n",
    "train_dataset[\"Policy_Sales_Channel\"] = train_dataset[\"Policy_Sales_Channel\"].astype(pd.StringDtype())\n",
    "\n",
    "# remove ## as this is what prevents us from propper type conversion\n",
    "train_dataset[\"Policy_Sales_Channel\"] = train_dataset[\"Policy_Sales_Channel\"].str.replace(\"#\", \"\")\n",
    "\n",
    "# convert to category as the Policy Sales Channels is a anonymized Code for the channel of outreaching to the customer\n",
    "train_dataset[\"Policy_Sales_Channel\"] = train_dataset[\"Policy_Sales_Channel\"].astype(pd.CategoricalDtype())\n",
    "\n",
    "###\n",
    "\n",
    "# real_dataset\n",
    "real_dataset[\"Policy_Sales_Channel\"] = real_dataset[\"Policy_Sales_Channel\"].astype(pd.CategoricalDtype())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Durch das Casten in den String-Datentyp kann das fehlerhafte Sonderzeichen (##) entfernt werden. Anschließend wird die Variable in den gewünschten Category-Datentypen gecastet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5.7 Variable Vintage <a class=\"anchor\" id=\"section_2_5_7\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset[\"Vintage\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aus dieser Ausgabe kann man sehen, dass eine fehlerhafte Eingabe getätigt wurde (\"81##\"). Da dieser Wert des Datensatz aber inhaltlich richtig sein könnte, soll dieser behalten werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to string\n",
    "train_dataset[\"Vintage\"] = train_dataset[\"Vintage\"].astype(pd.StringDtype())\n",
    "\n",
    "# remove ## as this is what prevents us from propper type conversion\n",
    "train_dataset[\"Vintage\"] = train_dataset[\"Vintage\"].str.replace(\"#\", \"\")\n",
    "\n",
    "# convert to int (no decimals observed in train data)\n",
    "train_dataset[\"Vintage\"] = train_dataset[\"Vintage\"].astype(\"Int64\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Durch das Casten in den String-Datentyp können die fehlerhaften Sonderzeichen (##) entfernt werden. Anschließend wird die Variable in den gewünschten Integer-Datentypen gecastet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5.8 Variable Unnamed: 0 <a class=\"anchor\" id=\"section_2_5_8\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.drop(\"Unnamed: 0\", axis=\"columns\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diese Spalte beinhaltet keine Informationen und wird aus dem \"train_dataset\" Datensatz entfernt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5.9 Angepasste Datentypen anzeigen <a class=\"anchor\" id=\"section_2_5_9\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 Deskriptive Analyse <a class=\"anchor\" id=\"section_2_6\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6.1 Kennzahlen zur Beschreibung des Datensatz <a class=\"anchor\" id=\"section_2_6_1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Folgende statistische Kennzahlen werden verwenden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.describe(include=\"all\").transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auffälligkeiten einzelner Variablen anhand der statistischen Kennzahlen werden im nachfolgenden näher erläutert:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| **Variable**          | **Beschreibung**  | \n",
    "|          :-           |         :-        |\n",
    "| id                    |- Beginnt bei 1 und endet bei 380.999 <br> - weißt keine Auffälligkeiten auf| \n",
    "| Gender                |- Das Geschlecht \"Male\" kommt am häufigsten vor mit 205.447 Datensätzen <br> - 2 verschiedene Ausprägungen <br> - 1051 Datensätze fehlen (Vergleich von 379.948 zu 380.999 Datensätzen) | \n",
    "| Age                   |- min. = 20 Jahre alt nicht auffällig <br> - Im Durchschnitt 39 Jahre alt <br> - max. = 205 Jahre alt <br> - 10.892 Datensätze fehlen (Vergleich von 370.107 zu 380.999 Datensätzen) | \n",
    "| Driving_License       |- Mehr Personen haben keinen Führerschein mit 206.635 Datensätzen als das Sie einen Führerschein haben <br> - 2 verschiedene Ausprägungen <br> - 51 Datensätze fehlen (Vergleich von 380.948 zu 380.999 Datensätzen) | \n",
    "| Region_Code           |- Die PLZ 28.0 kommt am häufigsten vor mit 106.372 Datensätzen <br> - 53 verschiedene Ausprägungen | \n",
    "| Previously_Insured    |- Mehr Personen haben keine Versicherung mit 206.635 Datensätzen als das Sie eine Versicherung haben <br> - 2 verschiedene Ausprägungen <br> - 51 Datensätze fehlen (Vergleich von 380.948 zu 380.999 Datensätzen) | \n",
    "| Vehicle_Age           |- Das Alter des Fahrzeugs beläuft sich auf bei den meisten Personen auf 1-2 Jahre mit 380.948 Datensätzen <br> - 3 verschiedene Ausprägungen <br> - 51 Datensätze fehlen (Vergleich von 380.948 zu 380.999 Datensätzen) | \n",
    "| Vehicle_Damage        |- Bei mehr Personen, 192.328 Datensätze, ist es zu einem Schadensfall gekommen <br> - 2 verschiedene Ausprägungen <br> - 51 Datensätze fehlen (Vergleich von 380.948 zu 380.999 Datensätzen) | \n",
    "| Annual_Premium        |- min. = -9997.0€ auffällig, da der Betrag den die Kunden zahlen müssen nicht negativ sein kann. <br> - Im Durchschnitt 30.527.71€ <br> - max. = 540.165€ auffällig, da der Betrag deutlich zu hoch ist | \n",
    "| Policy_Sales_Channel  |- 155 verschiedene Ausprägungen | \n",
    "| Vintage               |- min. = 10 Tage <br> - Im Durchschnitt 154 Tage <br> - max. = 299 Tage <br> - 51 Datensätze fehlen (Vergleich von 380.948 zu 380.999 Datensätzen) | \n",
    "| Response              |- Mehr Personen sind nicht interessiert mit 334.297\tDatensätzen <br> - 2 verschiedene Ausprägungen | \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6.2 Prüfung auf Missing Values <a class=\"anchor\" id=\"section_2_6_2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die zum Pandas Modul zugehörige Funktion \"**.isna()**\" ermöglicht die Ausgabe aller Missing Values(NaN) und die Funktion \"**.sum()**\" summiert die Missing Values der einzelnen Spalten auf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Überprüfung auf Missing Values zeigt, dass vor allem für die Variable `Age` Werte imputiert werden sollten. In der Spalte `Gender` fehlen rund 1000 Werte. Weiter sieht man, dass in den Spalten `Driving_License`, `Previously_Insured`, `Vehicle_Age`, `Vehicle_Damage` und `Vintage` genau 51 Werte fehlen. Das deutet darauf hin, dass diese Missing Values zu den selben Datensätzen gehören, was nachfolgend überprüft wird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NaN_in_selected_columns = train_dataset.loc[\n",
    "                  train_dataset[\"Vintage\"].isna()\n",
    "                & train_dataset[\"Vehicle_Damage\"].isna()\n",
    "                & train_dataset[\"Vehicle_Age\"].isna()\n",
    "                & train_dataset[\"Previously_Insured\"].isna()\n",
    "                & train_dataset[\"Driving_License\"].isna()\n",
    "]\n",
    "\n",
    "print(f\"Datensätze mit Vintage, Vehicle_Damage, Vehicle_Age, Previously_Insured und Driving_License fehlen: {len(NaN_in_selected_columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mithilfe einer Und(&)-Verbindung wird geprüft, ob die Missing Values alle von den selben Datensätzen stammen.\n",
    "Die Annahme wurde bestätigt. Der Test ergab 51 Treffer.\n",
    "Da nur wenige Informationen zu diesen Datensätzen verfügbar sind und eine Imputation daher nur eingeschränkt möglich ist, werden die Datensätze im Verlauf der Data Preparation entfernt. Hierdurch wird die Modellgüte nicht ausschlaggebend beeinträchtigt, da 51 Datensätze in der Gesamtheit der Daten (>350.000 Datensätze) keinen signifikanten Einfluss haben.<br>\n",
    "<br>\n",
    "Nachfolgend wurde überprüft, woher diese fehlerhaften Datensätze kommen. Unter verdacht standen die Vertriebskanäle `Policy_Sales_Channel` und `Region_Code` was auf fehlerhafte Eingaben in einer speziellen Filiale zurückzuführen wäre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cast Region_Code to Category using only the options that appear in the data frame\n",
    "NaN_in_selected_columns[\"Region_Code\"] = NaN_in_selected_columns[\"Region_Code\"].astype(\n",
    "    pd.CategoricalDtype(NaN_in_selected_columns[\"Region_Code\"].unique())\n",
    ")\n",
    "\n",
    "sns.catplot(\n",
    "    data=NaN_in_selected_columns, x=\"Region_Code\", kind=\"count\", height=10, aspect=2 / 1\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NaN_in_selected_columns_grpd = NaN_in_selected_columns.groupby(\"Policy_Sales_Channel\").count()\n",
    "\n",
    "NaN_in_selected_columns_grpd = NaN_in_selected_columns_grpd.loc[NaN_in_selected_columns_grpd[\"id\"] > 0]\n",
    "\n",
    "# reset index to re-include groupby counts (this resets all dtypes)\n",
    "NaN_in_selected_columns_grpd = NaN_in_selected_columns_grpd.reset_index()\n",
    "\n",
    "# reset PSC to categorial dtype\n",
    "NaN_in_selected_columns_grpd[\"Policy_Sales_Channel\"] = NaN_in_selected_columns_grpd[\"Policy_Sales_Channel\"].astype(\n",
    "    pd.CategoricalDtype(NaN_in_selected_columns_grpd[\"Policy_Sales_Channel\"].unique())\n",
    ")\n",
    "\n",
    "sns.catplot(\n",
    "    data=NaN_in_selected_columns_grpd,\n",
    "    x=\"Policy_Sales_Channel\",\n",
    "    y=\"id\",\n",
    "    height=10,\n",
    "    aspect=2 / 1,\n",
    "    kind=\"bar\",\n",
    ");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es gibt zwar Hinweise darauf, dass manche Regionen und Sales Channel fehleranfälliger sind als andere, der Verdacht, dass die fehlerhaften Datensätze auf eine Datenquelle zurückzuführen sind, konnte nicht bestätigt werden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.7 Korrelation der Variablen <a class=\"anchor\" id=\"section_2_7\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove id from correlation matrix as it does not provide any usefull information\n",
    "def correlation_matrix_table(train_dataset):\n",
    "    correlation = train_dataset.drop(columns=[\"id\"]).corr()\n",
    "    return correlation\n",
    "\n",
    "\n",
    "correlation_matrix_table(train_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation_matrix_plot(train_dataset, x, y, show_labels, col_map, method=\"\"):\n",
    "    correlation = train_dataset.corr(method=method)\n",
    "    plt.figure(figsize=(x, y))\n",
    "    sns.heatmap(\n",
    "        correlation, annot=show_labels, linewidths=1, linecolor=\"black\", cmap=col_map, vmin=-1, vmax=1\n",
    "    )\n",
    "    plt.title(f\"Korrelationsmatrix ({method})\", fontsize=18, weight=\"bold\")\n",
    "\n",
    "\n",
    "correlation_matrix_plot(train_dataset, 12, 6, True, \"seismic\", \"pearson\")\n",
    "correlation_matrix_plot(train_dataset, 12, 6, True, \"seismic\", \"spearman\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Es fällt auf, dass `Previously_Insured` und `Driving_License` die höchste Korrelation, undzwar von 1, aufweisen. Das liegt daran, dass jeder KFZ-Besitzer eine KFZ-Versicherung haben muss sofern das KFZ angemeldet ist.\n",
    "- Die geringste Korrelation weisen die Variablen `Driving_License` und `Vintage`, sowie `Previously_Insured` und `Vintage` auf, mit einer Korrelation von 0,0024.\n",
    "- Hohe negative Korrelation zwischen `Vehicle_Damage` und `Previously_Insured`.\n",
    "- Korrelation von 0,35 zwischen `Vehicle_Damage` und `Response`. Wenn ich in der Vergangenheit einen Schadensfall hatte, bin ich eher dazu geneigt eine Versicherung abzuschließen.\n",
    "- Die Korrelationen von `Vintage` liege nahe an 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'In wie vielen Fällen ist Driving_License != Previously_Insured?\\n -> {len(train_dataset.loc[train_dataset[\"Driving_License\"] != train_dataset[\"Previously_Insured\"]])}')\n",
    "# Observation was confirmed!\n",
    "# Columns Driving_License and Previously_Insured are equals!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Beobachtungen**:\n",
    "- Die Spalten `Driving_License` und `Previously_Insured` beinhalten die gleichen Daten."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.8 Interpretation der Variablen <a class=\"anchor\" id=\"section_2_8\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.8.1 Interpretation der Variable Gender <a class=\"anchor\" id=\"section_2_8_1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Variable `Gender` beschreibt das Geschlecht der Kunden. Diese ist eine kategoriale Variable mit den zwei Ausprägungen `Male` und `Female`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 14))\n",
    "colors = sns.color_palette('pastel')[0:2]\n",
    "l = [\"Response: True\", \"Response: False\"]\n",
    "fig.suptitle(\"Kreisdiagramm der Variable Gender in Zusammenhang mit Response\", fontsize=20, weight=\"bold\")\n",
    "plt.subplots_adjust(top=1.32)\n",
    "\n",
    "\n",
    "# MALE PIE CHART\n",
    "male = train_dataset.loc[train_dataset[\"Gender\"] == \"Male\"]\n",
    "d_m = [len(male.loc[male[\"Response\"] == True]),\n",
    "       len(male.loc[male[\"Response\"] == False])]\n",
    "ax1.pie(d_m, labels=l, colors=colors, autopct='%.0f%%')\n",
    "ax1.set_title(\"Male Responses\", weight=\"bold\", fontsize=14)\n",
    "\n",
    "# FEMALE PIE CHART\n",
    "female = train_dataset.loc[train_dataset[\"Gender\"] == \"Female\"]\n",
    "d_f = [len(female.loc[female[\"Response\"] == True]),\n",
    "       len(female.loc[female[\"Response\"] == False])]\n",
    "ax2.pie(d_f, labels=l, colors=colors, autopct='%.0f%%')\n",
    "ax2.set_title(\"Female Responses\", weight=\"bold\", fontsize=14); # \";\" prevents output in console"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Beobachtungen**:\n",
    "- Keine signifikanten unterschiede im Interesse an KFZ-Versicherungen bei Männern und Frauen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.8.2 Interpretation der Variable Age <a class=\"anchor\" id=\"section_2_8_2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Variable `Age` beschreibt das Alter der Kunden.\n",
    "\n",
    "Erwartungen:\n",
    "- Plotten der Altersverteilung gibt Rückschlüsse zur Datenqualität bzw. zur Datenherkunft\n",
    "    - Es ist eine pyramiedenförmige Altersverteilung zu erwarten, da der Datensatz aus Indien stammt\n",
    "- Ältere und damit erfahrenere Kunden sind eher an einer Versicherung interessiert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={\"figure.figsize\": (22, 10)})\n",
    "histplot_age = sns.histplot(train_dataset, x=\"Age\", binwidth=5)\n",
    "histplot_age.set_title(\"Histogram der Variable Age\", fontsize=30, weight='bold')\n",
    "histplot_age.set_xlabel(\"Age\", fontsize=20, weight='bold')\n",
    "histplot_age.set_ylabel(\"Count\", fontsize=20, weight='bold');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Beobachtungen:**\n",
    "- Aus der Fallbeschreibung konnte entnommen werden, dass es sich um einen Datensatz aus Indien handelt. Es wurde von der Währung Rs (Indische Rupie) gesprochen. Die Altersverteilung kommt der pyramidenförmigen demografischen Verteilung von Indien deutlich näher als der Urnenform von Deutschland. Die geplottete Altersverteilung bestätigt zusätzlich die Datenherkunft und Datengüte, da die erwartete Verteilung, bis auf einen Sattelpunkt zwischen 30 Jahre und 40 Jahre, ausgegeben wurde.\n",
    "- Es gibt keine Werte unter 20 Jahre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={\"figure.figsize\": (25, 10)})\n",
    "boxplot = sns.boxplot(data=train_dataset, y=\"Gender\", x=\"Age\", orient=\"horizontal\")\n",
    "boxplot.set_xlabel(\"Age\", fontsize=20, weight='bold')\n",
    "boxplot.set_ylabel(\"Gender\", fontsize=20, weight='bold')\n",
    "boxplot.set_title(\"Boxplot der Variable Age in Zusammenhang mit Gender\" +\n",
    "                  \"\\n\", fontsize=30, weight='bold')\n",
    "plt.tick_params(axis=\"both\", labelsize=18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Beobachtungen**:\n",
    "- Es gibt unrealistisch hohe Alterswerte.\n",
    "- Männer sind im Schnitt älter als Frauen<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Durchschnittsalter von Männern: {train_dataset.loc[train_dataset[\"Gender\"] == \"Male\"].mean().round()[\"Age\"]}')\n",
    "print(f'Durchschnittsalter von Frauen: {train_dataset.loc[train_dataset[\"Gender\"] == \"Female\"].mean().round()[\"Age\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alle Datensätze bei denen das Alter über 100 Jahren liegt, sind nicht realitätsnah und werden genauer betrachtet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.loc[(train_dataset.Age >= 100)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Daten mit unrealistisch hohen Alterswerten sind möglicherweise alte Datensätze, die nicht gepflegt bzw. im Fall der Vertragsauflösung nicht gelöscht wurden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.8.3 Interpretation der Variable Driving_License <a class=\"anchor\" id=\"section_2_8_3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Variable `Driving_License` beschreibt ob ein Kunde einen Führerschein besitzt.\n",
    "\n",
    "Erwartungen:\n",
    "- Kunden, die keinen Führerschein besitzen, haben keine Verwendung für eine KFZ-Versicherung\n",
    "    - Außer sie planen kurzfristig den Erwerb eines Führerscheins\n",
    "- Führerscheinbesitzer haben möglicherweise schon eine KFZ-Versicherung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 14))\n",
    "colors = sns.color_palette('pastel')[0:4]\n",
    "fig.suptitle(\"Kreisdiagramm der Variable Driving_License in Zusammenhang mit Response\", fontsize=20, weight=\"bold\")\n",
    "plt.subplots_adjust(top=1.32)\n",
    "\n",
    "dl_true = train_dataset.loc[train_dataset[\"Driving_License\"] == True]\n",
    "dl_false=train_dataset.loc[train_dataset[\"Driving_License\"] == False]\n",
    "\n",
    "# dl_true PIE CHART\n",
    "d_true = [len(dl_true.loc[dl_true[\"Response\"] == True]),\n",
    "       len(dl_true.loc[dl_true[\"Response\"] == False])]\n",
    "l_true = [\"Response: True\", \"Response: False\"]\n",
    "ax1.pie(d_true, labels=l_true, colors=colors, autopct='%.0f%%')\n",
    "ax1.set_title(\"Driving License Owner\", weight=\"bold\", fontsize=14)\n",
    "\n",
    "# dl_false PIE CHART\n",
    "d_false = [len(dl_false.loc[dl_false[\"Response\"] == True]),\n",
    "       len(dl_false.loc[dl_false[\"Response\"] == False])]\n",
    "l_false = l_true\n",
    "\n",
    "ax2.pie(d_false, labels=l_false, colors=colors, autopct='%.0f%%')\n",
    "ax2.set_title(\"Not Driving License Owner\", weight=\"bold\", fontsize=14);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Beobachtungen**:\n",
    "- Kein Führerscheinbesitzer ist an einer KFZ-Versicherung interessiert. Möglicherweise weil Führerscheinbesitzer ein Auto und deswegen auch eine KFZ-Versicherung besitzen.\n",
    "- 23% aller Führerscheinlosen haben Interesse an einer KFZ-Versicherung bekundet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.8.4 Interpretation der Variable Region_Code <a class=\"anchor\" id=\"section_2_8_4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Variable `Region_Code` beschreibt den Wohnort der Kunden. \n",
    "\n",
    "Erwartungen:\n",
    "- In einer guten Wohngegend können sich die Versicherungsnehmer eher eine KFZ-Versicherung leisten oder besitzen ein teureres Auto, für das sich eine Versicherung lohnt\n",
    "- Analog dazu verzichten Kunden aus ärmeren Regionen aus finanziellen Gründen eher auf eine KFZ-Versicherung\n",
    "- Bestimmte Verkaufskanäle konzentrieren sich auf bestimmte Regionen, andere agieren flächendeckend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_dataset[\"Region_Code\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_data = train_dataset.groupby(\"Region_Code\").count()\n",
    "\n",
    "p_data = p_data.loc[p_data[\"id\"] > 0]\n",
    "\n",
    "# reset index to re-include groupby counts (this resets all dtypes)\n",
    "p_data = p_data.reset_index()\n",
    "\n",
    "# reset PSC to categorial dtype\n",
    "p_data[\"Region_Code\"] = p_data[\"Region_Code\"].astype(\n",
    "    pd.CategoricalDtype(p_data[\"Region_Code\"].unique())\n",
    ")\n",
    "\n",
    "plot = sns.catplot(\n",
    "    data=p_data,\n",
    "    x=\"Region_Code\",\n",
    "    y=\"id\",\n",
    "    height=10,\n",
    "    aspect=2 / 1,\n",
    "    kind=\"bar\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bei dieser Variable handelt es sich um eine kategoriale Variable mit 53 Ausprägungen. Sie kann analog zur Postleitzahl verstanden werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={\"figure.figsize\": (22, 10)})\n",
    "countplot_region_code = sns.countplot(data=train_dataset, x=\"Region_Code\", hue=\"Response\") \n",
    "countplot_region_code.set_title(\"Balkendiagramm der Variable Region_Code in Zusammenhang mit Response\", fontsize=30, weight='bold')\n",
    "countplot_region_code.set_xlabel(\"Region_Code\", fontsize=20, weight='bold')\n",
    "countplot_region_code.set_ylabel(\"Count\", fontsize=20, weight='bold'); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Beobachtungen:**\n",
    "- Es fällt auf das die meisten Kunden aus dem Verkaufskanal 28.0 kommen und dementsprechend die Nachfrage nach einer KFZ-Versicherung am größten ist. Das könnte vielleicht daran liegen das es sich um eine gute Wohngegend handelt und sich die Versicherungsnehmer eher ein Fahrzeug und somit eine KFZ-Versicherung leisten können."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catplot_region_code = sns.catplot(data=train_dataset, x=\"Region_Code\", y=\"Annual_Premium\", jitter=False, height=10, aspect= 2/1)\n",
    "catplot_region_code.fig.subplots_adjust(top=0.93)\n",
    "catplot_region_code.fig.suptitle(\"Streudiagramm der Variable Region_Code in Zusammenhang mit Annual_Premium\", fontsize=30, weight='bold')\n",
    "catplot_region_code.set_xlabels(\"Region_Code\", fontsize=20, weight='bold')\n",
    "catplot_region_code.set_ylabels(\"Annual_Premium\", fontsize=20, weight='bold');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Beobachtungen:**\n",
    "- In einigen Verkaufskanälen ist die jährliche Zahlung an die Krankenversicherung unrealistisch hoch. Zudem haben einige Verkaufskanäle negative jährliche Zahlungen, was deutlich einen Fehler darstellt da die Versicherungsgesellschaft sonst den Kunden bezahlen würde.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.8.5 Interpretation der Variable Previously_Insured <a class=\"anchor\" id=\"section_2_8_5\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Variable `Previously_Insured` beschreibt ob ein Kunde eine KFZ-Versicherung besitzt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 14))\n",
    "colors = sns.color_palette('pastel')[0:2]\n",
    "l = [\"Driving_License: True\", \"Driving_License: False\"]\n",
    "fig.suptitle(\"Kreisdiagramm der Variable Previously_Insured in Zusammenhang mit Driving_License\", fontsize=20, weight=\"bold\")\n",
    "plt.subplots_adjust(top=1.32)\n",
    "\n",
    "d_1 = train_dataset.loc[train_dataset[\"Previously_Insured\"] == True]\n",
    "p_1 = [len(d_1.loc[d_1[\"Driving_License\"] == True]),\n",
    "       len(d_1.loc[d_1[\"Driving_License\"] == False])]\n",
    "ax1.pie(p_1, labels=l, colors=colors, autopct='%.0f%%', startangle = 45)\n",
    "ax1.set_title(\"Previously insured\", weight=\"bold\", fontsize=14)\n",
    "\n",
    "d_2 = train_dataset.loc[train_dataset[\"Previously_Insured\"] == False]\n",
    "p_2 = [len(d_2.loc[d_2[\"Driving_License\"] == True]),\n",
    "       len(d_2.loc[d_2[\"Driving_License\"] == False])]\n",
    "ax2.pie(p_2, labels=l, colors=colors, autopct='%.0f%%', startangle = 45)\n",
    "ax2.set_title(\"Not previously insured\", weight=\"bold\", fontsize=14);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Beobachtungen:**\n",
    "- Kunden die eine KFZ-Versicherung abgeschlossen haben besitzen einen Führerschein.\n",
    "- Kunden die keine KFZ-Versicherung abgeschlossen haben besitzen keinen Führerschein."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 14))\n",
    "colors = sns.color_palette('pastel')[0:2]\n",
    "l = [\"Response: True\", \"Response: False\"]\n",
    "fig.suptitle(\"Kreisdiagramm der Variable Previously_Insured in Zusammenhang mit Response\", fontsize=20, weight=\"bold\")\n",
    "plt.subplots_adjust(top=1.32)\n",
    "\n",
    "d_1 = train_dataset.loc[train_dataset[\"Previously_Insured\"] == True]\n",
    "p_1 = [len(d_1.loc[d_1[\"Response\"] == True]),\n",
    "       len(d_1.loc[d_1[\"Response\"] == False])]\n",
    "ax1.pie(p_1, labels=l, colors=colors, autopct='%.0f%%')\n",
    "ax1.set_title(\"Previously insured\", weight=\"bold\", fontsize=14)\n",
    "\n",
    "d_2 = train_dataset.loc[train_dataset[\"Previously_Insured\"] == False]\n",
    "p_2 = [len(d_2.loc[d_2[\"Response\"] == True]),\n",
    "       len(d_2.loc[d_2[\"Response\"] == False])]\n",
    "ax2.pie(p_2, labels=l, colors=colors, autopct='%.0f%%')\n",
    "ax2.set_title(\"Not previously insured\", weight=\"bold\", fontsize=14);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Beobachtungen:**\n",
    "- Kunden die eine KFZ-Versicherung haben, sind an keiner KFZ-Versicherung interessiert.\n",
    "- 77% der Kunden die keine KFZ-Versicherung haben sind auch an keiner KFZ-Versicherung interessiert. 23% der Kunden die keine KFZ-Versicherung haben sind an einer KFZ-Versicherung interessiert."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.8.6 Interpretation der Variable Vehicle_Age <a class=\"anchor\" id=\"section_2_8_6\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Variable `Vehicle_Age` beschreibt das Alter des Fahrzeugs. Diese ist eine kategoriale Variable mit den drei Ausprägungen `< 1 Year`, `1-2 Year` und `> 2 Years`.\n",
    "\n",
    "Erwartungen:\n",
    "- Besitzer neuer KFZs wollen ihre Neuanschaffung eher versichern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catplot_region_code = sns.catplot(data=train_dataset, x=\"Vehicle_Age\", kind=\"count\", height=10, aspect= 2/1)\n",
    "catplot_region_code.fig.subplots_adjust(top=0.93)\n",
    "catplot_region_code.fig.suptitle(\"Balkendiagramm der Variable Vehicle_Age\", fontsize=30, weight='bold')\n",
    "catplot_region_code.set_xlabels(\"Vehicle_Age\", fontsize=20, weight='bold')\n",
    "catplot_region_code.set_ylabels(\"Count\", fontsize=20, weight='bold');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Beobachtungen:**\n",
    "- Kunden die ein Fahrzeug besitzen das 1-2 Jahre Alt ist, sind am häufigsten vorhanden mit ca. 200.000 Datensätzen. Fahrzeuge die unter einem Jahr alt sind, sind ebenfalls häufig vorhanden mit ca. 165.000 Datensätzen. Fahrzeuge die über 2 Jahre alt sind, sind nicht sehr häufig vorhanden mit ca. 20.000 Datensätzen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catplot_region_code = sns.catplot(data=train_dataset, x=\"Vehicle_Age\", y=\"Annual_Premium\", jitter=False, height=10, aspect= 2/1)\n",
    "catplot_region_code.fig.subplots_adjust(top=0.93)\n",
    "catplot_region_code.fig.suptitle(\"Streudiagramm der Variable Vehicle_Age in Zusammenhang mit Annual_Premium\", fontsize=30, weight='bold')\n",
    "catplot_region_code.set_xlabels(\"Vehicle_Age\", fontsize=20, weight='bold')\n",
    "catplot_region_code.set_ylabels(\"Annual_Premium\", fontsize=20, weight='bold');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Beobachtungen:**\n",
    "- Kunden deren Fahrzeuge 1-2 Jahre alt und unter einem Jahr sind haben die höchsten zu zahlenden jährlichen Beträge an die Krankenversicherung. Dies könnte auf einen Fehler hindeuten, da die Beträge für die Krankenversicherung deutlich zu hoch ausfallen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Durchschnittszahlungen an die Krankenversicherung wenn das Auto <1 Jahr alt ist: {train_dataset.loc[train_dataset[\"Vehicle_Age\"] == \"< 1 Year\"].mean().round(2)[\"Annual_Premium\"]} Rupien')\n",
    "print(f'Durchschnittszahlungen an die Krankenversicherung wenn das Auto 1-2 Jahre alt ist: {train_dataset.loc[train_dataset[\"Vehicle_Age\"] == \"1-2 Year\"].mean().round(2)[\"Annual_Premium\"]} Rupien')\n",
    "print(f'Durchschnittszahlungen an die Krankenversicherung wenn das Auto mehr als 2 Jahre alt ist: {train_dataset.loc[train_dataset[\"Vehicle_Age\"] == \"> 2 Years\"].mean().round(2)[\"Annual_Premium\"]} Rupien')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(20, 10))\n",
    "colors = sns.color_palette('pastel')[0:2]\n",
    "fig.suptitle(\"Kreisdiagramm der Variable Vehicle_Age in Zusammenhang mit Response\", fontsize=20, weight=\"bold\")\n",
    "plt.subplots_adjust(top=1.2)\n",
    "\n",
    "dl_1 = train_dataset.loc[train_dataset[\"Vehicle_Age\"] == \"< 1 Year\"]\n",
    "dl_2 = train_dataset.loc[train_dataset[\"Vehicle_Age\"] == \"1-2 Year\"]\n",
    "dl_3 = train_dataset.loc[train_dataset[\"Vehicle_Age\"] == \"> 2 Years\"]\n",
    "\n",
    "l = [\"Response: True\", \"Response: False\"]\n",
    "# dl_1 PIE CHART\n",
    "d_1 = [len(dl_1.loc[dl_1[\"Response\"] == True]),\n",
    "       len(dl_1.loc[dl_1[\"Response\"] == False])]\n",
    "ax1.pie(d_1, labels=l, colors=colors, autopct='%.0f%%')\n",
    "ax1.set_title(\"Vehicle_Age < 1 Year\", weight=\"bold\", fontsize=14)\n",
    "\n",
    "# dl_2 PIE CHART\n",
    "d_2 = [len(dl_2.loc[dl_2[\"Response\"] == True]),\n",
    "       len(dl_2.loc[dl_2[\"Response\"] == False])]\n",
    "ax2.pie(d_2, labels=l, colors=colors, autopct='%.0f%%')\n",
    "ax2.set_title(\"Vehicle_Age 1-2 Year\", weight=\"bold\", fontsize=14)\n",
    "\n",
    "# dl_3 PIE CHART\n",
    "d_3 = [len(dl_3.loc[dl_3[\"Response\"] == True]),\n",
    "       len(dl_3.loc[dl_3[\"Response\"] == False])]\n",
    "ax3.pie(d_3, labels=l, colors=colors, autopct='%.0f%%')\n",
    "ax3.set_title(\"Vehicle_Age > 2 Years\", weight=\"bold\", fontsize=14);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Beobachtungen:**\n",
    "- Je Älter das Auto, desto interessierter sind die Kunden an einer KFZ-Versicherung. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.8.7 Interpretation der Variable Vehicle_Damage <a class=\"anchor\" id=\"section_2_8_7\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Variable `Vehicle_Damage` beschreibt, ob es an einem Fahrzeug schonmal einen Schadensfall gab.\n",
    "\n",
    "Erwartung:\n",
    "- Jemand, der bereits einen Schaden hatte, hat aus der Erfahrung gelernt, dass es Vorteilhaft sein kann eine Versicherung zu haben\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 14))\n",
    "colors = sns.color_palette('pastel')[0:2]\n",
    "fig.suptitle(\"Kreisdiagramm der Variable Vehicle_Damage in Zusammenhang mit Response\", fontsize=20, weight=\"bold\")\n",
    "plt.subplots_adjust(top=1.32)\n",
    "\n",
    "dl_1 = train_dataset.loc[train_dataset[\"Vehicle_Damage\"] ==True]\n",
    "dl_2 = train_dataset.loc[train_dataset[\"Vehicle_Damage\"] == False]\n",
    "\n",
    "l = [\"Response: True\", \"Response: False\"]\n",
    "# dl_1 PIE CHART\n",
    "d_1 = [len(dl_1.loc[dl_1[\"Response\"] == True]),\n",
    "       len(dl_1.loc[dl_1[\"Response\"] == False])]\n",
    "ax1.pie(d_1, labels=l, colors=colors, autopct='%.0f%%')\n",
    "ax1.set_title(\"Vehicle_Damage: True\", weight=\"bold\", fontsize=14)\n",
    "\n",
    "# dl_2 PIE CHART\n",
    "d_2 = [len(dl_2.loc[dl_2[\"Response\"] == True]),\n",
    "       len(dl_2.loc[dl_2[\"Response\"] == False])]\n",
    "ax2.pie(d_2, labels=l, colors=colors, autopct='%.0f%%')\n",
    "ax2.set_title(\"Vehicle_Damage: False\", weight=\"bold\", fontsize=14);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Beobachtungen:**\n",
    "- Es sind 24% an einer KFZ-Versicherung interessiert die bereits einen Schadensfall erlitten haben. \n",
    "- 1% sind an einer KFZ-Versicherung interessiert die bisher keinen Schadensfall erlitten haben.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.8.8 Interpretation der Variable Annual_Premium <a class=\"anchor\" id=\"section_2_8_8\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Variable `Annual_Premium` beschreibt die Höhe des jährlichen Versicherungsbeitrag der Krankenversicherung des Kunden.\n",
    "\n",
    "Erwartungen:\n",
    "- Ein Kunde, der mit seiner Krankenversicherung zufrieden ist, etwa weil der Beitrag niedrig ist, ist eher verleitet, bei der selben Versicherung ein weiteres Produkt zu kaufen\n",
    "- Das `Annual_Premium` ist abhängig vom Alter des Versicherten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset[\"Annual_Premium\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Der durchschnittliche `Annual_Premium` liegt bei rund 30.500 Rupien.\n",
    "- Das Minimun ist negativ, was auf mindestens einen fehlerhaften Wert hindeutet.\n",
    "- Das Maximum liegt bei ca. 540.000 Rupien, was auf einen Fehler hindeuten könnte. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={\"figure.figsize\": (22, 10)})\n",
    "histplot_annual_premium = sns.histplot(train_dataset, x=\"Annual_Premium\", binwidth=2500)\n",
    "histplot_annual_premium.set_title(\"Histogram der Variable Annual_Premium\", fontsize=30, weight='bold')\n",
    "histplot_age.set_xlabel(\"Age\", fontsize=20, weight='bold')\n",
    "histplot_age.set_ylabel(\"Count\", fontsize=20, weight='bold');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Anzahl der Datensätze bei ca. 2500 Rupien : {len(train_dataset.loc[(train_dataset['Annual_Premium'] >= 0) & (train_dataset['Annual_Premium'] < 3000)])} Datensätze\")\n",
    "print(f\"Anzahl der Datensätze zwischen 3000 Rupien und 100.000 Rupien: {len(train_dataset.loc[(train_dataset['Annual_Premium'] >= 3000) & (train_dataset['Annual_Premium'] < 100000)])} Datensätze\")\n",
    "print(f\"Anzahl der Datensätze ab 100.000 Rupien: {len(train_dataset.loc[train_dataset['Annual_Premium'] >= 100000])} Datensätze\")\n",
    "print(f\"Anzahl der Datensätze negativer Beträge: {len(train_dataset.loc[train_dataset['Annual_Premium'] < 0])} Datensätze\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={\"figure.figsize\": (22, 10)})\n",
    "relplot = sns.relplot(data=train_dataset, x=\"Age\", y=\"Annual_Premium\",\n",
    "                col=\"Response\", hue=\"Vehicle_Age\")\n",
    "relplot.fig.subplots_adjust(top=0.8)\n",
    "relplot.fig.suptitle(\"Streudiagramm der Variable Annual_Premium in Zusammenhang mit Age, Vehicle_Age und Response\", fontsize=16, weight='bold')\n",
    "relplot.set_xlabels(\"Age\", fontsize=12, weight='bold')\n",
    "relplot.set_ylabels(\"Annual_Premium\", fontsize=12, weight='bold');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Beobachtungen:**\n",
    "- Kunden die kein Interesse an einer KFZ-Versicherung haben zahlen höhere jährliche Beträge an die Krankenkasse.\n",
    "- Jüngere Kunden haben überwiegend ein Fahrzeug das unter einem Jahr alt ist.\n",
    "- Kunden zwischen 50 Jahren und 80 Jahren haben Fahrzeuge die über 2 Jahre alt sind.\n",
    "- Kunden deren Fahrzeug zwischen 1-2 Jahre alt sind, sind in allen Altersgruppen verteilt.\n",
    "- Mehr Kunden sind nicht an einer KFZ-Versicherung interessiert. Zudem lässt sich erkennen das die Kunden dazu geneigt sind eine KFZ-Versicherung abzuschließen wenn der jährlich zu zahlende Betrag an die Krankenversicherung nicht so hoch ist. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={\"figure.figsize\": (20, 10)})\n",
    "\n",
    "isolate_annual_premium = train_dataset.loc[(train_dataset[\"Annual_Premium\"] > 0) &\n",
    "                      (train_dataset[\"Annual_Premium\"] < 70000)]\n",
    "\n",
    "histplot_annual_premium = sns.histplot(isolate_annual_premium, x=\"Annual_Premium\", binwidth=1000)\n",
    "histplot_annual_premium.set_title(\"Betrachtung des realistischen Datenbereichs der Variable Annual_Premium\", fontsize=30, weight='bold');\n",
    "histplot_annual_premium.set_xlabel(\"Annual_Premium\", fontsize=20, weight='bold')\n",
    "histplot_annual_premium.set_ylabel(\"Count\", fontsize=20, weight='bold');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beobachtungen:\n",
    "- rechtsschiefe Verteilung um 30.000 Rupien.\n",
    "- Ausreißer bei rund 2.000 Rupien. Das ist möglicherweise ein besonderer Versicherungstarif, z.B. ein pauschaler Tarif."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={\"figure.figsize\": (30, 10)})\n",
    "boxplot = sns.boxplot(data=train_dataset, y=\"Gender\",\n",
    "                      x=\"Annual_Premium\", orient=\"horizontal\")\n",
    "boxplot.set_xlabel(\"Annual_Premium\", fontsize=20, weight='bold')\n",
    "boxplot.set_ylabel(\"Gender\", fontsize=20, weight='bold')\n",
    "\n",
    "boxplot.set_xlim(0, 550000)\n",
    "boxplot.set_xticks(range(0, 550000, 25000))\n",
    "\n",
    "boxplot.set_title(\"Boxplot der Variable Annual_Premium in Zusammenhang mit Gender.\" +\n",
    "                  \"\\n\", fontsize=30, weight='bold')\n",
    "plt.tick_params(axis=\"both\", labelsize=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Durchschnittszahlungen an die Krankenversicherung von Männern: {train_dataset.loc[train_dataset[\"Gender\"] == \"Male\"].mean().round(2)[\"Annual_Premium\"]} Rupien')\n",
    "print(f'Durchschnittszahlungen an die Krankenversicherung von Frauen: {train_dataset.loc[train_dataset[\"Gender\"] == \"Female\"].mean().round()[\"Annual_Premium\"]} Rupien')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Beobachtungen**:\n",
    "- Es gibt unrealistisch hohe jährliche Zahlungen an die Krankenversicherung. Zudem bei den Frauen unrealistisch niedrige Zahlungen.\n",
    "- Männer und Frauen zahlen im Schnitt gleiche jährliche Zahlungen an die Krankenversicherung."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.8.9 Interpretation der Variable Policy_Sales_Channel <a class=\"anchor\" id=\"section_2_8_9\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Variable `Policy_Sales_Channel` beschreibt den Verkaufskanal, über den die bestehende Krankenversicherung abgeschlossen wurde.\n",
    "\n",
    "Erwartungen:\n",
    "- Bei bestimmten Verkaufskanälen gibt es ein höheres Interesse an KFZ-Versicherungen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catplot_region_code = sns.catplot(x=\"Policy_Sales_Channel\",y=\"Response\", data=train_dataset, ci=None, aspect=4, kind=\"bar\")\n",
    "catplot_region_code.fig.subplots_adjust(top=0.88)\n",
    "catplot_region_code.fig.suptitle(\"Balkendiagramm der Variable Policy_Sales_Channel in Zusammenhang mit Response\", fontsize=30, weight='bold')\n",
    "catplot_region_code.set_xticklabels([]) # is categorical variable, no information to gain from labels\n",
    "catplot_region_code.set_xlabels(\"Policy_Sales_Channel\", fontsize=20, weight='bold')\n",
    "catplot_region_code.set_ylabels(\"Response in %\", fontsize=20, weight='bold');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Beobachtungen**:\n",
    "- Es gibt deutliche Unterschiede zwischen den Vertriebskanälen\n",
    "    - Allerdings haben Vertriebskanäle mit wenigen Kunden extremere Werte, da die Stichprobengröße kleiner ist\n",
    "\n",
    "Es müssen weitere Untersuchungen von prozentualer positiver Rückmeldung und Anzahl der Kunden für jeden Vertriebskanal vorgenommen werden.\n",
    "\n",
    "Nachfolgend werden die Daten pro Vertriebskanal zusammengefasst, um deren Positivrückmeldungsrate im Vergleich zur Anzahl der betreuten Kunden einordnen zu können."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get percentage of True response\n",
    "percent =  train_dataset.groupby(\"Policy_Sales_Channel\").sum() / train_dataset.groupby(\"Policy_Sales_Channel\").count()\n",
    "percent = percent.reset_index()\n",
    "percent[\"Policy_Sales_Channel\"] = percent[\"Policy_Sales_Channel\"].astype(pd.CategoricalDtype(percent[\"Policy_Sales_Channel\"].unique()))\n",
    "\n",
    "# get count of all response\n",
    "count = train_dataset.groupby(\"Policy_Sales_Channel\").count()\n",
    "count = count.reset_index()\n",
    "count[\"Policy_Sales_Channel\"] = count[\"Policy_Sales_Channel\"].astype(pd.CategoricalDtype(count[\"Policy_Sales_Channel\"].unique()))\n",
    "\n",
    "# join results\n",
    "combined = pd.merge(percent, count, how=\"inner\", on=[\"Policy_Sales_Channel\",\"Policy_Sales_Channel\"], suffixes=[\"_percent\", \"_count\"])\n",
    "combined = combined.sort_values(\"Response_percent\", ascending=False)\n",
    "\n",
    "# trim useless columns\n",
    "combined = combined[[\"Policy_Sales_Channel\", \"Response_percent\", \"Response_count\"]]\n",
    "\n",
    "no_positive_responses = combined.loc[combined[\"Response_percent\"] == 0]\n",
    "combined\n",
    "# remove sales channels with no customers\n",
    "combined = combined.loc[combined[\"Response_count\"] > 0]\n",
    "combined\n",
    "p = sns.regplot(x=\"Response_count\", y=\"Response_percent\" ,data=combined)\n",
    "p.set_xscale(\"log\")\n",
    "p.set_xlabel(\"Anzahl der Kunden (logarithmische Skala zur besseren Darstellung)\", size=20, weight=\"bold\")\n",
    "p.set_ylabel(\"Anteil der True Responses in %\", size=20, weight=\"bold\")\n",
    "p.set_title(\"Erfolgsquote und Anzahl der Kunden pro Vertriebskanal (1 Punkt je Kanal)\", size=30, weight=\"bold\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Anzahl der Vertriebskanäle ohne positive Response: {len(no_positive_responses)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Beobachtungen**:\n",
    "- Die Vertriebskanäle sind unabhängig von ihrer Größe mehr oder weniger erfolgreich\n",
    "- Es gibt große Abweichungen vom Mittelwert unabhängig von der Anzahl der Kunden\n",
    "- Wie erwartet haben die Vertriebskanäle mit 100% Positivrückmeldungsquote nur einen einzigen Kunden\n",
    "    - Dennoch gibt es auch Vertriebskanäle mit über 1000 Kunden und rund 33% Positivquote\n",
    "- Die meisten Vertriebskanäle haben weniger als 1000 Kunden\n",
    "- Es gibt 34 Vertriebskanäle ohne positive Rückmeldung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.8.10 Interpretation der Variable Vintage <a class=\"anchor\" id=\"section_2_8_10\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Variable `Vintage` beschreibt die Dauer des Versicherungsverhältnisses im letzten Jahr.\n",
    "\n",
    "Erwartung:\n",
    "- Besondere Salesevents oder Aktionen mit limitierter Laufzeit können als Peak erkannt werden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={\"figure.figsize\": (22, 10)})\n",
    "histplot = sns.histplot(data=train_dataset, x=\"Vintage\", binwidth=7)      # binwidth = 7 days = 1 week\n",
    "histplot.set_title(\"Histogram der Variable Vintage\", fontsize=30, weight='bold')\n",
    "histplot.set_xlabel(\"Vintage\", fontsize=20, weight='bold')\n",
    "histplot.set_ylabel(\"Count\", fontsize=20, weight='bold');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Beobachtungen**:\n",
    "- Beinahe Gleichverteilung von `Vintage`. Es scheinen keine Verkaufsaktionen stattgefunden zu haben, oder sie sind ohne Erfolg geblieben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at cheap contracts\n",
    "d = train_dataset.loc[(train_dataset[\"Annual_Premium\"] > 0) & (train_dataset[\"Annual_Premium\"] < 3000)]\n",
    "\n",
    "#d = d.loc[d[\"Response\"] == True]\n",
    "\n",
    "sns.set(rc={\"figure.figsize\": (22, 10)})\n",
    "scatterplot = sns.scatterplot(data=d, x=\"Vintage\", y=\"Annual_Premium\", hue=\"Response\")\n",
    "scatterplot.set_xlabel(\"Vintage\", fontsize=20, weight='bold')\n",
    "scatterplot.set_title(\"Scatterplot der günstigen Tarife im Zusammenhang mit Vintage\", fontsize=30, weight='bold')\n",
    "scatterplot.set_ylabel(\"Count\", fontsize=20, weight='bold');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Beobachtungen**:\n",
    "- Es gibt keine besonderen Zeiträume, in denen der günstige Pauschaltarif besonders häufg abgeschlossen wird\n",
    "- Es gibt keine besonderen Zeiträume, in denen die  `Response` besonders gut ist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.8.11 Interpretation der Variable Response <a class=\"anchor\" id=\"section_2_8_11\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Variable `Response` beschreibt das Interesse der Kunden an einer KFZ-Versicherung. Es ist die Zielvariable, die mithilfe eines Modells vorhergesagt werdern soll."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={\"figure.figsize\": (22, 10)})\n",
    "histplot = sns.histplot(data=train_dataset, x=\"Age\", binwidth=5, hue=\"Response\")\n",
    "histplot.set_title(\"Histogramm der Variable Response in Zusammenhang mit Age \", fontsize=30, weight='bold')\n",
    "histplot.set_xlabel(\"Age\", fontsize=20, weight='bold')\n",
    "histplot.set_ylabel(\"Count\", fontsize=20, weight='bold');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Beobachtung**:\n",
    "- Kunden im mittleren Alter (zwischen 30 Jahre und 60 Jahre) haben ein vergleichsweise höheres Interesse an einer Versicherung.\n",
    "- Ältere und jüngere Kunden haben ein überproportional geringes Interesse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(20, 10))\n",
    "colors = sns.color_palette('pastel')[0:2]\n",
    "fig.suptitle(\"Kreisdiagramm der Variable Response in Zusammenhang mit Age\", fontsize=20, weight=\"bold\")\n",
    "plt.subplots_adjust(top=1.2)\n",
    "\n",
    "d_1 = train_dataset.loc[train_dataset[\"Age\"] < 30]\n",
    "d_2 = train_dataset.loc[(train_dataset[\"Age\"] >= 30) & (train_dataset[\"Age\"] < 60)]\n",
    "d_3 = train_dataset.loc[(train_dataset[\"Age\"] >= 60) & (train_dataset[\"Age\"] < 100)] # remove false data\n",
    "\n",
    "l = [\"Response: True\", \"Response: False\"]\n",
    "\n",
    "p_1 = [len(d_1.loc[d_1[\"Response\"] == True]),\n",
    "       len(d_1.loc[d_1[\"Response\"] == False])]\n",
    "ax1.pie(p_1, labels=l, colors=colors, autopct='%.0f%%')\n",
    "ax1.set_title(\"Age: < 30\", weight=\"bold\", fontsize=14)\n",
    "\n",
    "p_2 = [len(d_2.loc[d_2[\"Response\"] == True]),\n",
    "       len(d_2.loc[d_2[\"Response\"] == False])]\n",
    "ax2.pie(p_2, labels=l, colors=colors, autopct='%.0f%%')\n",
    "ax2.set_title(\"Age: >=30 und < 60\", weight=\"bold\", fontsize=14)\n",
    "\n",
    "p_3 = [len(d_3.loc[d_3[\"Response\"] == True]),\n",
    "       len(d_3.loc[d_3[\"Response\"] == False])]\n",
    "ax3.pie(p_3, labels=l, colors=colors, autopct='%.0f%%')\n",
    "ax3.set_title(\"Age: >= 60\", weight=\"bold\", fontsize=14);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Beobachtung**:\n",
    "- Besonders in der Altersgruppe 30 Jahre bis 60 Jahre ist ein besonders großes Interesse an einer KFZ-Versicherung zu erkennen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Data Preparation <a class=\"anchor\" id=\"chapter3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Erkenntnisse, die im Kapitel **Data Understanding** gewonnen wurden, werden nachfolgend angewandt, um invalide Daten zu entfernen und die Datenqualität zu erhöhen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Ausreißer behandeln <a class=\"anchor\" id=\"section_3_1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.1 Ausreißer innerhalb der Variable Age <a class=\"anchor\" id=\"section_3_1_1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ab dem Alter >100 Jahre werden alle Werte in Missing Values umgewandelt, da dieses Alter nicht realitätsnah ist.\n",
    "- Diese Grenze wurde als großzügige Einschätzung des zu erwartenden Lebensalters festgelegt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Es sind {len(train_dataset.loc[train_dataset['Age']> 100])} Datensätze von dieser Änderung betroffen.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.loc[train_dataset[\"Age\"] > 100, \"Age\"] = np.NaN\n",
    "train_dataset.loc[train_dataset[\"Age\"] < 18, \"Age\"] = np.NaN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.2 Ausreißer innerhalb der Variable Annual_Premium <a class=\"anchor\" id=\"section_3_1_2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset[\"Annual_Premium\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Negative Werte für `Annual_Premium` sind nicht valide. Es würde bedeuten, dass die Versicherungsgesellschaft den Kunden bezahlt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Es sind {len(train_dataset.loc[train_dataset['Annual_Premium']< 0])} Datensätze von dieser Änderung betroffen.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove negative values\n",
    "train_dataset.loc[train_dataset[\"Annual_Premium\"] < 0, \"Annual_Premium\"] = np.NaN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Analyse der nicht vorhandenen Werte <a class=\"anchor\" id=\"section_3_2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1 Löschen der 51 fehlerhaften Datensätze <a class=\"anchor\" id=\"section_3_2_1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie im Abschnitt 2.6.2 beschrieben wurden 51 Datensätze in den Spalten `Driving_License`, `Previously_Insured`, `Vehicle_Age`, `Vehicle_Damage` und `Vintage` mit Missing Values gefunden, die zum selben Datensatz gehören. Da diese keinen signifikanten Einfluss auf das Modell haben werden, werden sie entfernt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove 51 data sets with missing values\n",
    "# NaN_in_selected_columns was generated before (in section 2.6.2) and contains 51 data sets that we want to remove\n",
    "train_dataset = train_dataset.loc[~train_dataset[\"id\"].isin(NaN_in_selected_columns[\"id\"].to_numpy())]  # ~ = not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Train/Test-Split <a class=\"anchor\" id=\"section_3_3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Für den Split unterteilen wir die Daten aus der \"train.csv\" in Trainingsdaten und Testdaten. Hier wird ein 70/30-Split genutzt.\n",
    "- Es wird eine Teilung in 70% Trainingsdaten und 30% Testdaten vorgenommen.\n",
    "- Der Algorithmus lernt aus den Trainingsdaten und dient zum Trainieren des Modells.\n",
    "- Die Testdaten sind unabhängig von den Trainingsdaten und werden beim Training des Modells nicht benutzt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Features\n",
    "X = train_dataset.copy(deep=True)\n",
    "X.drop(\"Response\", axis=\"columns\", inplace=True)\n",
    "X.drop(\"id\", axis=\"columns\", inplace=True)\n",
    "\n",
    "#labels (X_train = all columns except Response / y_train = only Response //// X_test = all columns except Response / y_test = only Response)\n",
    "y = train_dataset['Response'].copy(deep=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# help IDE understand that we are still dealing with data frames\n",
    "X_train = pd.DataFrame(X_train)\n",
    "X_test = pd.DataFrame(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Imputation der fehlenden Werte <a class=\"anchor\" id=\"section_3_4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Imputationsstrategie*:<br>\n",
    "Die Imputation erfolgt anhand der nachfolgenden Prozedur. Es werden verschiedene Imputationsstrategien (`mean`, `median`, `hot_code_locf` und `most_frequent`) ausprobiert.\n",
    "- Die Imputation der fehlenden Werte wird für die Trainingsdaten \"X_train\" und für die Testdaten \"X_test\" separat gemacht."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# strategies: mean, median, hot_code_locf, most_frequent, KNN\n",
    "def impute_data(data: pd.DataFrame, col_name, strategy, y_data=None):\n",
    "    if(strategy == \"hot_code_locf\"):\n",
    "        return data[col_name].fillna(method=\"ffill\")\n",
    "\n",
    "    elif(strategy == \"KNN\"):\n",
    "        # prepare data\n",
    "        ref_data = pd.concat([data, pd.get_dummies(\n",
    "            data[\"Gender\"], prefix=\"Gender_is_\")], axis=1)\n",
    "        ref_data = pd.concat([data, pd.get_dummies(\n",
    "            data[\"Vehicle_Age\"], prefix=\"Vehicle_Age_is_\")], axis=1)\n",
    "        ref_data = data.loc[:, ~data.columns.duplicated()]\n",
    "\n",
    "        # KNN imputation\n",
    "        imputer = KNNImputer(missing_values=np.nan, n_neighbors=2)\n",
    "        col_data = imputer.fit_transform(\n",
    "            ref_data.select_dtypes([\"number\", \"boolean\"]), y_data)\n",
    "\n",
    "        # restore column names\n",
    "        col_data = pd.DataFrame(col_data, columns=ref_data.columns)\n",
    "\n",
    "        return col_data[col_name]\n",
    "\n",
    "    else:\n",
    "        imputer = SimpleImputer(strategy=strategy, missing_values=np.NaN)\n",
    "        fit = imputer.fit(data[[col_name]])\n",
    "        col_data = fit.transform(data[[col_name]])\n",
    "        return col_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.1 Ersetzung der fehlenden Werte numerischer Variablen <a class=\"anchor\" id=\"section_3_4_1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4.1.1 Imputation der Variable Age <a class=\"anchor\" id=\"section_3_4_1_1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trainingsdaten\n",
    "X_train[\"Age\"] = impute_data(X_train, \"Age\", \"mean\")\n",
    "\n",
    "#Testdaten\n",
    "X_test[\"Age\"] = impute_data(X_test, \"Age\", \"mean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4.1.2 Imputation der Variable Annual_Premium <a class=\"anchor\" id=\"section_3_4_1_2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trainingsdaten\n",
    "X_train[\"Annual_Premium\"] = impute_data(X_train, \"Annual_Premium\", \"median\")\n",
    "\n",
    "#Testdaten\n",
    "X_test[\"Annual_Premium\"] = impute_data(X_test, \"Annual_Premium\", \"median\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.2 Ersetzung der fehlenden Werte kategorialer Variablen <a class=\"anchor\" id=\"section_3_4_2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4.2.1 Imputation der Variable Gender <a class=\"anchor\" id=\"section_3_4_2_1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trainingsdaten\n",
    "X_train[\"Gender\"] = impute_data(X_train, \"Gender\", \"most_frequent\")\n",
    "\n",
    "#Testdaten\n",
    "X_test[\"Gender\"] = impute_data(X_test, \"Gender\", \"most_frequent\")\n",
    "\n",
    "#cast Gender to category Datatype again:\n",
    "#Trainingsdaten\n",
    "X_train[\"Gender\"] = X_train[\"Gender\"].astype(pd.CategoricalDtype())\n",
    "\n",
    "#Testdaten\n",
    "X_test[\"Gender\"] = X_test[\"Gender\"].astype(pd.CategoricalDtype())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.3 Überprüfung der Imputationen<a class=\"anchor\" id=\"section_3_4_3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Missing Values in der Spalte Age: Test = {X_test[\"Age\"].isna().sum()}, Training = {X_train[\"Age\"].isna().sum()}')\n",
    "print(f'Missing Values in der Spalte Annual_Premium: Test = {X_test[\"Annual_Premium\"].isna().sum()}, Training = {X_train[\"Annual_Premium\"].isna().sum()}')\n",
    "print(f'Missing Values in der Spalte Gender: Test = {X_test[\"Gender\"].isna().sum()}, Training = {X_train[\"Gender\"].isna().sum()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Imputation war erfolgreich und alle Missing Values in den Trainingsdaten und Testdaten wurden ersetzt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5. Sampling <a class=\"anchor\" id=\"section_3_5\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zunächst muss die Zielvariable `Response` wieder zu den Trainingsdaten und Testdaten hinzugefügt werden, da wir beim Sampling die Zielvariable betrachten.\n",
    "\n",
    "- Insgesamter Datensatz der Zielvariable im **X_train** beträgt: 266.663 Datensätze\n",
    "- Davon macht True 12% des Datensatzes aus. Dies ist die minority Class\n",
    "- Davon macht False 88% des Datensatzes aus. Dies ist die majority Class<br>\n",
    "<br>\n",
    "- Insgesamter Datensatz der Zielvariable im **X_test** beträgt: 114.285 Datensätze\n",
    "- Davon macht True 12% des Datensatzes aus. Dies ist die minority Class\n",
    "- Davon macht False 88% des Datessatzes aus. Dies ist die majority Class\n",
    "\n",
    "Mit der Methode des zufälligen Oversamplings werden Datensätze aus der Minderheitsklasse, in dem Fall `Response` True, zufällig ausgewählt und dupliziert und dem Trainingsdatensatz hinzugefügt.\n",
    "Beim zufälligen Undersampling werden Datensätze aus der Mehrheitsklasse, in dem Fall `Response` False, zufällig ausgewählt und aus dem Trainingsdatensatz entfernt.\n",
    "- Aus einer unbalancierten Klassenverteilung wird zwischen der minority und majority class ein Gleichgewicht hergestellt.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-add Response\n",
    "\n",
    "#insert in X_train --> y_train \n",
    "X_train.insert(len(X_train.columns), value=y_train, column=\"Response\")\n",
    "\n",
    "#insert in X_test --> y_test\n",
    "X_test.insert(len(X_test.columns), value=y_test, column=\"Response\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions for visualization\n",
    "\n",
    "# plot output\n",
    "def plot_prop_of_split(train, test, col_name, sub_heading=\"\"):\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(20, 10))\n",
    "\n",
    "    #Plot for Trainingdata\n",
    "    cp_1 = sns.countplot(data=train, x=col_name, ax=ax[0])\n",
    "    cp_1.set_title(\"Trainingsdaten\", weight=\"bold\", fontsize=14)\n",
    "    cp_1.set_xlabel(\"Response\", fontsize=20, weight='bold')\n",
    "    cp_1.set_ylabel(\"Count\", fontsize=20, weight='bold');\n",
    "\n",
    "    #Plot for Testdata\n",
    "    cp_2 = sns.countplot(data=test, x=col_name, ax=ax[1])\n",
    "    cp_2.set_title(\"Testdaten\", weight=\"bold\", fontsize=14)\n",
    "    cp_2.set_xlabel(\"Response\", fontsize=20, weight='bold')\n",
    "    cp_2.set_ylabel(\"Count\", fontsize=20, weight='bold');\n",
    "\n",
    "   #Title over both charts\n",
    "    fig.suptitle(f\"Verteilung der Variable {col_name} in Trainingsdaten und Testdaten\\n {sub_heading}\", weight=\"bold\", fontsize=30)\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "# console output\n",
    "def print_class_len_and_ratio(data: pd.DataFrame, col_name):\n",
    "\n",
    "    # minority_class\n",
    "    minority_class_len = len(data[data[col_name] == True])\n",
    "    print(f\"Die Variable {col_name} enthält {minority_class_len} Datensätze die den Wert True enthalten.\")\n",
    "\n",
    "    # majority_class\n",
    "    majority_class_len = len(data[data[col_name] == False])\n",
    "    print(f\"Die Variable {col_name} enthält {majority_class_len} Datensätze die den Wert False enthalten.\")\n",
    "\n",
    "    # ratio\n",
    "    print(train_dataset[\"Response\"].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_prop_of_split(X_train, X_test, \"Response\", \"(vor Sampling)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_class_len_and_ratio(X_train, \"Response\")\n",
    "print(\"-\"*50)\n",
    "print_class_len_and_ratio(X_test, \"Response\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5.1. Undersampling <a class=\"anchor\" id=\"section_3_5_1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def undersample(data: pd.DataFrame, col_name):\n",
    "    # Variable values count as integer\n",
    "    response_false_count, response_true_count = data[col_name].value_counts()\n",
    "\n",
    "    # Seperate in bool values (True and False values)\n",
    "    seperate_response_false = data[data[col_name] == False]\n",
    "    seperate_response_true = data[data[col_name] == True]\n",
    "\n",
    "    # Undersampling to balance imbalanced datasets --> deleting samples from the majority class\n",
    "    response_false_undersampling = seperate_response_false.sample(response_true_count, random_state=42)\n",
    "    undersampling = pd.concat([response_false_undersampling, seperate_response_true], axis=0)\n",
    "\n",
    "    return undersampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datensätze aus der majority_class werden zufällig entfernt.\n",
    "- Daraus entsteht eine identische Anzahl an Datensätzen für die Zielvariable `Response` mit den Ausprägungen True und False.\n",
    "- Der Datensatz wird balanciert, indem die gleiche Anzahl an Datensätzen von True zufällig für False gezogen wird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train run through the undersample function from section 3.5.1\n",
    "X_train_undersampling = undersample(X_train, \"Response\")\n",
    "\n",
    "# After the undersampling process X_train_undersampling will be plotted (plot function from section 3.5)\n",
    "plot_prop_of_split(X_train_undersampling, X_test, \"Response\", \"(nach Undersampling)\")\n",
    "\n",
    "# console output from X_train_Undersampling\n",
    "print_class_len_and_ratio(X_train_undersampling, \"Response\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5.2. Oversampling <a class=\"anchor\" id=\"section_3_5_2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oversample(data: pd.DataFrame, col_name):\n",
    "    # Variable values count as integer\n",
    "    response_false_count, response_true_count = data[col_name].value_counts()\n",
    "\n",
    "    # Seperate in bool values (True and False values)\n",
    "    seperate_response_false = data[data[col_name] == False]\n",
    "    seperate_response_true = data[data[col_name] == True]\n",
    "\n",
    "    # Oversampling to balance imbalanced datasets --> generate samples from the minority class\n",
    "    response_true_oversampling = seperate_response_true.sample(response_false_count, replace=True, random_state=42)\n",
    "    oversampling = pd.concat([response_true_oversampling, seperate_response_false], axis=0)\n",
    "\n",
    "    return oversampling  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datensätze aus der minority_class werden durch Generierung künstlicher Beispiele aufgestockt.\n",
    "- Daraus entsteht eine identische Anzahl an Datensätzen für die Zielvariable `Response` mit den Ausprägungen True und False.\n",
    "- Der Datensatz wird balanciert, indem die gleiche Anzahl an Datensätzen von False künstlich für True erzeugt wird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train run through the oversample function from section 3.5.2\n",
    "X_train_oversampling = oversample(X_train, \"Response\")\n",
    "\n",
    "# new rows were added to X_train by Oversampling, but they dont have an index yet\n",
    "X_train_oversampling = X_train_oversampling.reset_index()\n",
    "\n",
    "# After the oversampling process X_train_oversampling will be plotted (plot function from section 3.5)\n",
    "plot_prop_of_split(X_train_oversampling, X_test, \"Response\", \"(nach Oversampling)\")\n",
    "\n",
    "# console output from X_train_oversampling\n",
    "print_class_len_and_ratio(X_train_oversampling, \"Response\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5.3. Cleanup <a class=\"anchor\" id=\"section_3_5_3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die gesplitteten Trainingsdaten und Testdaten mussten für das Over- und Undersampling wieder mit der Zielvariable `Response` verknüpft werden. Im Fall von Oversampling wurden neue Datensätze erzeugt und im Fall von Undersampling wurden Datensätze entfernt, um ein Gleichgewicht der Klassen zu schaffen. Beides führt dazu, dass der gesampelte Datensatz `X_train` (Undersampling oder Oversampling) nicht mehr zu dem ursprünglichen Datensatz der Zielvariable `y_train` passt, da Länge und Zuordnung der Werte des jeweiligen gesampelten Datensatzes nicht mehr übereinstimmt. Deshalb wird nur die Spalte mit der gesampelten (Undersamling oder Oversampling) Zielvariable einer neuen Variable zugewiesen damit wir diese neue Variable nachfolgend verwenden können."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nach dem Undersampling wird die Zielvariable Response der Variable \"y_train_undersampling\" zugewiesen\n",
    "y_train_undersampling = X_train_undersampling[\"Response\"]\n",
    "\n",
    "# nach dem Oversampling wird die Zielvariable Response der Variable \"y_train_oversampling\" zugewiesen\n",
    "y_train_oversampling = X_train_oversampling[\"Response\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anschließend wird die Zielvariable wieder von den Trainingsdaten und Testdaten entfernt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Response from the undersampled dataset\n",
    "X_train_undersampling = X_train_undersampling.drop(\"Response\", axis=\"columns\")\n",
    "\n",
    "# Remove Response from the oversampled dataset\n",
    "X_train_oversampling = X_train_oversampling.drop(\"Response\", axis=\"columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5.4. Under- vs. Oversampling <a class=\"anchor\" id=\"section_3_5_4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bei einem stark unausgeglichenen Datensatz kann das Oversampling dazu führen das die Minterheitsklasse überangepasst wird, da die Wahrscheinlichkeit größer ist das exakte Kopien der Datensätze für die Minderheitsklasse erstellt werden.\n",
    "\n",
    "Im vorliegenden Datensatz stehen die Minderheiten- und Mehrheitenklasse im Verhältnis 12:88, daher verwenden wir Undersampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set to undersampling to work with this dataset. \n",
    "# X_train = the undersampled dataset without response\n",
    "# y_train = the undersampled dataset only with response\n",
    "\n",
    "X_train = X_train_undersampling\n",
    "y_train = y_train_undersampling\n",
    "print(\"Using Undersampling\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6. Feature Engineering <a class=\"anchor\" id=\"section_3_6\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6.1. Altersklassen als Feature <a class=\"anchor\" id=\"section_3_6_1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Eingrenzung der Variable `Age` in Oktile (q=8) um die Intervalle festzustellen.\n",
    "- Das Ergebnis der Funktion \".qcut\" ist eine Variable des Datentypes \"Category\" da jedes Intervall (bin) einer Kategorie entspricht.\n",
    "- Der Kategorien der Variable `Age_bin` für den `X_train` und `X_test` Datensatz sind:\n",
    "    - [20.0 - 23.0[ < [23.0 - 25.0[ < [25.0 - 28.0[ < [28.0 - 36.0[ < [36.0 - 43.0[ < [43.0 - 49.0[ < [49.0 - 59.0[ < [59.0 - 85.0["
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainigsdaten\n",
    "X_train['Age_bins'] = pd.qcut(train_dataset[\"Age\"], q=8)\n",
    "print(f\"Age Bins for Trainingdata:\\n{X_train['Age_bins'].value_counts().sort_index()}\\n\")\n",
    "\n",
    "# Testdaten\n",
    "X_test['Age_bins'] = pd.qcut(train_dataset[\"Age\"], q=8)\n",
    "print(f\"Age Bins for Testdata:\\n{X_test['Age_bins'].value_counts().sort_index()}\\n\")\n",
    "\n",
    "###\n",
    "\n",
    "# Dataset from the test.csv\n",
    "real_dataset[\"Age_bins\"] = pd.qcut(train_dataset[\"Age\"], q=8)\n",
    "print(f\"Age Bins for test.csv:\\n{real_dataset['Age_bins'].value_counts().sort_index()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split Age in 8 categories --> octiles\n",
    "octiles_list = [0, 0.125, 0.25, 0.375, 0.5, 0.625, 0.75, 0.875, 1]\n",
    "octiles = X_train[\"Age\"].quantile(octiles_list)\n",
    "\n",
    "# Plot Age as histplot\n",
    "plt.figure(figsize= (22, 10))\n",
    "fig, ax = plt.subplots()\n",
    "X_train['Age'].hist(bins=65, color='#A9C5D3', \n",
    "                             edgecolor='black', grid=False)\n",
    "\n",
    "# Plot the octiles as axvplot over the histplot\n",
    "for quantile in octiles:\n",
    "    axvlineplot = plt.axvline(quantile, color='r')\n",
    "ax.legend([axvlineplot], ['Oktil'], fontsize=16)\n",
    "\n",
    "ax.set_title('Age Histogramm mit Oktile', \n",
    "             fontsize=24, weight=\"bold\")\n",
    "ax.set_xlabel('Age', fontsize=14, weight=\"bold\")\n",
    "ax.set_ylabel('Count', fontsize=14, weight=\"bold\")\n",
    "\n",
    "# start graph just before 20 (no smaller values)\n",
    "ax.set_xlim(19, 90)\n",
    "\n",
    "# show ticks at octiles and steps of 10\n",
    "ax.set_xticks([*octiles.to_numpy(), *range(20,90,10)]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Beobachtung:**\n",
    "- Der Peak bei 40 ist auf die Imputation durch den Mittelwert zurückzuführen\n",
    "    - Alle Missing Values der Variable `Age` wurden auf **40** gesetzt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define labels\n",
    "def labels():\n",
    "    q = train_dataset[\"Age\"].quantile(octiles_list).to_numpy()\n",
    "    i = 0\n",
    "    labels = []\n",
    "    while i < len(q)-1:\n",
    "        labels.append(f\"[{q[i]} - {q[i+1]}[\")\n",
    "        i+=1\n",
    "\n",
    "    return labels\n",
    "\n",
    "# function for numerical_binning\n",
    "def numerical_binning(data):\n",
    "        data['Age_bins'] = pd.qcut(\n",
    "            data.Age, q=8, labels=labels()\n",
    "            )\n",
    "        return data['Age_bins'].value_counts().sort_index()\n",
    "\n",
    "\n",
    "# Trainingsdaten\n",
    "numerical_binning(X_train)\n",
    "\n",
    "# Testdaten\n",
    "numerical_binning(X_test)\n",
    "\n",
    "\n",
    "###\n",
    "\n",
    "# Dataset from the test.csv\n",
    "numerical_binning(real_dataset);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={\"figure.figsize\": (22, 10)})\n",
    "histplot =sns.histplot(X_train, x=\"Age\", hue=\"Age_bins\", bins=65)\n",
    "\n",
    "histplot.set_title('Histogram der Variable Age in Zusammenhang mit Age_bins', \n",
    "             fontsize=24, weight=\"bold\")\n",
    "histplot.set_xlabel('Age', fontsize=14, weight=\"bold\")\n",
    "histplot.set_ylabel('Count', fontsize=14, weight=\"bold\")\n",
    "histplot.set_xlim(19, 85)\n",
    "histplot.set_xticks(range(20,90,1));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6.2 Features durch Aggregationen, Differenzen und Verhältnisse <a class=\"anchor\" id=\"section_3_6_2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create features function\n",
    "def feature_encoding(data, col_name):\n",
    "    selected_categorical_columns = data.select_dtypes(include=[\"category\"])\n",
    "    for categorical_columns in selected_categorical_columns:\n",
    "\n",
    "        # mean encoding using numeric variable//\n",
    "        # group by categorical variables and obtain the mean over the numeric variable\n",
    "        mean = data.groupby(categorical_columns)[col_name].agg(['mean'])\n",
    "        mean.columns = [f'mean_{col_name}_by_' + categorical_columns]\n",
    "\n",
    "        # joining the column to the main dataset \n",
    "        data = pd.merge(data, mean, left_on=categorical_columns,\n",
    "                        right_index=True, how='left')\n",
    "\n",
    "        # difference between the numerical variable and the mean grouped by the categorical variables over the numeric one.\n",
    "        data[f\"diff_{col_name}_mean_by_\" + categorical_columns] = data[col_name] - \\\n",
    "            data[f\"mean_{col_name}_by_\" + categorical_columns]\n",
    "\n",
    "        # percentage of the difference\n",
    "        perc = data[f\"diff_{col_name}_mean_by_\" + categorical_columns].abs() / data[f'mean_{col_name}_by_' + categorical_columns]\n",
    "        data[f\"prop_{col_name}_mean_by_\" + categorical_columns] = perc\n",
    "                                                                       \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainingsdaten\n",
    "print(\"Creating features for Trainingdata:\")\n",
    "for col in X_train.select_dtypes(include=[\"number\"], exclude=[\"bool\", \"boolean\"]):\n",
    "    print(f\"Creating features for {col}\")\n",
    "    X_train = feature_encoding(X_train, col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testdaten\n",
    "print(\"Creating features for Testdata:\")\n",
    "for col in X_test.select_dtypes(include=[\"number\"], exclude=[\"bool\", \"boolean\"]):\n",
    "    print(f\"Creating features for {col}\")\n",
    "    X_test = feature_encoding(X_test, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset from the test.csv\n",
    "print(\"Creating features for the test.csv:\")\n",
    "for col in real_dataset.select_dtypes(include=[\"number\"], exclude=[\"bool\", \"boolean\"]):\n",
    "    print(f\"Creating features for {col}\")\n",
    "    real_dataset = feature_encoding(real_dataset, col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6.3 One-Hot-Encoding für kategoriale Variablen <a class=\"anchor\" id=\"section_3_6_3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Konvertieren von kategorialen Variablen in Dummy/Indikator-Variablen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainingsdaten\n",
    "X_train = pd.concat([X_train, pd.get_dummies(X_train[\"Gender\"], prefix=\"Gender_is_\")], axis=1)\n",
    "X_train = pd.concat([X_train, pd.get_dummies(X_train[\"Vehicle_Age\"], prefix=\"Vehicle_Age_is_\")], axis=1)\n",
    "X_train = pd.concat([X_train, pd.get_dummies(X_train[\"Age_bins\"], prefix=\"Age_bins_is\")], axis=1)\n",
    "X_train = X_train.loc[:,~X_train.columns.duplicated()]\n",
    "print(f\"Wir starten mit {len(X_train.columns)} Features in die Featureselektion\")\n",
    "\n",
    "# Testdaten\n",
    "X_test = pd.concat([X_test, pd.get_dummies(X_test[\"Gender\"], prefix=\"Gender_is_\")], axis=1)\n",
    "X_test = pd.concat([X_test, pd.get_dummies(X_test[\"Vehicle_Age\"], prefix=\"Vehicle_Age_is_\")], axis=1)\n",
    "X_test = pd.concat([X_test, pd.get_dummies(X_test[\"Age_bins\"], prefix=\"Age_bins_is\")], axis=1)\n",
    "X_test = X_test.loc[:,~X_test.columns.duplicated()]\n",
    "\n",
    "###\n",
    "\n",
    "# Dataset from the test.csv\n",
    "real_dataset = pd.concat([real_dataset, pd.get_dummies(real_dataset[\"Gender\"], prefix=\"Gender_is_\")], axis=1)\n",
    "real_dataset = pd.concat([real_dataset, pd.get_dummies(real_dataset[\"Vehicle_Age\"], prefix=\"Vehicle_Age_is_\")], axis=1)\n",
    "real_dataset = pd.concat([real_dataset, pd.get_dummies(real_dataset[\"Age_bins\"], prefix=\"Age_bins_is\")], axis=1)\n",
    "real_dataset = real_dataset.loc[:,~real_dataset.columns.duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.7 Feature Selection <a class=\"anchor\" id=\"section_3_7\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Bei der Feature Selection wählen wir die Features aus, die für den machine-learning-process verwendet werden. \n",
    "- Hierbei ist darauf zu achten, dass nur relevante Features zur Modellbildung verwendet werden sollten, da sonst eine Überanpassung des Modells stattfinden kann.\n",
    "- Durch die neu hinzugekommenen Features aus dem Feature Engineering umfasst der Datensatz nun 69 Spalten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 100)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Um sich eine Übersicht über die Variablen zu verschaffen wird ein Korrelationsplot genutzt, damit die Abhängigkeiten der einzelnen Variablen betrachtet werden können.\n",
    "- Variablen die eine zu hohe Korrelaton vorweisen, werden aus dem Datensatz entfernt da sich diese negativ auf die Modellierung auswirken können.\n",
    "- Der folgende Korrelationsplot berücksichtigt alle Variablen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Korrelation aller Variablen nach Pearson (using the function from section 2.7)\n",
    "correlation_matrix_plot(X_train, 24, 12, False, \"seismic\", \"pearson\")\n",
    "\n",
    "# Korrelation aller Variablen nach Spearman (using the function from section 2.7)\n",
    "correlation_matrix_plot(X_train, 24, 12, False, \"seismic\", \"spearman\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pearson = X_train.corr(method=\"pearson\")\n",
    "spearman = X_train.corr(method=\"spearman\")\n",
    "\n",
    "delta = spearman.abs() - pearson.abs()\n",
    "hm = sns.heatmap(delta, cmap=\"seismic\", center=0)\n",
    "hm.set_title(\"Abweichungen zwischen Spearman und Pearson\",\n",
    "             fontsize=24, weight=\"bold\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bei der Feature Selection wird die Spearman-Korrelation verwendet. Da diese ohne Betrachtung der Abstände der einzelnen Werte auskommt, ist sie inklusiver als die Pearson-Korrelation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um die Feature Selection durchführen zu können, muss der Datensatz auf numerische Daten reduziert werden. Die Vorbereitungen hierzu wurden bereits im Abschnitt **Data Preparation** getroffen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainingsdaten\n",
    "X_train_feature = X_train.select_dtypes([\"number\", \"boolean\"])\n",
    "print(f\"Spalten des Datensatzes 'X_train' nur mit numerischen und booleschen Datentypen: {len(X_train_feature.columns)}\")\n",
    "\n",
    "#Testdaten\n",
    "X_test_feature = X_test.select_dtypes([\"number\", \"boolean\"])\n",
    "print(f\"Spalten des Datensatzes 'X_test' nur mit numerischen und booleschen Datentypen: {len(X_test_feature.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.7.1 Feature Selection anhand von Korrelation <a class=\"anchor\" id=\"section_3_7_1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features mit zu hohen Korrelationen untereinander können als redundant betrachtet werden. Nachfolgend werden alle Features mit einer Korrelation über einem Threshold entfernt. Der Threshold wird bestimmt, indem er nach und nach (von 1 aus kommend) verringert wird.\n",
    "- Daher werden alle Variablen mit einem `threshold` von <= - 0,9 und >= 0,9 entfernt.\n",
    "- Bei der Pearson-Methode werden 36 features entfernt.\n",
    "- Bei der Spearman-Methode werden 35 features entfernt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection auf Basis zu hoher Korrelation\n",
    "def get_columns_with_high_correlations(data: pd.DataFrame, threshold, corr_method):\n",
    "    corr = data.corr(method=corr_method)\n",
    "\n",
    "    # create a triangle of boolean Trues as a mask to keep values from corr matrix\n",
    "    #       t   t   t   t\n",
    "    #           t   t   t\n",
    "    #               t   t\n",
    "    #                   t\n",
    "    # all values in  the matrix that overlap with this mask will be kept\n",
    "    # all values below will be removed to prevent double deletion and deletion of correlations in the diagonal (where corr is always 1)\n",
    "    mask = np.triu(np.ones(corr.shape), k=1).astype(np.bool)\n",
    "\n",
    "    # upper side of corr matrix\n",
    "    upper_triange = corr.where(mask)\n",
    "\n",
    "    # get all ABSOLUTE correlations that are > threshold\n",
    "    cols_to_drop = [column for column in upper_triange.columns if any(\n",
    "        upper_triange[column].abs() > threshold)]\n",
    "    return cols_to_drop\n",
    "\n",
    "\n",
    "def drop_columns_with_high_correlation(data: pd.DataFrame, threshold, corr_method):\n",
    "    cols = get_columns_with_high_correlations(data, threshold, corr_method)\n",
    "    data = data.drop(cols, axis=1)\n",
    "    print(f\"Removed {len(cols)} features using method: {corr_method} and threshold: {threshold}\")\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection by removing the highest korrelation (threshold <= -0,9 and >= 0,9 = correlations similar or higher than 0,9 and correlations similar or lower than -0,9 will be romoved)\n",
    "\n",
    "# RUN THIS ONLY FOR FINDING THRESHOLD\n",
    "# try to find propper threshold using the function in section 3.7\n",
    "\"\"\"\n",
    "for thresh in [0.9, 0.8, 0.7]:\n",
    "    drop_columns_with_high_correlation(X_train_feature, thresh, \"pearson\")\n",
    "\n",
    "    drop_columns_with_high_correlation(X_train_feature, thresh, \"spearman\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform feature selection on dataset \"X_train_feature\" with selected threshold (using the function in section 3.7)\n",
    "corr_thresh = 0.9\n",
    "pearson = drop_columns_with_high_correlation(X_train_feature, corr_thresh, \"pearson\")\n",
    "\n",
    "spearman = drop_columns_with_high_correlation(X_train_feature, corr_thresh, \"spearman\")\n",
    "\n",
    "# select feature set to continue with\n",
    "X_train_removed_features = spearman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Es verbleiben im Datensatz X_train nach spearman: {len(X_train_removed_features.columns)} Features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nach der Bereinigung des Datensatzes sind alle Variablen mit einem `threshold` von <= - 0,9 und >= 0,9 entfernt worden, wie am nachfolgenden Korrelationsplot ersichtlich ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Korrelation aller Variablen nach entfernung der features durch den threshold nach Spearman (using the function from section 2.7)\n",
    "correlation_matrix_plot(X_train_removed_features, 24, 12, False, \"seismic\", \"spearman\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.7.2 Feature Importance durch Logistische Regression <a class=\"anchor\" id=\"section_3_7_2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bei der Ermittlung der Feature Importance werden die Features mithilfe logistischer Regression analysiert. Dabei werden die Koeffizienten der einzelnen Variablen in Abhängigkeit zu der Zielvariable `Response` betrachtet. Daraus lässt sich der **Score** ermitteln. Auch hier wird ein Grenzwert benötigt, der zwischen unwichtigen und wichtigen Features unterscheidet. Dieser Threshold kann nach Betrachtung der Feature Importance am besten eingeschätzt werden.\n",
    "\n",
    "|    **Score**          | **Erklärung**  | \n",
    "|          :-:           |         :-        |\n",
    "|       >0              |Wenn der Score >0 ist dann hat die Variable einen tendenziell positiven Einfluss darauf das eine KFZ-Versicherung abgeschlossen wird.| \n",
    "|         <0              |Wenn der Score <0 ist dann hat die Variable einen tendenziell negativen Einfluss darauf das eine KFZ-Versicherung abgeschlossen wird.| \n",
    "|  =0                 |Wenn der Score =0 ist dann hat die Variable weder einen tendenziell positiven, noch negativen Einfluss darauf, dass eine KFZ-Versicherung abgeschlossen wird.| "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature importance by linear regression\n",
    "feat_imp_thresh = 0.01\n",
    "\n",
    "# define the model\n",
    "model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "# fit the model \n",
    "model.fit(X_train_removed_features, y_train)    # y_train is the dataset after undersampling (y_train_undersampling --> section 3.5.4)\n",
    "\n",
    "# get importance\n",
    "importance = model.coef_[0]\n",
    "i = pd.DataFrame(importance)\n",
    "i[\"Feature\"] = X_train_removed_features.columns\n",
    "i = i.rename(columns={0: \"Score\"})\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "# summarize feature importance --> console output\n",
    "for i, v in enumerate(importance):\n",
    "    print('Feature: %0d %s, Score: %.5f' %\n",
    "          (i, X_train_removed_features.columns[i], v))\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# plot feature importance\n",
    "i = i.sort_values(\"Score\", ascending=False)\n",
    "b = sns.barplot(x=\"Feature\", y=\"Score\", data=i)\n",
    "b.tick_params(axis='x', rotation=90)\n",
    "b.set_title(\"Scores der Features\", fontsize=\"30\", weight=\"bold\")\n",
    "b.set_xlabel(\"Feature\", fontsize=20, weight=\"bold\")\n",
    "b.set_ylabel(\"Score\", fontsize=20, weight=\"bold\")\n",
    "b.axhline(feat_imp_thresh, color=\"r\")\n",
    "b.axhline(-feat_imp_thresh, color=\"r\");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nach der Untersuchung der Feature Importance bleiben nur wenige Features für die Modellierung übrig.\n",
    "\n",
    "Die Test- und Trainingsdaten werden auf die ausgewählten Features reduziert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output in console only the relevant features\n",
    "relevant_features = i.loc[i[\"Score\"].abs() > feat_imp_thresh]\n",
    "print(relevant_features)\n",
    "\n",
    "# Trainingsdaten\n",
    "modelling_data_train = X_train_removed_features[relevant_features[\"Feature\"]]\n",
    "\n",
    "# Testdaten\n",
    "modelling_data_test = X_test_feature[relevant_features[\"Feature\"]]\n",
    "\n",
    "###\n",
    "\n",
    "# Dataset from the test.csv\n",
    "real_data_for_modelling = real_dataset[relevant_features[\"Feature\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Modeling <a class=\"anchor\" id=\"chapter4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im Folgenden werden 3 verschiedene Modelle untersucht:\n",
    "\n",
    "1. Random Forest Classification\n",
    "1. Neuronales Netz\n",
    "1. Gradient Boosting\n",
    "\n",
    "Um die optimalen Parametereinstellungen zu finden, wird auf jedes Modell Hyperparametertuning angewendet. Das bedeutet, dass aus einer Vorauswahl von möglichen Parameterwerten alle Kombinationen ausprobiert werden. So kann das beste Modell gefunden werden.\n",
    "\n",
    "Zum einfachen Vergleich werden die Vorhersagen der Modelle in einem Array gespeichert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [None, None, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explicitly require this experimental feature\n",
    "from sklearn.experimental import enable_halving_search_cv # noqa\n",
    "# now you can import normally from model_selection\n",
    "from sklearn.model_selection import HalvingGridSearchCV\n",
    "\n",
    "# Function to run all classifications through\n",
    "# trains and evaluates models\n",
    "# returns classifier, grid tuner, and prediction\n",
    "def hyper_parameter_tuning(param_grid, clf, X_train, y_train, X_test, y_test, model_name, cv=5, use_multithreading=False):\n",
    "\n",
    "    grid_tuner = None\n",
    "    if use_multithreading == True:\n",
    "        # build Grid Search CV\n",
    "        grid_tuner = HalvingGridSearchCV(\n",
    "            estimator=clf, param_grid=param_grid, cv=cv, verbose=2, n_jobs=4)\n",
    "    else:\n",
    "        grid_tuner = HalvingGridSearchCV(\n",
    "            estimator=clf, param_grid=param_grid, cv=cv, verbose=2)\n",
    "\n",
    "    grid_tuner.fit(X_train, y_train)\n",
    "\n",
    "    # predict\n",
    "    y_pred = grid_tuner.predict(X_test)\n",
    "\n",
    "    print(grid_tuner.best_params_)\n",
    "    print(\"\\n\")\n",
    "    print(f\"Train Accuracy: {grid_tuner.score(X_train, y_train)}\")\n",
    "    print(f\"Test Accuracy:  {grid_tuner.score(X_test, y_test)}\")\n",
    "    return clf, grid_tuner, {\"Prediction\": y_pred, \"Name\": f\"{model_name}\"}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Modell: Random Forest mit Hyperparametertuning <a class=\"anchor\" id=\"section_4_1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das `Random Forest`-Modell ist das einfachste Modell im Vergleich. Es besteht aus einer Anzahl von Entscheidungsbäumen. Grob vereinfacht, stimmen alle Bäume darüber ab, welche entgültige Klassifikation angewendet wird.\n",
    "Über die Parameter `n_estimators` und `max_depth` wird die Anzahl und die maximale Tiefe der Bäume bestimmt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flag to select new HPT run or run on best values found previously\n",
    "use_best_values = False\n",
    "\n",
    "param_grid = {}\n",
    "cv = 5\n",
    "use_multithreading = True\n",
    "\n",
    "# these values come from previous runs\n",
    "# set use_best_values to true to quickly generate new output without rerunning HPT\n",
    "if use_best_values == True:\n",
    "    param_grid = {\n",
    "        \"n_estimators\": [400],\n",
    "        \"max_features\": [\"auto\"],\n",
    "        \"criterion\": [\"gini\"],\n",
    "        # \"max_depth\": [8],\n",
    "        # \"min_samples_leaf\": [2],\n",
    "        \"min_samples_split\": [8],\n",
    "        \"bootstrap\": [True]\n",
    "    }\n",
    "    cv = 2\n",
    "else:\n",
    "    # Hyperparametertuning\n",
    "    param_grid = {\n",
    "        \"n_estimators\": [100, 200, 400, 800],\n",
    "        \"criterion\": [\"gini\", \"entropy\"],\n",
    "        \"max_features\": [\"auto\"],\n",
    "        # \"max_depth\": [None, ],\n",
    "        # \"min_samples_leaf\": range(2, 5, 1),\n",
    "        \"min_samples_split\": [2, 8],\n",
    "        \"bootstrap\": [True]\n",
    "    }\n",
    "    cv = 5\n",
    "\n",
    "rf_clf, rf_grid_tuner, rf_prediction = hyper_parameter_tuning(param_grid, RandomForestClassifier(random_state=42),\n",
    "                                                              modelling_data_train, y_train,\n",
    "                                                              modelling_data_test, y_test,\n",
    "                                                              \"Random Forest (HPT)\", cv, use_multithreading)\n",
    "\n",
    "predictions[0] = rf_prediction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Modell: Neuronales Netz mit Hyperparametertuning <a class=\"anchor\" id=\"section_4_2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neuronale Netze sind vom Aufbau des Gehirns inspiriert. Ein neuronales Netz besteht aus Neuronen, die in Schichten angeordnet und immer mit allen Neuronen der Vorgängerschicht verbunden sind. Die Neuronen entscheiden anhand einer Aktivierungsfunktion, ob sie aktiviert werden oder nicht. Dieses Verhalten hat Einfluss darauf, welche Neuronen im nachfolgenden Layer aktiviert werden. Auf diese Art werden Neuronen von Schicht zu Schicht aktiviert, bis sie im Outputlayer ankommen. Dort ist wird je nach dem, welches Neuron aktiviert ist entschieden, welche Vorhersage getroffen werden kann.\n",
    "\n",
    "Im Zuge des Hyperparametertunings werden verschiedene Tiefen, Aktivierungsfunktionen und Anzahl der Iterationen des neuronalen Netzes ausprobiert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flag to select new HPT run or run on best values found previously\n",
    "use_best_values = False\n",
    "use_multithreading = True\n",
    "\n",
    "if use_best_values == True:\n",
    "    param_grid = {\n",
    "        'activation': ['tanh'],\n",
    "        'early_stopping': [False],\n",
    "        'hidden_layer_sizes': [(100, 100, 100)],\n",
    "        'max_iter': [500],\n",
    "        'solver': ['lbfgs']\n",
    "    }\n",
    "    cv = 2\n",
    "else:\n",
    "    # Hyperparametertuning\n",
    "    param_grid = {\n",
    "        \"hidden_layer_sizes\": [(100, 100,), (100, 100, 100),(100, 100, 100, 100)],\n",
    "        \"activation\": [\"identity\", \"tanh\"],\n",
    "        \"solver\": [\"lbfgs\", \"sgd\"],\n",
    "        \"max_iter\": [100, 200, 500],\n",
    "        \"early_stopping\": [False],\n",
    "    }\n",
    "    cv = 5\n",
    "\n",
    "nn_clf, nn_grid_tuner, nn_prediction = hyper_parameter_tuning(param_grid, MLPClassifier(random_state=42),\n",
    "                                                              modelling_data_train, y_train,\n",
    "                                                              modelling_data_test, y_test,\n",
    "                                                              \"Neuronales Netz (HPT)\", cv, use_multithreading)\n",
    "predictions[1] = nn_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Modell: Gradient Boosting mit Hyperparametertuning <a class=\"anchor\" id=\"section_4_3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flag to select new HPT run or run on best values found previously\n",
    "use_best_values = False\n",
    "use_multithreading = True\n",
    "\n",
    "if use_best_values == True:\n",
    "    param_grid = {\n",
    "        \"n_estimators\": [30],\n",
    "        \"loss\": [\"deviance\"],\n",
    "        \"learning_rate\": [0.2],\n",
    "        \"criterion\": [\"friedman_mse\"],\n",
    "        \"min_samples_split\": [2],\n",
    "        # \"min_samples_leaf\": [1],\n",
    "        # \"max_depth\": [5],\n",
    "        \"max_features\": [\"auto\"]\n",
    "    }\n",
    "    cv = 2\n",
    "else:\n",
    "    # Hyperparametertuning\n",
    "    param_grid = {\n",
    "        \"n_estimators\": [10, 20, 30, 50, 100, 200, 400],\n",
    "        \"loss\": [\"deviance\", \"exponential\"],\n",
    "        \"learning_rate\": np.linspace(0, 1, 6)[1:],  # 0,2 steps\n",
    "        \"criterion\": [\"friedman_mse\"],\n",
    "        \"min_samples_split\": [2, 4, 8],\n",
    "        # \"min_samples_leaf\": [2,4],\n",
    "        # \"max_depth\": [3, 5, 7],\n",
    "        \"max_features\": [\"auto\"]\n",
    "    }\n",
    "    cv = 5\n",
    "\n",
    "gb_clf, gb_grid_tuner, gb_prediction = hyper_parameter_tuning(param_grid, GradientBoostingClassifier(random_state=42),\n",
    "                                                              modelling_data_train, y_train,\n",
    "                                                              modelling_data_test, y_test,\n",
    "                                                              \"Gradient Boosting (HPT)\", cv, use_multithreading)\n",
    "predictions[2] = gb_prediction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Evaluation <a class=\"anchor\" id=\"chapter5\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bei der Evaluation werden die Gütemaße der Modelle berechnet und verglichen.\n",
    "\n",
    "Es werden folgende Gütemaße verglichen:\n",
    "- **TPR:** Anteil der `korrekten true`  Vorhersagen unter allen `tatsächlichen true`    Beobachtungen\n",
    "- **TNR:** Anteil der `korrekten false` Vorhersagen unter allen `tatsächlichen false`   Beobachtungen\n",
    "\n",
    "- **FPR:** Anteil der `falschen true`   Vorhersagen unter allen `tatsächlichen false`   Beobachtungen\n",
    "- **FNR:** Anteil der `falschen false`  Vorhersagen unter allen `tatsächlich true`      Beobachtungen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_confusion_matrix(y_test, y_prediction):\n",
    "    matrix = metrics.confusion_matrix(y_test, y_prediction)\n",
    "\n",
    "    matrix = np.append(matrix, [np.sum(matrix, axis=0)], axis=0)\n",
    "    col = np.array([np.sum(matrix, axis=1)])\n",
    "    matrix = np.concatenate((matrix, col.T), axis=1)\n",
    "\n",
    "    return matrix\n",
    "\n",
    "\n",
    "def get_scores(y_test, y_prediction):\n",
    "    matrix = metrics.confusion_matrix(y_test, y_prediction)\n",
    "\n",
    "    TN = matrix[0][0]\n",
    "    FP = matrix[0][1]\n",
    "    FN = matrix[1][0]\n",
    "    TP = matrix[1][1]\n",
    "\n",
    "    # Recall / Sensitivität / True Positive Rate / Trefferquote\n",
    "    TPR = TP / (TP + FN)\n",
    "\n",
    "    # Anteil der fälschlich als negativ klassifizierten Beobachtungen\n",
    "    FNR = 1 - TPR\n",
    "\n",
    "    # Spezifizität\n",
    "    TNR = TN / (TN + FP)\n",
    "\n",
    "    # False Positive Rate\n",
    "    FPR = 1 - TNR\n",
    "\n",
    "    return matrix, TPR, FNR, TNR, FPR\n",
    "\n",
    "\n",
    "def plot_scores(data: pd.DataFrame):\n",
    "    y_ticks = np.linspace(0, 1, 11)\n",
    "    fig, ax = plt.subplots(1, 6, sharey=True)\n",
    "\n",
    "    d_real = pd.DataFrame(y_test)\n",
    "    vc = pd.DataFrame(d_real[\"Response\"].value_counts() / len(d_real))\n",
    "\n",
    "    p_real = sns.barplot(data=vc, x=\"Response\", y=\"Response\", ax=ax[0], palette=sns.color_palette('binary_r', 2))\n",
    "    p_real.set_title(\"Realität\")\n",
    "    p_real.set_xticklabels([\"True\", \"False\"])\n",
    "    p_real.set_xlabel(\"\")\n",
    "    p_real.set_ylabel(\"\")\n",
    "\n",
    "    p_TPR = sns.barplot(data=data, x=\"Name\", y=\"TPR\", ax=ax[1])\n",
    "    p_TPR.set_yticks(y_ticks)\n",
    "    p_TPR.set_title(\"True Positive Rate\")\n",
    "    p_TPR.set_xlabel(\"\")\n",
    "    p_TPR.set_ylabel(\"\")\n",
    "    p_TPR.tick_params(axis='x', rotation=90)\n",
    "\n",
    "    p_FNR = sns.barplot(data=data, x=\"Name\", y=\"FNR\", ax=ax[2])\n",
    "    p_FNR.set_title(\"False Negative Rate\")\n",
    "    p_FNR.set_xlabel(\"\")\n",
    "    p_FNR.set_ylabel(\"\")\n",
    "    p_FNR.tick_params(axis='x', rotation=90)\n",
    "\n",
    "    p_TNR = sns.barplot(data=data, x=\"Name\", y=\"TNR\", ax=ax[3])\n",
    "    p_TNR.set_title(\"True Negative Rate\")\n",
    "    p_TNR.set_xlabel(\"\")\n",
    "    p_TNR.set_ylabel(\"\")\n",
    "    p_TNR.tick_params(axis='x', rotation=90)\n",
    "\n",
    "    p_FPR = sns.barplot(data=data, x=\"Name\", y=\"FPR\", ax=ax[4])\n",
    "    p_FPR.set_title(\"False Positive Rate\")\n",
    "    p_FPR.set_xlabel(\"\")\n",
    "    p_FPR.set_ylabel(\"\")\n",
    "    p_FPR.tick_params(axis='x', rotation=90)\n",
    "\n",
    "    p_AUC = sns.barplot(data=data, x=\"Name\", y=\"AUC\", ax=ax[5])\n",
    "    p_AUC.set_title(\"Area Under Curve\")\n",
    "    p_AUC.set_xlabel(\"\")\n",
    "    p_AUC.set_ylabel(\"\")\n",
    "    p_AUC.tick_params(axis='x', rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = pd.DataFrame(\n",
    "    columns=[\"Name\", \"TN\", \"FP\", \"FN\", \"TP\", \"TPR\", \"FNR\", \"FPR\", \"AUC\"])\n",
    "for model in predictions:\n",
    "    if model is not None:\n",
    "        matrix, TPR, FNR, TNR, FPR = get_scores(y_test, model[\"Prediction\"])\n",
    "        AUC = metrics.roc_auc_score(y_test, model[\"Prediction\"])\n",
    "        scores = scores.append({\"Name\": model[\"Name\"],\n",
    "                                \"TN\": matrix[0][0], \"FP\": matrix[0][1],\n",
    "                                \"FN\": matrix[1][0], \"TP\": matrix[1][1],\n",
    "                                \"TPR\": TPR,\n",
    "                                \"FNR\": FNR,\n",
    "                                \"TNR\": TNR,\n",
    "                                \"FPR\": FPR,\n",
    "                                \"AUC\": AUC\n",
    "                                }, ignore_index=True)\n",
    "plot_scores(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Bestes Modell <a class=\"anchor\" id=\"section_5_1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aus den drei berechneten Modellen können wir anhand der Gütemaße das beste heraussuchen. Welches das beste Modell ist hängt davon ab, auf welche Faktoren besonderen Wert gelegt wird.\n",
    "Die Aufgabenstellung des Projektes war es, ein Modell zu entwickeln, um möglichst effektiv Crossselling betreiben zu können. Auf der Basis der zur Verfügung gestellten Daten, versuchen wir vorherzusagen welche Kunden gezielt angesprochen werden sollten, um eine KFZ-Versicherung abzuschließen.\n",
    "\n",
    "- Das bedeutet unser Modell sollte eine **möglichst hohe Trefferquote** haben, denn es lohnt sich nur auf Kunden zuzugehen, die auch Bereit sind eine Versicherung abzuschließen.\n",
    "\n",
    "- In zweiter Priorität versuchen wir eine **möglichst niedrige False Positive Rate** zu erreichen, denn der Versuch einen Kunden zu erreichen, der fläschlicherweise als kaufwillig eingestuft wurde, kostet Zeit und Geld."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_test, y_prediction, model_name, axis=None):\n",
    "    conf_matrix = get_confusion_matrix(y_test, y_prediction)\n",
    "\n",
    "    plot = sns.heatmap(conf_matrix, annot=True, fmt=\"d\", ax=axis)\n",
    "    plot.set_xticklabels([\"False\", \"True\", \"Total\"])\n",
    "    plot.set_yticklabels([\"False\", \"True\", \"Total\"])\n",
    "    plot.set_xlabel(\"Predicted\")\n",
    "    plot.set_ylabel(\"Actual\")\n",
    "    plot.set_title(f\"Konfusionsmatrix von {model_name}\")\n",
    "    plot.axis = axis\n",
    "    return plot\n",
    "\n",
    "\n",
    "def plot_auc(y_test, y_prediction, model_name):\n",
    "    fpr, tpr, t = metrics.roc_curve(y_test, y_prediction)\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    d = metrics.RocCurveDisplay(\n",
    "        fpr=fpr, tpr=tpr, roc_auc=roc_auc, estimator_name=model_name)\n",
    "    return d\n",
    "\n",
    "# returns classifer, grid_tuner, predicction and scores\n",
    "\n",
    "\n",
    "def select_model(model_name):\n",
    "    if model_name == \"Random Forest (HTP)\":\n",
    "        return rf_clf, rf_grid_tuner, rf_prediction, scores.loc[scores[\"Name\"] == \"Random Forest (HTP)\"].sum()\n",
    "    if model_name == \"Neuronales Netz (HPT)\":\n",
    "        return nn_clf, nn_grid_tuner, nn_prediction, scores.loc[scores[\"Name\"] == \"Neuronales Netz (HPT)\"].sum()\n",
    "    if model_name == \"Gradient Boosting (HPT)\":\n",
    "        return gb_clf, gb_grid_tuner, gb_prediction, scores.loc[scores[\"Name\"] == \"Gradient Boosting (HPT)\"].sum()\n",
    "\n",
    "\n",
    "# select best model by name\n",
    "best_clf, best_grid_tuner, best_prediction, best_scores = select_model(\"Random Forest (HTP)\")\n",
    "\n",
    "n = best_scores.TP + best_scores.TN + best_scores.FP + best_scores.FN\n",
    "\n",
    "# calc scores\n",
    "ACC = (best_scores.TP + best_scores.TN) / n\n",
    "ER = 1 - ACC\n",
    "PRECISION = best_scores.TP / (best_scores.TP + best_scores.FP)\n",
    "print(\"Korrektklassifikationsrate: %.2f\" % (ACC))\n",
    "print(\"Fehlerrate:                 %.2f\" % (ER))\n",
    "print(\"Recall (TPR):               %.2f\" % (best_scores.TPR))\n",
    "print(\"Precision:                  %.2f\" % (PRECISION))\n",
    "print(\"AUC                         %.2f\" % (best_scores.AUC))\n",
    "\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(30, 10))\n",
    "\n",
    "# confusion matrix\n",
    "p_conf = plot_confusion_matrix(\n",
    "    y_test, best_prediction[\"Prediction\"], f\"{best_prediction['Name']}\", ax1)\n",
    "\n",
    "# AUC\n",
    "p_auc = plot_auc(y_test, best_prediction[\"Prediction\"],\n",
    "                 f\"Model: {best_prediction['Name']}\")\n",
    "p_auc.plot(ax2)\n",
    "ax2.set_title(\"ROC Curve\")\n",
    "\n",
    "p, r, t = metrics.precision_recall_curve(y_test, best_prediction[\"Prediction\"])\n",
    "prc = metrics.PrecisionRecallDisplay(p, r)\n",
    "prc.plot(ax3)\n",
    "ax3.set_title(\"Precision-Recall Curve\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Anwendung <a class=\"anchor\" id=\"chapter6\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das beste Modell wird auf die Realdaten (`test.csv`) angewendet. Die Realdaten wurden analog zu den Testdaten aus dem Train-Test-Split behandelt. Nur so können die Features erstellt werden, die zur Auswertung benötigt werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# reconstruct best model\n",
    "\n",
    "# build test grid\n",
    "# USE THIS FOR QUICK FINISH RUN\n",
    "# THIS SETUP EQUALS BEST PARAMS FROM GRID BELOW\n",
    "param_grid = {\n",
    "    \"n_estimators\": [50],\n",
    "    \"max_features\": [\"auto\"],\n",
    "    \"max_depth\": [8],\n",
    "    \"min_samples_leaf\": [2],\n",
    "    \"min_samples_split\": [8],\n",
    "    \"bootstrap\": [True]\n",
    "}\n",
    "\n",
    "\n",
    "# build model\n",
    "clf = RandomForestClassifier(n_estimators=50, max_features=\"auto\",\n",
    "                             max_depth=8, min_samples_leaf=2, min_samples_split=8, bootstrap=True)\n",
    "clf.fit(modelling_data_train, y_train)\n",
    "\n",
    "prediction = clf.predict(real_data_for_modelling)\n",
    "\n",
    "out = pd.DataFrame(real_data[\"id\"])\n",
    "out[\"response\"] = prediction\n",
    "out = out.to_numpy()\n",
    "\n",
    "with open(\"sample_submission.csv\", \"w\", newline=\"\") as f:\n",
    "    writer =  csv.writer(f, delimiter=\";\")\n",
    "    writer.writerows(out)\n",
    "    f.flush()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a2550543169cd2ce8a6c4f8f78a73b7b08da2472231e70d3105c33516a9ccd45"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
