{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inhaltsverzeichnis\n",
    "\n",
    "* [1. Business Understanding](#chapter1)\n",
    "    * [1.1. Projektbeschreibung](#section_1_1)\n",
    "    * [1.2. Data Dictionary des \"train\"- Datensatz](#section_1_2)\n",
    "* [2. Data Understanding](#chapter2)\n",
    "    * [2.1. Pakete importieren](#section_2_1)\n",
    "    * [2.2. Daten einlesen](#section_2_2)\n",
    "    * [2.3. Datensatz anzeigen](#section_2_3)\n",
    "    * [2.4. Spaltennamen und Datentypen](#section_2_4)\n",
    "    * [2.5. Datentypen anpassen](#section_2_5)\n",
    "        * [2.5.1 Variable Age](#section_2_5_1)\n",
    "        * [2.5.2 Variablen Driving_License, Previously_Insured und Vehicle_Damage](#section_2_5_2)\n",
    "        * [2.5.3 Variable Gender](#section_2_5_3)\n",
    "        * [2.5.4 Variable Region Code](#section_2_5_4)\n",
    "        * [2.5.5 Variable Vehicle_Age](#section_2_5_5)\n",
    "        * [2.5.6 Variable Policy_Sales_Channel](#section_2_5_6)\n",
    "        * [2.5.7 Variable Vintage](#section_2_5_7)\n",
    "        * [2.5.8 Variable Unnamed: 0](#section_2_5_8)\n",
    "        * [2.5.9 Angepasste Datentypen anzeigen](#section_2_5_9)\n",
    "    * [2.6. Deskriptive Analyse](#section_2_6)\n",
    "        * [2.6.1 Kennzahlen zur Beschreibung des Datensatz](#section_2_6_1)\n",
    "        * [2.6.2 Prüfung auf Missing Values](#section_2_6_2)\n",
    "    * [2.7. Korrelation der Variablen](#section_2_7)\n",
    "    * [2.8. Interpretation der Variablen](#section_2_8)\n",
    "        * [2.8.1 Interpretation der Variable Gender](#section_2_8_1)\n",
    "        * [2.8.2 Interpretation der Variable Age](#section_2_8_2)\n",
    "        * [2.8.3 Interpretation der Variable Driving_License](#section_2_8_3)\n",
    "        * [2.8.4 Interpretation der Variable Region_Code](#section_2_8_4)\n",
    "        * [2.8.5 Interpretation der Variable Previously_Insured](#section_2_8_5)\n",
    "        * [2.8.6 Interpretation der Variable Vehicle_Age](#section_2_8_6)\n",
    "        * [2.8.7 Interpretation der Variable Vehicle_Damage](#section_2_8_7)\n",
    "        * [2.8.8 Interpretation der Variable Annual_Premium](#section_2_8_8)\n",
    "        * [2.8.9 Interpretation der Variable Policy_Sales_Channel](#section_2_8_9)\n",
    "        * [2.8.10 Interpretation der Variable Vintage](#section_2_8_10)\n",
    "        * [2.8.11 Interpretation der Variable Response](#section_2_8_11)\n",
    "* [3. Data Preparation](#chapter3)\n",
    "    * [3.1. Ausreißer behandeln](#section_3_1)\n",
    "        * [3.1.1 Ausreißer innerhalb der Variable Age](#section_3_1_1)\n",
    "        * [3.1.2 Ausreißer innerhalb der Variable Annual_Premium](#section_3_1_2)\n",
    "    * [3.2. Analyse der nicht vorhandenen Werte](#section_3_2)\n",
    "        * [3.2.1 Löschen der 51 fehlerhaften Datensätze](#section_3_2_1)\n",
    "    * [3.3. Train/Test-Split](#section_3_3)\n",
    "    * [3.4. Imputation der fehlenden Werte](#section_3_4)\n",
    "        * [3.4.1 Ersetzung der fehlenden Werte numerischer Variablen](#section_3_4_1)\n",
    "            * [3.4.1.1 Imputation der Variable Age](#section_3_4_1_1)\n",
    "            * [3.4.1.2 Imputation der Variable Annual_Premium](#section_3_4_1_2)\n",
    "        * [3.4.2 Ersetzung der fehlenden Werte kategorialer Variablen](#section_3_4_2)\n",
    "            * [3.4.2.1 Imputation der Variable Gender](#section_3_4_2_1)\n",
    "        * [3.4.3 Überprüfung der Imputationen](#section_3_4_3)\n",
    "    * [3.5. Sampling](#section_3_5)\n",
    "        * [3.5.1. Undersampling](#section_3_5_1)\n",
    "        * [3.5.2. Oversampling](#section_3_5_2)\n",
    "        * [3.5.3. Cleanup](#section_3_5_3)\n",
    "        * [3.5.4. Under- vs. Oversampling](#section_3_5_4)\n",
    "    * [3.6. Feature Engineering](#section_3_6)\n",
    "        * [3.6.1. Altersklassen als Feature](#section_3_6_1)\n",
    "        * [3.6.2. Features durch Aggregationen, Differenzen und Verhältnisse](#section_3_6_2)\n",
    "        * [3.6.3. One-Hot-Encoding für kategoriale Variablen](#section_3_6_3)\n",
    "    * [3.7. Feature Selection](#section_3_7)\n",
    "        * [3.7.1 Feature Selection anhand von Korrelation](#section_3_7_1)\n",
    "        * [3.7.2 Feature Selection nach Feature Importance](#section_3_7_2)\n",
    "* [4. Modeling](#chapter4)\n",
    "    * [4.1. Modell: Random Forest](#section_4_1)\n",
    "    * [4.2. Modell: Neuronales Netz](#section_4_2)\n",
    "    * [4.3. Modell: Gradient Boosting](#section_4_3)\n",
    "* [5. Evaluation](#chapter5)\n",
    "    * [5.1 Bestes Modell: Random Forest](#section_5_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Business Understanding <a class=\"anchor\" id=\"chapter1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Projektbeschreibung <a class=\"anchor\" id=\"section_1_1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das Forschungsteam *ProInsurance* wird damit beauftragt, dass Projekt Cross-Selling-Prediction für den Kunden *NextGen Insurance* durchzuführen. \n",
    "Der Kunde benötigt Hilfe bei der Erstellung eines Modells, mit dem sich vorhersagen lässt, ob die Versicherungsnehmer des letzten Jahres auch an einer angebotenen Kfz-Versicherung interessiert sein werden.\n",
    "Der Kunde wünscht die Durchführung des Projektes innerhalb eines knapp kalkulierten Zeitraums.\n",
    "\n",
    "Zu diesem Zweck erhält das Forschungsteam von ihrem Auftraggeber einen Datenbestand bestehend aus > 300.000 Datensätzen. Zusätzlich ein Data Dictionary, welches eine kurze Beschreibung der Daten liefert.\n",
    "\n",
    "Die *NextGen Insurance* hat mehrere Forschungsteams beauftragt an einer Lösung zu arbeiten, damit Sie sich nach Ende der Präsentationen für die beste Alternative entscheiden können."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Data Dictionary des \"train\"- Datensatz <a class=\"anchor\" id=\"section_1_2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unser Auftraggeber die *NextGen Insurance* stellt uns folgendes Data Dictionary und damit verbunden folgende Beschreibungen der einzelnen Variablen zur Verfügung:\n",
    "\n",
    "**1 - id : Unique ID for the customer<br>\n",
    "2 - Gender : Gender of the customer<br>\n",
    "3 - Age : Age of the customer <br>\n",
    "4 - Driving_License : 0 : Customer doesn't have DL, 1 : Customer has DL<br>\n",
    "5 - Region_Code : Unique code for the region of the customer<br>\n",
    "6 - Previously_Insured : 0 : Customer doesn't have Vehicle Insurance, 1 : Customer has Vehicle Insurance<br> \n",
    "7 - Vehicle_Age : Age of the Vehicle<br>\n",
    "8 - Vehicle_Damage : 1 : Customer got his/her vehicle damaged in the past. 0 : Customer didn't get his/her vehicle damaged in the past<br>\n",
    "9 - Annual_Premium : The amount customer needs to pay as premium in the year for Health insurance<br>\n",
    "10 - Policy_Sales_Channel : Anonymized Code for the channel of outreaching to the customer ie. Different Agents, Over Mail, Over Phone, In Person, etc.<br>\n",
    "11 - Vintage : Number of Days customer has been associated with the company<br>\n",
    "12 - Response : 1 : Customer is interested, 0 : Customer is not interested**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Understanding <a class=\"anchor\" id=\"chapter2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Pakete importieren <a class=\"anchor\" id=\"section_2_1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas.api.types import CategoricalDtype\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import PrecisionRecallDisplay\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import warnings\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Daten einlesen <a class=\"anchor\" id=\"section_2_2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der Datensatz wurde von der *NextGen Insurance* bereitgestellt.<br>\n",
    "Der Datensatz wird zur Analyse eingelesen:\n",
    "- Entfernung des Trennzeichen \"$\".\n",
    "- Umwandlung von Zelleninhalten in Wahrheitswerte (Yes, yes, 1; No, no, 0).\n",
    "- Einrücken des Datensatzes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\n",
    "    \"train.csv\",\n",
    "    sep=\"$\",\n",
    "    true_values=[\"Yes\", \"yes\", \"1\"],\n",
    "    false_values=[\"No\", \"no\", \"0\"],\n",
    "    index_col=False,\n",
    "    low_memory=False,\n",
    ")\n",
    "\n",
    "real_data = pd.read_csv(\n",
    "    \"test.csv\",\n",
    "    sep=\"\\$|,\",  # this csv uses 2 different separators\n",
    "    true_values=[\"Yes\", \"yes\", \"1\"],\n",
    "    false_values=[\"No\", \"no\", \"0\"],\n",
    "    index_col=False,\n",
    "    header=None,\n",
    "    engine=\"python\"  # c engine does not support regex or multiple separators\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Datensatz Anzeigen <a class=\"anchor\" id=\"section_2_3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zur Betrachtung der Variablen aus dem Datensatz werden die ersten zwanzig Einträge angezeigt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Spaltennamen und Datentypen <a class=\"anchor\" id=\"section_2_4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um eventuelle Korrekturen vorzunehmen betrachten wir die Datentypen der im Datensatz enthaltenen Variablen.<br>\n",
    "- Die Spalten **Driving_License**, **Previously_Insured**, und **Vehicle_Damage** wurden nicht in den booleschen Datentypen gecastet. Dies ist ein Indikator dafür das diese Spalten invalide oder fehlende Werte enthalten.\n",
    "- Die Spalte **Age** wurde nicht in einen Integer oder Float gecastet, auch hier ist dies ein Indikator dafür, dass diese Spalte invalide oder fehlende Werte enthält. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Datentypen anpassen <a class=\"anchor\" id=\"section_2_5\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Die zum Pandas Modul zugehörige Funktion \".unique()\" ermöglicht die Ausgabe aller einzigartigen Werte. Dies erleichtert das Nachvollziehen von Eingabefehlern um diese zu korrigieren.\n",
    "- Der Numpy-Datentyp `int64` unterstützt keine nullable Values (NaN), deshalb wird der Pandas-Datentyp `Int64` verwendet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5.1 Variable Age <a class=\"anchor\" id=\"section_2_5_1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Die letzten Werte beinhalten Eingabefehler. Bevor der Datentyp umgewandelt werden kann müssen die zwei Punkte (..) nach den Zahlen entfernt werden. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"Age\"].unique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aus dieser Ausgabe kann man sehen, dass einige fehlerhaften Eingaben getätigt wurden (z.B. \"29..\"). Da die Werte dieser Datensätze aber inhaltlich richtig sein könnten, sollen sie behalten werden. Durch das Casten in den String-Datentyp können die fehlerhaften Sonderzeichen entfertnt werden. Aschließend wird die Variable in den gewünschten Integer-Datentypen gecastet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to string\n",
    "train[\"Age\"] = train[\"Age\"].astype(pd.StringDtype())\n",
    "\n",
    "# remove .. as this is what prevents us from propper type conversion\n",
    "train[\"Age\"] = train[\"Age\"].str.replace(\".\", \"\")\n",
    "\n",
    "# convert to int (no decimals observed in train data)\n",
    "train[\"Age\"] = train[\"Age\"].astype(\"Int64\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5.2 Variablen Driving_License, Previously_Insured und Vehicle_Damage <a class=\"anchor\" id=\"section_2_5_2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Die Spalten beinhalten fehlende Werte (NaN). Damit die fehlenden Werte ordnungsgemäß behandelt werden können, müssen die Spalten in den nullable Boolean Type gecastet werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Driving_License:\", train[\"Driving_License\"].unique())\n",
    "print(\"Previously_Insured:\", train[\"Previously_Insured\"].unique())\n",
    "print(\"Vehicle_Damage:\", train[\"Vehicle_Damage\"].unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Ausgabe weist darauf hin, dass diese Variablen richtig einglesen werden konnten und es keine (inhaltlich) falschen Ausprägungen gibt. Es gibt nur `True`, `False` und fehlende Werte. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert each column\n",
    "train[\"Driving_License\"] = train[\"Driving_License\"].astype(pd.BooleanDtype())\n",
    "train[\"Previously_Insured\"] = train[\"Previously_Insured\"].astype(\n",
    "    pd.BooleanDtype())\n",
    "train[\"Vehicle_Damage\"] = train[\"Vehicle_Damage\"].astype(pd.BooleanDtype())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5.3 Variable Gender <a class=\"anchor\" id=\"section_2_5_3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"Gender\"].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"Gender\"] = train[\"Gender\"].astype(pd.CategoricalDtype())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5.4 Variable Region Code <a class=\"anchor\" id=\"section_2_5_4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Der letzte Werte beinhaltet einen Eingabefehler. Bevor der Datentyp umgewandelt werden kann muss nach der 41.0 die zwei Rautezeichen (##) entfernt werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"Region_Code\"].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to string\n",
    "train[\"Region_Code\"] = train[\"Region_Code\"].astype(pd.StringDtype())\n",
    "\n",
    "# remove ## as this is what prevents us from propper type conversion\n",
    "train[\"Region_Code\"] = train[\"Region_Code\"].str.replace(\"#\", \"\")\n",
    "\n",
    "# convert to category as the region codes are similar to postal codes and have no order\n",
    "train[\"Region_Code\"] = train[\"Region_Code\"].astype(pd.CategoricalDtype())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5.5 Variable Vehicle_Age <a class=\"anchor\" id=\"section_2_5_5\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"Vehicle_Age\"].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no cleanup required\n",
    "train[\"Vehicle_Age\"] = train[\"Vehicle_Age\"].astype(pd.CategoricalDtype())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5.6 Variable Policy_Sales_Channel <a class=\"anchor\" id=\"section_2_5_6\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ein Wert beinhaltet einen Eingabefehler. Bevor der Datentyp umgewandelt werden kann muss nach der 26.0 die zwei Rautezeichen (##) entfernt werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"Policy_Sales_Channel\"].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove ## as this is what prevents us from propper type conversion\n",
    "train[\"Policy_Sales_Channel\"] = train[\"Policy_Sales_Channel\"].str.replace(\n",
    "    \"#\", \"\")\n",
    "\n",
    "train[\"Policy_Sales_Channel\"] = train[\"Policy_Sales_Channel\"].astype(\n",
    "    pd.CategoricalDtype()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5.7 Variable Vintage <a class=\"anchor\" id=\"section_2_5_7\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ein Wert beinhaltet einen Eingabefehler. Bevor der Datentyp umgewandelt werden kann muss nach der 81 die zwei Rautezeichen (##) entfernt werden.\n",
    "- Der Numpy-Datentyp `int64` unterstützt keine nullable Values (NaN), deshalb wird der Pandas-Datentyp `Int64` verwendet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"Vintage\"].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to string\n",
    "train[\"Vintage\"] = train[\"Vintage\"].astype(pd.StringDtype())\n",
    "\n",
    "# remove ## as this is what prevents us from propper type conversion\n",
    "train[\"Vintage\"] = train[\"Vintage\"].str.replace(\"#\", \"\")\n",
    "\n",
    "# convert to category as the region codes are similar to postal codes and have no order\n",
    "train[\"Vintage\"] = train[\"Vintage\"].astype(\"Int64\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5.8 Variable Unnamed: 0 <a class=\"anchor\" id=\"section_2_5_8\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Die Spalte Unnamed: 0 hat keine Information und wird entfernt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(\"Unnamed: 0\", axis=\"columns\", inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5.9 Angepasste Datentypen anzeigen <a class=\"anchor\" id=\"section_2_5_9\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 Deskriptive Analyse <a class=\"anchor\" id=\"section_2_6\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6.1 Kennzahlen zur Beschreibung des Datensatz <a class=\"anchor\" id=\"section_2_6_1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Folgende statistische Kennzahlen werden verwenden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.describe(include=\"all\").transpose()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auffälligkeiten einzelner Variablen anhand der statistischen Kennzahlen werden im nachfolgenden näher erläutert:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| **Variable**          | **Beschreibung**  | \n",
    "|          :-           |         :-        |\n",
    "| ID                    |- Beginnt bei 1 und endet bei 380.999 <br> - weißt keine Auffälligkeiten auf| \n",
    "| Gender                |- Das Geschlecht \"Male\" kommt am häufigsten vor mit 205.447 Datensätzen <br> - 2 verschiedene Ausprägungen <br> - 1051 Datensätze fehlen (Vergleich von 379.948 zu 380.999 Datensätzen) | \n",
    "| Age                   |- min. = 20 Jahre alt nicht auffällig <br> - Im Durchschnitt 39 Jahre alt <br> - max. = 205 Jahre alt <br> - 10.892 Datensätze fehlen (Vergleich von 370.107 zu 380.999 Datensätzen) | \n",
    "| Driving_License       |- Mehr Personen haben keinen Führerschein mit 206.635 Datensätzen als das Sie einen Führerschein haben <br> - 2 verschiedene Ausprägungen <br> - 51 Datensätze fehlen (Vergleich von 380.948 zu 380.999 Datensätzen) | \n",
    "| Region_Code           |- Die PLZ 28.0 kommt am häufigsten vor mit 106.372 Datensätzen <br> - 53 verschiedene Ausprägungen | \n",
    "| Previously_Insured    |- Mehr Personen haben keine Versicherung mit 206.635 Datensätzen als das Sie eine Versicherung haben <br> - 2 verschiedene Ausprägungen <br> - 51 Datensätze fehlen (Vergleich von 380.948 zu 380.999 Datensätzen) | \n",
    "| Vehicle_Age           |- Das Alter des Fahrzeugs beläuft sich auf bei den meisten Personen auf 1-2 Jahre mit 380.948 Datensätzen <br> - 3 verschiedene Ausprägungen <br> - 51 Datensätze fehlen (Vergleich von 380.948 zu 380.999 Datensätzen) | \n",
    "| Vehicle_Damage        |- Bei mehr Personen, 192.328 Datensätze, ist es zu einem Schadensfall gekommen <br> - 2 verschiedene Ausprägungen <br> - 51 Datensätze fehlen (Vergleich von 380.948 zu 380.999 Datensätzen) | \n",
    "| Annual_Premium        |- min. = -9997.0€ auffällig, da der Betrag den die Kunden zahlen müssen nicht negativ sein kann. <br> - Im Durchschnitt 30.527.71€ <br> - max. = 540.165€ auffällig, da der Betrag deutlich zu hoch ist | \n",
    "| Policy_Sales_Channel  |- 155 verschiedene Ausprägungen | \n",
    "| Vintage               |- min. = 10 Tage <br> - Im Durchschnitt 154 Tage <br> - max. = 299 Tage <br> - 51 Datensätze fehlen (Vergleich von 380.948 zu 380.999 Datensätzen) | \n",
    "| Response              |- Mehr Personen sind nicht interessiert mit 334.297\tDatensätzen <br> - 2 verschiedene Ausprägungen | \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6.2 Prüfung auf Missing Values <a class=\"anchor\" id=\"section_2_6_2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die zum Pandas Modul zugehörige Funktion \".isna()\" ermöglicht die Ausgabe aller Missing Values (NA Values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.isna().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Überprüfung auf missing Values zeigt, dass vor allem für die Variable `Age` Werte imputiert werden sollten. In der Spalte `Gender` fehlen rund 1000 Werte. Weiter sieht man, dass in den Spalten `Driving_License`, `Previously_Insured`, `Vehicle_Age`, `Vehicle_Damage` und `Vintage` genau 51 Werte fehlen. Das deutet darauf hin, dass diese missing Values zu den selben Datensätzen gehören, was nachfolgend überprüft wird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look for the 51\n",
    "# len(train.loc[train[\"Vintage\"].isna()]) # => 51 entities\n",
    "# len(train.loc[train[\"Vintage\"].isna() & train[\"Vehicle_Damage\"].isna()]) # => 51 entities\n",
    "# len(train.loc[train[\"Vintage\"].isna() & train[\"Vehicle_Damage\"].isna() & train[\"Vehicle_Age\"].isna()]) # => 51 entities\n",
    "# len(train.loc[train[\"Vintage\"].isna() & train[\"Vehicle_Damage\"].isna() & train[\"Vehicle_Age\"].isna() & train[\"Previously_Insured\"].isna()]) # => 51 entities\n",
    "# len(train.loc[train[\"Vintage\"].isna() & train[\"Vehicle_Damage\"].isna() & train[\"Vehicle_Age\"].isna() & train[\"Previously_Insured\"].isna() & train[\"Driving_License\"].isna()]) # => 51 entities\n",
    "bad_train = train.loc[\n",
    "    train[\"Vintage\"].isna()\n",
    "    & train[\"Vehicle_Damage\"].isna()\n",
    "    & train[\"Vehicle_Age\"].isna()\n",
    "    & train[\"Previously_Insured\"].isna()\n",
    "    & train[\"Driving_License\"].isna()\n",
    "]\n",
    "print(\n",
    "    f\"Data sets with Vintage, Vehicle_Damage, Vehicle_Age, Previously_Insured and Driving_License missing: {len(bad_train)}\")\n",
    "# bad_train.groupby(\"Region_Code\").count().sort_values(\"id\", ascending=False)\n",
    "# bad_train.groupby(\"Policy_Sales_Channel\").count().sort_values(\"id\", ascending=False)\n",
    "# => !!! There are 51 entities that make up most of the missing values.\n",
    "# maybe we simply remove them\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mithilfe einer Und-Verbindung wird geprüft, ob die missing Values alle von den selben Datensätzen stammen.\n",
    "Die Annahme wurde bestätigt. Der Test ergab 51 Treffer.\n",
    "Da nur wenige Informationen zu diesen Datensätzen verfügbar sind und eine Imputation daher nur eingeschränkt möglich ist, werden die Datensätze im Verlauf der Data Preparation entfernt. Hierdurch wird die Modellgüte nicht ausschlaggebend beeinträchtigt, da 51 Datensätze in der Gesamtheit der Daten (ca. 390.000 Datensätze) keinen signifikanten Einfluss haben."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nachfolgend wurde überprüft, woher diese fehlerhaften Datensätze kommen. Unter verdacht standen die Vertriebskanäle `Policy_Sales_Channel` und `Region_Code` was auf fehlerhafte Eingaben in einer speziellen Filiale zurückzuführen wäre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cast Region_Code to Category using only the options that appear in the data frame\n",
    "bad_train[\"Region_Code\"] = bad_train[\"Region_Code\"].astype(\n",
    "    pd.CategoricalDtype(bad_train[\"Region_Code\"].unique())\n",
    ")\n",
    "\n",
    "sns.catplot(\n",
    "    data=bad_train, x=\"Region_Code\", kind=\"count\", height=10, aspect=2 / 1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_train_grpd = bad_train.groupby(\"Policy_Sales_Channel\").count()\n",
    "\n",
    "bad_train_grpd = bad_train_grpd.loc[bad_train_grpd[\"id\"] > 0]\n",
    "\n",
    "# reset index to re-include groupby counts (this resets all dtypes)\n",
    "bad_train_grpd = bad_train_grpd.reset_index()\n",
    "\n",
    "# reset PSC to categorial dtype\n",
    "bad_train_grpd[\"Policy_Sales_Channel\"] = bad_train_grpd[\"Policy_Sales_Channel\"].astype(\n",
    "    pd.CategoricalDtype(bad_train_grpd[\"Policy_Sales_Channel\"].unique())\n",
    ")\n",
    "\n",
    "sns.catplot(\n",
    "    data=bad_train_grpd,\n",
    "    x=\"Policy_Sales_Channel\",\n",
    "    y=\"id\",\n",
    "    height=10,\n",
    "    aspect=2 / 1,\n",
    "    kind=\"bar\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es gibt zwar Hinweise darauf, dass manche Regionen und Sales Channel fehleranfälliger sind als andere, der Verdacht, dass die fehlerhaften Datensätze auf eine Datenquelle zurückzuführen sind, konnte nicht bestätigt werden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.7 Korrelation der Variablen <a class=\"anchor\" id=\"section_2_7\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove id from correlation matrix as it does not provide any usefull information\n",
    "def correlation_matrix_table(data):\n",
    "    correlation = data.corr()\n",
    "    return correlation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix_table(train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation_matrix(data, x, y, show_labels, col_map, method=\"pearson\"):\n",
    "    corr = data.corr(method=method)\n",
    "    plt.figure(figsize=(x, y))\n",
    "    sns.heatmap(\n",
    "        corr, annot=show_labels, linewidths=1, linecolor=\"black\", cmap=col_map, vmin=-1, vmax=1\n",
    "    )\n",
    "    plt.title(f\"Korrelationsmatrix ({method})\", fontsize=18, weight=\"bold\")\n",
    "\n",
    "\n",
    "correlation_matrix(train, 12, 6, True, \"seismic\", \"pearson\")\n",
    "correlation_matrix(train, 12, 6, True, \"seismic\", \"spearman\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Es fällt auf, dass `Previously_Insured` und `Driving_License` die höchste Korrelation, undzwar von 1, aufweisen. Das liegt daran, dass jeder KFZ-Besitzer eine KFZ-Versicherung haben muss sofern das KFZ angemeldet ist.\n",
    "- Die geringste Korrelation weisen die Variablen (`Driving_License` und `Vintage`), sowie (`Previously_Insured` und `Vintage`) auf, mit einer Korrelation von 0,0024.\n",
    "- Hohe negative Korrelation zwischen `Vehicle_Damage` und `Previously_Insured`\n",
    "- Korrelation von 0,35 zwischen `Vehicle_Damage` und `Response`. Wenn ich in der Vergangenheit einen Schadensfall hatte, bin ich eher dazu geneigt eine Versicherung abzuschließen.\n",
    "- Generell scheint `Vintage` keine nennenswerte Korrelation aufzuweisen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'In wie vielen Fällen ist Driving_License != Previously_Insured?\\n -> {len(train.loc[train[\"Driving_License\"] != train[\"Previously_Insured\"]])}')\n",
    "# Observation was confirmed!\n",
    "# Columns Driving_License and Previously_Insured are equals!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beobachtung:\n",
    "- Die Spalte `Driving_License` und `Previously_Insured` haben exakt die gleichen Daten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.8 Interpretation der Variablen <a class=\"anchor\" id=\"section_2_8\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.8.1 Interpretation der Variable Gender <a class=\"anchor\" id=\"section_2_8_1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Variable Gender beschreibt das Geschlecht der Versicherungsnehmer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 10))\n",
    "colors = sns.color_palette('pastel')[0:2]\n",
    "l = [\"True\", \"False\"]\n",
    "\n",
    "male = train.loc[train[\"Gender\"] == \"Male\"]\n",
    "\n",
    "# MALE PIE CHART\n",
    "d_m = [len(male.loc[male[\"Response\"] == True]),\n",
    "       len(male.loc[male[\"Response\"] == False])]\n",
    "ax1.pie(d_m, labels=l, colors=colors, autopct='%.0f%%')\n",
    "ax1.set_title(\"Male Responses\")\n",
    "\n",
    "# FEMALE PIE CHART\n",
    "female = train.loc[train[\"Gender\"] == \"Female\"]\n",
    "d_f = [len(female.loc[female[\"Response\"] == True]),\n",
    "       len(female.loc[female[\"Response\"] == False])]\n",
    "ax2.pie(d_f, labels=l, colors=colors, autopct='%.0f%%')\n",
    "ax2.set_title(\"Female Responses\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beobachtungen:\n",
    "- Keine signifikanten unterschiede im Interesse an KFZ-Versicherungen bei Männern und Frauen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.8.2 Interpretation der Variable Age <a class=\"anchor\" id=\"section_2_8_2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Variable Age beschreibt das Alter der Versicherungsnehmer.\n",
    "\n",
    "Erwartungen:\n",
    "- Plotten der Altersverteilung gibt Rückschlüsse zur Datenqualität bzw. zur Datenherkunft\n",
    "    - Es ist eine pyramiedenförmige Altersverteilung zu erwarten, da der Datensatz aus Indien stammt\n",
    "- Ältere und damit erfahrenere Kunden sind eher an einer Versicherung interessiert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={\"figure.figsize\": (25, 10)})\n",
    "histplot_age = sns.histplot(train, x=\"Age\", binwidth=5)\n",
    "histplot_age.set_title(\"Betrachtung aller Daten\", fontsize=30, weight='bold')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beobachtungen:\n",
    "- Es gibt unrealisitsch hohe Alterswerte\n",
    "- Aus der Fallbeschreibung konnte entnommen werden, dass es sich um einen Datensatz aus Indien handelt. Es wurde von der Währung Rs (Indische Rupie) gesprochen. Die Altersverteilung kommt der pyramidenförmigen demografischen Verteilung von Indien deutlich näher als der Urnenform von Deutschland. Die geplottete Altersverteilung bestätigt zusätzlich die Datenherkunft und Datengüte, da die erwartete Verteilung, bis auf einen Sattelpunkt bei 30-40, ausgegeben wurde.\n",
    "- Es gibt keine Werte unter 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={\"figure.figsize\": (25, 10)})\n",
    "boxplot = sns.boxplot(data=train, y=\"Gender\", x=\"Age\", orient=\"horizontal\")\n",
    "boxplot.set_xlabel(\"Age\", fontsize=20, weight='bold')\n",
    "boxplot.set_ylabel(\"Gender\", fontsize=20, weight='bold')\n",
    "boxplot.set_title(\"Boxplot der Variable Age in Zusammenhang mit Gender.\" +\n",
    "                  \"\\n\", fontsize=30, weight='bold')\n",
    "plt.tick_params(axis=\"both\", labelsize=18)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Durchschnittsalter von Männern: {train.loc[train[\"Gender\"] == \"Male\"].mean()[\"Age\"]}')\n",
    "print(f'Durchschnittsalter von Frauen: {train.loc[train[\"Gender\"] == \"Female\"].mean()[\"Age\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beobachtungen:\n",
    "- Männer sind im Schnitt älter als Frauen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alle Datensätze bei denen das Alter über 100 Jahren liegt, sind nicht realitätsnah und werden genauer betrachtet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[(train.Age >= 100)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Daten mit unrealistisch hohen Alterswerten sind möglicherweise alte Datensätze, die nicht gepflegt bzw. im Fall der Vertragsauflösung nicht gelöscht wurden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.8.3 Interpretation der Variable Driving_License <a class=\"anchor\" id=\"section_2_8_3\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Variable `Driving_License` beschreibt ob ein Versicherungsnehmer einen Führerschein besitzt.\n",
    "\n",
    "Erwartungen:\n",
    "- Kunden, die keinen Führerschein besitzen, haben keine Verwendung für eine KFZ-Versicherung\n",
    "    - Außer sie planen kurzfristig den Erwerb eines Führerscheins\n",
    "- Führerscheinbesitzer haben möglicherweise schon eine KFZ-Versicherung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 10))\n",
    "colors = sns.color_palette('pastel')[0:4]\n",
    "\n",
    "dl_true = train.loc[train[\"Driving_License\"] == True]\n",
    "dl_false=train.loc[train[\"Driving_License\"] == False]\n",
    "\n",
    "# dl_true PIE CHART\n",
    "d_true = [len(dl_true.loc[dl_true[\"Response\"] == True]),\n",
    "       len(dl_true.loc[dl_true[\"Response\"] == False])]\n",
    "l_true = [\"Response: True\", \"Response: False\"]\n",
    "ax1.pie(d_true, labels=l_true, colors=colors, autopct='%.0f%%')\n",
    "ax1.set_title(\"Driving License Owner\")\n",
    "\n",
    "# dl_false PIE CHART\n",
    "d_false = [len(dl_false.loc[dl_false[\"Response\"] == True]),\n",
    "       len(dl_false.loc[dl_false[\"Response\"] == False])]\n",
    "l_false = l_true\n",
    "\n",
    "ax2.pie(d_false, labels=l_false, colors=colors, autopct='%.0f%%')\n",
    "ax2.set_title(\"Not Driving License Owner\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beobachtungen:\n",
    "- Nahezu kein Führerscheinbesitzer ist an einer KFZ-Versicherung interessiert. Möglicherweise weil Führerscheinbesitzer auch ein Auto und deswegen auch eine KFZ-Versicherung besitzen\n",
    "- Fast 1/4 aller Führerscheinlosen haben Interesse an einer KFZ-Versicherung bekundet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.8.4 Interpretation der Variable Region_Code <a class=\"anchor\" id=\"section_2_8_4\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Variable `Region_Code` beschreibt den Wohnort der Kunden. Es handelt sich um eine kategoriale Variable mit 53 Ausprägungen. Sie kann analog zur Postleitzahl verstanden werden.\n",
    "\n",
    "Erwartungen:\n",
    "- In einer guten Wohngegend können sich die Versicherungsnehmer eher eine KFZ-Versicherung leisten oder besitzen ein teureres Auto, für das sich eine Versicherung lohnt\n",
    "- Analog dazu verzichten Kunden aus ärmeren Regionen aus finanziellen Gründen eher auf eine KFZ-Versicherung\n",
    "- Bestimmte Verkaufskanäle konzentrieren sich auf bestimmte Regionen, andere agieren flächendeckend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train[\"Region_Code\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_data = train.groupby(\"Region_Code\").count()\n",
    "\n",
    "p_data = p_data.loc[p_data[\"id\"] > 0]\n",
    "\n",
    "# reset index to re-include groupby counts (this resets all dtypes)\n",
    "p_data = p_data.reset_index()\n",
    "\n",
    "# reset PSC to categorial dtype\n",
    "p_data[\"Region_Code\"] = p_data[\"Region_Code\"].astype(\n",
    "    pd.CategoricalDtype(p_data[\"Region_Code\"].unique())\n",
    ")\n",
    "\n",
    "plot = sns.catplot(\n",
    "    data=p_data,\n",
    "    x=\"Region_Code\",\n",
    "    y=\"id\",\n",
    "    height=10,\n",
    "    aspect=2 / 1,\n",
    "    kind=\"bar\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot = sns.catplot(\n",
    "    data=train,\n",
    "    x=\"Region_Code\",\n",
    "    y=\"Annual_Premium\",\n",
    "    height=10,\n",
    "    aspect=2 / 1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.8.5 Interpretation der Variable Previously_Insured <a class=\"anchor\" id=\"section_2_8_5\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 10))\n",
    "colors = sns.color_palette('pastel')[0:2]\n",
    "\n",
    "d_1 = train.loc[train[\"Previously_Insured\"] == True]\n",
    "d_2 = train.loc[train[\"Previously_Insured\"] == False]\n",
    "\n",
    "l = [\"Response: True\", \"Response: False\"]\n",
    "\n",
    "p_1 = [len(d_1.loc[d_1[\"Response\"] == True]),\n",
    "       len(d_1.loc[d_1[\"Response\"] == False])]\n",
    "ax1.pie(p_1, labels=l, colors=colors, autopct='%.0f%%')\n",
    "ax1.set_title(\"Previously insured\")\n",
    "\n",
    "p_2 = [len(d_2.loc[d_2[\"Response\"] == True]),\n",
    "       len(d_2.loc[d_2[\"Response\"] == False])]\n",
    "ax2.pie(p_2, labels=l, colors=colors, autopct='%.0f%%')\n",
    "ax2.set_title(\"Not previously insured\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.8.6 Interpretation der Variable Vehicle_Age <a class=\"anchor\" id=\"section_2_8_6\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Variable `Vehicle_Age` beschreibt das Alter des Fahrzeugs. Es ist eine kategoriale Variable mit den drei Ausprägungen `< 1 Year`, `1-2 Year` und `> 2 Years`.\n",
    "\n",
    "Erwartungen:\n",
    "- Besitzer neuer KFZs wollen ihre Neuanschaffung eher versichern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(20, 10))\n",
    "colors = sns.color_palette('pastel')[0:2]\n",
    "\n",
    "dl_1 = train.loc[train[\"Vehicle_Age\"] == \"< 1 Year\"]\n",
    "dl_2 = train.loc[train[\"Vehicle_Age\"] == \"1-2 Year\"]\n",
    "dl_3 = train.loc[train[\"Vehicle_Age\"] == \"> 2 Years\"]\n",
    "\n",
    "l = [\"Response: True\", \"Response: False\"]\n",
    "# dl_1 PIE CHART\n",
    "d_1 = [len(dl_1.loc[dl_1[\"Response\"] == True]),\n",
    "       len(dl_1.loc[dl_1[\"Response\"] == False])]\n",
    "ax1.pie(d_1, labels=l, colors=colors, autopct='%.0f%%')\n",
    "ax1.set_title(\"Vehicle_Age < 1 Year\")\n",
    "\n",
    "# dl_2 PIE CHART\n",
    "d_2 = [len(dl_2.loc[dl_2[\"Response\"] == True]),\n",
    "       len(dl_2.loc[dl_2[\"Response\"] == False])]\n",
    "ax2.pie(d_2, labels=l, colors=colors, autopct='%.0f%%')\n",
    "ax2.set_title(\"Vehicle_Age 1-2 Year\")\n",
    "\n",
    "# dl_3 PIE CHART\n",
    "d_3 = [len(dl_3.loc[dl_3[\"Response\"] == True]),\n",
    "       len(dl_3.loc[dl_3[\"Response\"] == False])]\n",
    "ax3.pie(d_3, labels=l, colors=colors, autopct='%.0f%%')\n",
    "ax3.set_title(\"Vehicle_Age > 2 Years\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beobachtungen:\n",
    "- Das Gegenteil der Erwarteten Verteilung ist der Fall: Je älter ein Auto ist, desto eher ist der Besitzer an einer Versicherung interessiert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.8.7 Interpretation der Variable Vehicle_Damage <a class=\"anchor\" id=\"section_2_8_7\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Variable `Vehicle_Damage` beschreibt, ob es an einem Fahrzeug schonmal einen Schadensfall gab.\n",
    "\n",
    "Erwartung:\n",
    "- Jemand, der bereits einen Schaden hatte, hat aus der Erfahrung gelernt, dass es Vorteilhaft sein kann eine Versicherung zu haben"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 10))\n",
    "colors = sns.color_palette('pastel')[0:2]\n",
    "\n",
    "dl_1 = train.loc[train[\"Vehicle_Damage\"] ==True]\n",
    "dl_2 = train.loc[train[\"Vehicle_Damage\"] == False]\n",
    "\n",
    "l = [\"Response: True\", \"Response: False\"]\n",
    "# dl_1 PIE CHART\n",
    "d_1 = [len(dl_1.loc[dl_1[\"Response\"] == True]),\n",
    "       len(dl_1.loc[dl_1[\"Response\"] == False])]\n",
    "ax1.pie(d_1, labels=l, colors=colors, autopct='%.0f%%')\n",
    "ax1.set_title(\"Vehicle_Damage: True\")\n",
    "\n",
    "# dl_2 PIE CHART\n",
    "d_2 = [len(dl_2.loc[dl_2[\"Response\"] == True]),\n",
    "       len(dl_2.loc[dl_2[\"Response\"] == False])]\n",
    "ax2.pie(d_2, labels=l, colors=colors, autopct='%.0f%%')\n",
    "ax2.set_title(\"Vehicle_Damage: False\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beobachtung:\n",
    "- Genau wie erwartet, gibt es einen deutlichen Zusammenhang zwischen bereits erlittenem Schadensfall und dem Interesse an einer KFZ-Versicherung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.8.8 Interpretation der Variable Annual_Premium <a class=\"anchor\" id=\"section_2_8_8\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Variable `Annual_Premium` beschreibt den jährlichen Versicherungsbeitrag (der Krankenversicherung) des Kunden.\n",
    "\n",
    "Erwartungen:\n",
    "- Ein Kunde, der mit seiner Krankenversicherung zufrieden ist, etwa weil der Beitrag niedrig ist, ist eher verleitet, bei der selben Versicherung ein weiteres Produkt zu kaufen\n",
    "- Das `Annual_Premium` ist abhängig vom Alter des Versicherten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"Annual_Premium\"].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(train.loc[train[\"Annual_Premium\"].isna()])\n",
    "train[\"Annual_Premium\"].isna().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Der durchschnittliche `Annual_Premium` liegt bei rund 30.500\n",
    "- Das Minimun ist negativ, was auf (mindestens) einen fehlerhaften Wert hindeutet\n",
    "- Es gibt 100 missing Values\n",
    "- Das Maximum liegt gbei ca. 540.000 (dem 17 fachen des Durchschnitts). Entweder handelt es sich um ein teures Luxusauto, oder um einen Fehler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={\"figure.figsize\": (20, 10)})\n",
    "\n",
    "histplot_annual_premium = sns.histplot(\n",
    "    train, x=\"Annual_Premium\", binwidth=2500)\n",
    "histplot_annual_premium.set_title(\n",
    "    \"Übersicht über alle Werte\", fontsize=30, weight='bold')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beobachtungen:\n",
    "- Es gibt zwei Arten von Ausreißern. es gibt eine deutliche Konzentration (~65.000) bei einem Wert, außerhalb der eigentlichen Verteilung\n",
    "- Es gibt wenige besonders hohe Werte (>100.000)\n",
    "- Die Skala für `Annual_Premium` beginnt nicht bei 0, also gibt es invalide negative Werte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count values < 3.000\n",
    "print(\n",
    "    f\"Anzahl konzentrierter Werte bei rund 2.500: {len(train.loc[(train['Annual_Premium'] > 0) & (train['Annual_Premium'] < 3000)])}\")\n",
    "\n",
    "# count values > 100.000 -> 773\n",
    "print(\n",
    "    f\"Anzahl besonders hoher Werte für Annual_Premium: {len(train.loc[train['Annual_Premium'] > 100000])}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Theorie: Das `Annual_Premium` ist abhängig vom Alter des Versicherten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={\"figure.figsize\": (20, 10)})\n",
    "x = sns.relplot(data=train, x=\"Age\", y=\"Annual_Premium\",\n",
    "                col=\"Response\", hue=\"Vehicle_Age\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beobachtung:\n",
    "- Die Theorie, dass ältere Versicherungsnehmer höhere Beiträge zahlen scheint nicht zu stimmen. Es hätte ein Abwärtstrend zu sehen sein müssen.\n",
    "- Vor allem in der Gruppe der unter einem Jahr alten Autos kann man sehen, dass die Besitzer fast ausschließlich Versicherungen abgeschlossen haben, wenn sie bereits einen günstigen KV-Tarif hatten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={\"figure.figsize\": (20, 10)})\n",
    "\n",
    "plot_data = train.loc[(train[\"Annual_Premium\"] > 0) &\n",
    "                      (train[\"Annual_Premium\"] < 70000)]\n",
    "\n",
    "histplot_annual_premium = sns.histplot(\n",
    "    plot_data, x=\"Annual_Premium\", binwidth=1000)\n",
    "histplot_annual_premium.set_title(\n",
    "    \"Betrachtung des validen/realistischen Datenbereichs\", fontsize=30, weight='bold')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beobachtungen:\n",
    "- rechtsschiefe Verteilung um 30.000\n",
    "- Ausreißer bei rund 2.000. Das ist möglicherweise ein besonderer Versicherungstarif, z.B. ein pauschaler Tarif."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={\"figure.figsize\": (30, 10)})\n",
    "boxplot = sns.boxplot(data=train, y=\"Gender\",\n",
    "                      x=\"Annual_Premium\", orient=\"horizontal\")\n",
    "boxplot.set_xlabel(\"Annual_Premium\", fontsize=20, weight='bold')\n",
    "boxplot.set_ylabel(\"Gender\", fontsize=20, weight='bold')\n",
    "\n",
    "boxplot.set_xlim(0, 550000)\n",
    "boxplot.set_xticks(range(0, 550000, 25000))\n",
    "\n",
    "boxplot.set_title(\"Boxplot der Variable Annual_Premium in Zusammenhang mit Gender.\" +\n",
    "                  \"\\n\", fontsize=30, weight='bold')\n",
    "plt.tick_params(axis=\"both\", labelsize=18)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.8.9 Interpretation der Variable Policy_Sales_Channel <a class=\"anchor\" id=\"section_2_8_9\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Variable `Policy_Sales_Channel` beschreibt den Verkaufskanal, über den die bestehende Krankenversicherung abgeschlossen wurde.\n",
    "\n",
    "Erwartungen:\n",
    "- Bei bestimmten Verkaufskanälen gibt es ein höheres Interesse an KFZ-Versicherungen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = sns.catplot(x=\"Policy_Sales_Channel\",y=\"Response\", data=train, ci=None, aspect=4, kind=\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beobachtungen:\n",
    "- Es gibt deutliche Unterschiede zwischen den Vertriebskanälen\n",
    "    - Allerdings haben Vertriebskanäle mit wenigen Kunden extremere Werte, da die Stichprobengröße kleiner ist\n",
    "\n",
    "Es müssen weitere Untersuchungen von prozentualer positiver Rückmeldung und Anzahl der Kunden für jeden Vertriebskanal vorgenommen werden.\n",
    "\n",
    "Nachfolgend werden die Daten pro Vertriebskanal zusammengefasst, um deren Positivrückmeldungsrate im Vergleich zur Anzahl der betreuten Kunden einordnen zu können."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get percentage of True response\n",
    "percent =  train.groupby(\"Policy_Sales_Channel\").sum() / train.groupby(\"Policy_Sales_Channel\").count()\n",
    "percent = percent.reset_index()\n",
    "percent[\"Policy_Sales_Channel\"] = percent[\"Policy_Sales_Channel\"].astype(pd.CategoricalDtype(percent[\"Policy_Sales_Channel\"].unique()))\n",
    "\n",
    "# get count of all response\n",
    "count = train.groupby(\"Policy_Sales_Channel\").count()\n",
    "count = count.reset_index()\n",
    "count[\"Policy_Sales_Channel\"] = count[\"Policy_Sales_Channel\"].astype(pd.CategoricalDtype(count[\"Policy_Sales_Channel\"].unique()))\n",
    "\n",
    "# join results\n",
    "combined = pd.merge(percent, count, how=\"inner\", on=[\"Policy_Sales_Channel\",\"Policy_Sales_Channel\"], suffixes=[\"_percent\", \"_count\"])\n",
    "combined = combined.sort_values(\"Response_percent\", ascending=False)\n",
    "\n",
    "# trim useless columns\n",
    "combined = combined[[\"Policy_Sales_Channel\", \"Response_percent\", \"Response_count\"]]\n",
    "\n",
    "no_positive_responses = combined.loc[combined[\"Response_percent\"] == 0]\n",
    "combined\n",
    "# remove sales channels with no customers\n",
    "combined = combined.loc[combined[\"Response_count\"] > 0]\n",
    "combined\n",
    "p = sns.regplot(x=\"Response_count\", y=\"Response_percent\" ,data=combined)\n",
    "p.set_xscale(\"log\")\n",
    "p.set_xlabel(\"Anzahl der Kunden (logarithmische Skala zur besseren Darstellung\")\n",
    "p.set_ylabel(\"Prozentualer Anteil der True Responses\")\n",
    "p.set_title(\"Erfolgsquote und Anzahl der Kunden pro Vertriebskanal (1 Punkt je Kanal)\", size=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Anzahl der Vertriebskanäle ohne positive Response: {len(no_positive_responses)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beobachtungen:\n",
    "- Die Vertriebskanäle sind unabhängig von ihrer Größe mehr oder weniger erfolgreich\n",
    "- Es gibt große Abweichungen vom Mittelwert unabhängig von der Anzahl der Kunden\n",
    "- Wie erwartet haben die Vertriebskanäle mit 100% Positivrückmeldungsquote nur einen einzigen Kunden\n",
    "    - Dennoch gibt es auch Vertriebskanäle mit über 1000 Kunden und rund 33% Positivquote\n",
    "- Die meisten Vertriebskanäle haben weniger als 1000 Kunden\n",
    "- Es gibt 34 Vertriebskanäle ohne positive Rückmeldung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.8.10 Interpretation der Variable Vintage <a class=\"anchor\" id=\"section_2_8_10\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Variable `Vintage` beschreibt die Dauer des Versicherungsverhältnisses im letzten Jahr.\n",
    "\n",
    "Erwartung:\n",
    "- Besondere Salesevents oder Aktionen mit limitierter Laufzeit können als Peak erkannt werden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = sns.histplot(\n",
    "    data=train,\n",
    "    x=\"Vintage\",\n",
    "    binwidth=7 # 7 days = 1 week\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Look at cheap contracts\n",
    "d = train.loc[(train[\"Annual_Premium\"] < 5000) & (train[\"Annual_Premium\"] > 0)]\n",
    "# d = d.loc[d[\"Response\"] == True]\n",
    "sns.scatterplot(data=d, x=\"Vintage\", y=\"Annual_Premium\", hue=\"Response\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beobachtungen:\n",
    "- Beinahe Gleichverteilung von `Vintage`\n",
    "    - Es scheinen keine Verkaufsaktionen stattgefunden zu haben, oder sie sind ohne Erfolg geblieben\n",
    "- Es gibt keine besonderen Zeiträume, in denen der günstige Pauschaltarif abgeschlossen wird\n",
    "- Es gibt keine besonderen Zeiträume, in denen die  `Response` besonders gut ist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.8.11 Interpretation der Variable Response <a class=\"anchor\" id=\"section_2_8_11\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Variable `Response` beschreibt das Interesse der Kunden an einer KFZ-Versicherung. Es ist die Zielvariable, die mithilfe eines Modells vorhergesagt werdern soll."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = sns.histplot(\n",
    "    data=train,\n",
    "    x=\"Age\",\n",
    "    binwidth=5,\n",
    "    hue=\"Response\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beobachtung:\n",
    "- Kunden im mittleren Alter (zwischen 30 und 60) haben ein vergleichsweise höheres Interesse an einer Versicherung\n",
    "- Ältere und jüngere Kunden haben ein überproportional geringes Interesse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(30, 10))\n",
    "colors = sns.color_palette('pastel')[0:2]\n",
    "\n",
    "d_1 = train.loc[train[\"Age\"] < 30]\n",
    "d_2 = train.loc[(train[\"Age\"] >= 30) & (train[\"Age\"] < 60)]\n",
    "d_3 = train.loc[(train[\"Age\"] >= 60) & (train[\"Age\"] < 100)] # remove false data\n",
    "\n",
    "l = [\"Response: True\", \"Response: False\"]\n",
    "\n",
    "p_1 = [len(d_1.loc[d_1[\"Response\"] == True]),\n",
    "       len(d_1.loc[d_1[\"Response\"] == False])]\n",
    "ax1.pie(p_1, labels=l, colors=colors, autopct='%.0f%%')\n",
    "ax1.set_title(\"Age < 30\")\n",
    "\n",
    "p_2 = [len(d_2.loc[d_2[\"Response\"] == True]),\n",
    "       len(d_2.loc[d_2[\"Response\"] == False])]\n",
    "ax2.pie(p_2, labels=l, colors=colors, autopct='%.0f%%')\n",
    "ax2.set_title(\"30 <= Age < 60\")\n",
    "\n",
    "p_3 = [len(d_3.loc[d_3[\"Response\"] == True]),\n",
    "       len(d_3.loc[d_3[\"Response\"] == False])]\n",
    "ax3.pie(p_3, labels=l, colors=colors, autopct='%.0f%%')\n",
    "ax3.set_title(\"Age >= 60\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beobachtung:\n",
    "- Besonders in der Altersgruppe 30-60 ist ein besonders großes Interesse an einer KFZ-Versicherung zu erkennen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Data Preparation <a class=\"anchor\" id=\"chapter3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Erkenntnisse, die im Kapitel **Data Understanding** gewonnen wurden, werden nachfolgend angewandt, um invalide Daten zu entfernen und die Datenqualität zu erhöhen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Ausreißer behandeln <a class=\"anchor\" id=\"section_3_1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.1 Ausreißer innerhalb der Variable Age <a class=\"anchor\" id=\"section_3_1_1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ab dem Alter >=100 Jahre werden alle Werte in Missing Values umgewandelt, da dieses Alter nicht realistisch ist.\n",
    "- Diese Grenze wurde als großzügige Einschätzung den zu erwartenden Lebensalters festgelegt.\n",
    "- Von dieser Änderung sind 100 Datensätze betroffen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(train.loc[train[\"Age\"]> 100])\n",
    "train.loc[train[\"Age\"] > 100, \"Age\"] = np.NaN\n",
    "train.loc[train[\"Age\"] < 18, \"Age\"] = np.NaN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.2 Ausreißer innerhalb der Variable Annual_Premium <a class=\"anchor\" id=\"section_3_1_2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"Annual_Premium\"].describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Negative Werte für `Annual_Premium` sind nicht valide. Es würde bedeuten, dass die Versicherungsgesellschaft den Kunden bezahlt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove negative values\n",
    "train.loc[train[\"Annual_Premium\"] < 0, \"Annual_Premium\"] = np.NaN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Analyse der nicht vorhandenen Werte <a class=\"anchor\" id=\"section_3_2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1 Löschen der 51 fehlerhaften Datensätze <a class=\"anchor\" id=\"section_3_2_1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie im Abschnitt Data Unterstanding beschrieben wurden 51 Datensätze mit vielen fehlenden Werten gefunden. Da diese keinen signifikanten Einfluss auf das Modell haben werden, werden sie entfernt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove faulty data sets\n",
    "# bad_train was generated before and contains 51 data sets that we want to remove\n",
    "train = train.loc[~train[\"id\"].isin(bad_train[\"id\"].to_numpy())]  # ~ = not\n",
    "train.isna().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Train/Test-Split <a class=\"anchor\" id=\"section_3_3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "Für den Split unterteilen wir die Daten aus der Train.csv in Test und Train-Daten. Hier wird ein 70/30-Split genutzt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Features\n",
    "X = train.copy(deep=True)\n",
    "X.drop(\"Response\", axis=\"columns\", inplace=True)\n",
    "X.drop(\"id\", axis=\"columns\", inplace=True)\n",
    "#labels\n",
    "y = train['Response'].copy(deep=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "# help IDE understand that we are still dealing with data frames\n",
    "X_train = pd.DataFrame(X_train)\n",
    "X_test = pd.DataFrame(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Imputation der fehlenden Werte <a class=\"anchor\" id=\"section_3_4\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imputationsstrategie:\n",
    "Die Imputation erfolgt anhand der nachfolgenden Prozedur. Es werden verschiedene Imputationsstrategien (`mean`, `median`, `hot_code_locf` und `most_frequent`) ausprobiert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# strategies: mean, median, hot_code_locf, most_frequent, KNN\n",
    "def impute_data(data: pd.DataFrame, col_name, strategy, y_data=None):\n",
    "    if(strategy == \"hot_code_locf\"):\n",
    "        return data[col_name].fillna(method=\"ffill\")\n",
    "\n",
    "    elif(strategy == \"KNN\"):\n",
    "        # prepare data\n",
    "        ref_data = pd.concat([data, pd.get_dummies(\n",
    "            data[\"Gender\"], prefix=\"Gender_is_\")], axis=1)\n",
    "        ref_data = pd.concat([data, pd.get_dummies(\n",
    "            data[\"Vehicle_Age\"], prefix=\"Vehicle_Age_is_\")], axis=1)\n",
    "        ref_data = data.loc[:, ~data.columns.duplicated()]\n",
    "\n",
    "        # KNN imputation\n",
    "        imputer = KNNImputer(missing_values=np.nan, n_neighbors=2)\n",
    "        col_data = imputer.fit_transform(\n",
    "            ref_data.select_dtypes([\"number\", \"boolean\"]), y_data)\n",
    "\n",
    "        # restore column names\n",
    "        col_data = pd.DataFrame(col_data, columns=ref_data.columns)\n",
    "\n",
    "        return col_data[col_name]\n",
    "\n",
    "    else:\n",
    "        imputer = SimpleImputer(strategy=strategy, missing_values=np.NaN)\n",
    "        fit = imputer.fit(data[[col_name]])\n",
    "        col_data = fit.transform(data[[col_name]])\n",
    "        return col_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.1 Ersetzung der fehlenden Werte numerischer Variablen <a class=\"anchor\" id=\"section_3_4_1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4.1.1 Imputation der Variable Age <a class=\"anchor\" id=\"section_3_4_1_1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train[\"Age\"] = impute_data(X_train, \"Age\", \"KNN\", y_data=y_train)\n",
    "# X_test[\"Age\"] = impute_data(X_test, \"Age\", \"KNN\", y_data=y_test)\n",
    "\n",
    "X_train[\"Age\"] = impute_data(X_train, \"Age\", \"mean\")\n",
    "X_test[\"Age\"] = impute_data(X_test, \"Age\", \"mean\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4.1.2 Imputation der Variable Annual_Premium <a class=\"anchor\" id=\"section_3_4_1_2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[\"Annual_Premium\"] = impute_data(X_train, \"Annual_Premium\", \"median\")\n",
    "X_test[\"Annual_Premium\"] = impute_data(X_test, \"Annual_Premium\", \"median\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.2 Ersetzung der fehlenden Werte kategorialer Variablen <a class=\"anchor\" id=\"section_3_4_2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4.2.1 Imputation der Variable Gender <a class=\"anchor\" id=\"section_3_4_2_1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[\"Gender\"] = impute_data(X_train, \"Gender\", \"most_frequent\")\n",
    "X_test[\"Gender\"] = impute_data(X_test, \"Gender\", \"most_frequent\")\n",
    "\n",
    "# cast to category again\n",
    "X_train[\"Gender\"] = X_train[\"Gender\"].astype(pd.CategoricalDtype())\n",
    "X_test[\"Gender\"] = X_test[\"Gender\"].astype(pd.CategoricalDtype())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.3 Überprüfung der Imputationen<a class=\"anchor\" id=\"section_3_4_3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Missing Values im bei Age: Test-> {X_test[\"Age\"].isna().sum()}, Training-> {X_train[\"Age\"].isna().sum()}')\n",
    "print(f'Missing Values im bei Annual_Premium: Test-> {X_test[\"Annual_Premium\"].isna().sum()}, Training-> {X_train[\"Annual_Premium\"].isna().sum()}')\n",
    "print(f'Missing Values im bei Gender: Test-> {X_test[\"Gender\"].isna().sum()}, Training-> {X_train[\"Gender\"].isna().sum()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5. Sampling <a class=\"anchor\" id=\"section_3_5\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Betrachtung der Zielvariable `Response`.\n",
    "- Insgesamter Datensatz der Zielvariable beträgt: 380948 Datensätze\n",
    "- Davon True: 46695 Datensätze, das macht 12% des Datensatzes aus. Dies ist die minority Class\n",
    "- Davon False: 334253 Datensätze, das macht 88% des Datessatzes aus. Dies ist die majority Class\n",
    "\n",
    "Mit den Methoden Oversampling und Undersampling wird versucht, ein Gleichgewicht zwischen der minority und majority Class herzustellen.\n",
    "Zunächst muss die Zielvariable wieder zum Test- und Trainingsdatensatz hinzugefügt werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-add Response\n",
    "X_train.insert(len(X_train.columns), value=y_train, column=\"Response\")\n",
    "X_test.insert(len(X_test.columns), value=y_test, column=\"Response\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions for visualization\n",
    "# plot output\n",
    "def plot_prop_of_split(train, test, col_name):\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(20, 10))\n",
    "\n",
    "    cp_1 = sns.countplot(data=train, x=col_name, ax=ax[0])\n",
    "    cp_1.set_title(\"Trainingsdaten\")\n",
    "    cp_2 = sns.countplot(data=test, x=col_name, ax=ax[1])\n",
    "    cp_2.set_title(\"Testdaten\")\n",
    "\n",
    "    fig.suptitle(\n",
    "        f\"Verteilung der Variable {col_name} in Test- und Trainingsdaten\")\n",
    "    fig.show()\n",
    "\n",
    "# console output\n",
    "\n",
    "\n",
    "def print_class_len_and_ratio(data: pd.DataFrame, col_name):\n",
    "\n",
    "    # minority_class\n",
    "    minority_class_len = len(data[data[col_name] == True])\n",
    "    print(\n",
    "        f\"Die Variable {col_name} enthält {minority_class_len} Datensätze die den Wert True enthalten.\")\n",
    "\n",
    "    # majority_class\n",
    "    majority_class_len = len(data[data[col_name] == False])\n",
    "    print(\n",
    "        f\"Die Variable {col_name} enthält {majority_class_len} Datensätze die den Wert False enthalten.\")\n",
    "\n",
    "    # ratio\n",
    "    print(train[\"Response\"].value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_prop_of_split(X_train, X_test, \"Response\")\n",
    "# print_class_len_and_ratio(X_train, \"Response\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5.1. Undersampling <a class=\"anchor\" id=\"section_3_5_1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def undersample(data: pd.DataFrame, col_name):\n",
    "    # Variable  values count as integer\n",
    "    response_false_count, response_true_count = data[col_name].value_counts()\n",
    "\n",
    "    # Seperate in bool values (True and False values)\n",
    "    seperate_response_false = data[data[col_name] == False]\n",
    "    seperate_response_true = data[data[col_name] == True]\n",
    "\n",
    "    # Undersampling to balance imbalanced datasets --> deleting samples from the majority class\n",
    "    response_false_undersampling = seperate_response_false.sample(\n",
    "        response_true_count)\n",
    "    undersampling = pd.concat(\n",
    "        [response_false_undersampling, seperate_response_true], axis=0)\n",
    "\n",
    "    return undersampling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Datensätze aus der majority_class werden zufällig entfernt.\n",
    "    - Daraus entsteht eine identische Anzahl an Datensätzen für die Zielvariable `Response` mit den Ausprägungen True und False.\n",
    "    - Der Datensatz wird balanciert, indem die gleiche Anzahl an Datensätzen von True zufällig für False gezogen wird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_undersampling = undersample(X_train, \"Response\")\n",
    "\n",
    "plot_prop_of_split(train_undersampling, X_test, \"Response\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5.2. Oversampling <a class=\"anchor\" id=\"section_3_5_2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def oversampling_dataset(imbalanced_dataset):\n",
    "    #Variable \"Response\" values count as integer\n",
    "    response_false_count, response_true_count = imbalanced_dataset[\"Response\"].value_counts()\n",
    "    \n",
    "    #Seperate in bool values (True and False values)\n",
    "    seperate_response_false = imbalanced_dataset[imbalanced_dataset[\"Response\"] == False]\n",
    "    seperate_response_true = imbalanced_dataset[imbalanced_dataset[\"Response\"] == True]\n",
    "    \n",
    "    #Undersampling to balance imbalanced datasets --> deleting samples from the majority class\n",
    "    response_true_oversampling = seperate_response_true.sample(response_false_count, replace=True)\n",
    "    oversampling = pd.concat([response_true_oversampling, seperate_response_false], axis = 0)    \n",
    "\n",
    "    return oversampling      \n",
    "\n",
    "train_oversampling = oversampling_dataset(X_train)\n",
    "\n",
    "# new rows were added but they dont have an index yet\n",
    "train_oversampling =train_oversampling.reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_prop_of_split(train_oversampling, X_test, \"Response\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Datensätze aus der minority_class werden durch Generierung künstlicher Beispiele aufgestockt.\n",
    "    - Daraus entsteht eine identische Anzahl an Datensätzen für die Zielvariable `Response` mit den Ausprägungen True und False.\n",
    "    - Der Datensatz wird balanciert, indem die gleiche Anzahl an Datensätzen von False künstlich für True erzeugt wird."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5.3. Cleanup <a class=\"anchor\" id=\"section_3_5_3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die gesplitteten Test- und Trainingsdaten mussten für das Over- und Undersampling wieder mit der Zielvariable verknüpft werden. Im Fall von Oversampling wurden neue Datensätze erzeugt und im Fall von Undersampling wurden Datensätze entfernt, um ein Gleichgewicht der Klassen zu schaffen. Beides führt dazu, dass die zuvor gesplitteten Datensätze `X_train` und `X_test` nicht mehr zu den Datensätzen der Zielvariable `y_train` und `y_test` passen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# undersamplng\n",
    "y_under_train = train_undersampling[\"Response\"]\n",
    "\n",
    "# oversampling\n",
    "y_over_train = train_oversampling[\"Response\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anschließend wird die Zielvariable wieder von den Test- und Trainingsdaten entfernt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# undersamplng\n",
    "train_undersampling = train_undersampling.drop(\"Response\", axis=\"columns\")\n",
    "\n",
    "# oversampling\n",
    "train_oversampling = train_oversampling.drop(\"Response\", axis=\"columns\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5.4. Under- vs. Oversampling <a class=\"anchor\" id=\"section_3_5_4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #todo Welches Sampling nehmen wir?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_oversampling = False\n",
    "if use_oversampling == True:    \n",
    "    # set to undersampling\n",
    "    print(\"Using Oversampling\")\n",
    "    X_train = train_oversampling\n",
    "    y_train = y_over_train\n",
    "else:\n",
    "    # set to undersampling\n",
    "    print(\"Using Undersampling\")\n",
    "    X_train = train_undersampling\n",
    "    y_train = y_under_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6. Feature Engineering <a class=\"anchor\" id=\"section_3_6\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6.1. Altersklassen als Feature <a class=\"anchor\" id=\"section_3_6_1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Eingrenzung der Variable `Age` in 8 Quantile (q=8) um die Intervalle festzustellen.\n",
    "- Das Ergebnis der Funktion \".qcut\" ist eine Variable des Datentypes \"Category\" da jedes Intervall (bin) einer Kategorie entspricht.\n",
    "- Die Kategorien sind in einer mathematischen Notation beschrieben.\n",
    "    - (exklusive, inklusive]\n",
    "- Der Kategorien der Variable `Age_bin` sind:\n",
    "    - (19.999,23] < (23,25] < (25,28] < (28,37] < (37,43] < (43,49] < (49,59] < (59,85]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['Age_bins'] = pd.qcut(train[\"Age\"], q=8)\n",
    "print(f\"{X_train['Age_bins'].value_counts().sort_index()}\")\n",
    "\n",
    "X_test['Age_bins'] = pd.qcut(train[\"Age\"], q=8)\n",
    "print(f\"{X_test['Age_bins'].value_counts().sort_index()}\")\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "octiles_list = [0, 0.125, 0.25, 0.375, 0.5, 0.625, 0.75, 0.875, 1]\n",
    "\n",
    "octiles = X_train[\"Age\"].quantile(octiles_list)\n",
    "\n",
    "plt.figure(figsize= (22, 10))\n",
    "fig, ax = plt.subplots()\n",
    "X_train['Age'].hist(bins=65, color='#A9C5D3', \n",
    "                             edgecolor='black', grid=False)\n",
    "\n",
    "for quantile in octiles:\n",
    "    axvlineplot = plt.axvline(quantile, color='r')\n",
    "ax.legend([axvlineplot], ['Oktil'], fontsize=16)\n",
    "\n",
    "ax.set_title('Age Histogramm mit Oktile', \n",
    "             fontsize=24, weight=\"bold\")\n",
    "ax.set_xlabel('Age', fontsize=14, weight=\"bold\")\n",
    "ax.set_ylabel('Count', fontsize=14, weight=\"bold\")\n",
    "\n",
    "# start graph just before 20 (no smaller values)\n",
    "ax.set_xlim(19, 90)\n",
    "\n",
    "# show ticks at octiles and steps of 10\n",
    "ax.set_xticks([*octiles.to_numpy(), *range(20,90,10)]); # ; prevents output in console"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Zur besseren Leserlichkeit wurden die Kategorien mit dem Parameter \"labels\" händisch eingeteilt, dabei ist darauf zu achten welche Werte exklusiv und inklusiv sind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_binning(data):\n",
    "        data['Age_bins'] = pd.qcut(\n",
    "            data.Age, q=8, labels=[ (\"20-23\"),(\"24-25\"),(\"26-28\"),(\"29-37\"),(\"38-43\"),(\"44-49\"),(\"50-59\"),(\"60-85\")]\n",
    "            )\n",
    "        return data['Age_bins'].value_counts().sort_index()\n",
    "\n",
    "numerical_binning(X_test)\n",
    "numerical_binning(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[\"Age\"].quantile(octiles_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={\"figure.figsize\": (22, 10)})\n",
    "histplot =sns.histplot(X_train, x=\"Age\", hue=\"Age_bins\", bins=65)\n",
    "\n",
    "histplot.set_title('Histogram der Variable Age in Zusammenhang mit Age_bins', \n",
    "             fontsize=24, weight=\"bold\")\n",
    "histplot.set_xlabel('Age', fontsize=14, weight=\"bold\")\n",
    "histplot.set_ylabel('Count', fontsize=14, weight=\"bold\")\n",
    "histplot.set_xlim(19, 85)\n",
    "histplot.set_xticks(range(20,90,1));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6.2 Features durch Aggregationen, Differenzen und Verhältnisse <a class=\"anchor\" id=\"section_3_6_2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_encoding(data, col_name):\n",
    "    selected_categorical_columns = data.select_dtypes(include = [\"category\"])\n",
    "    for categorical_columns in selected_categorical_columns:\n",
    "        \n",
    "        #mean encoding using Annual_Premium as the numeric variable// \n",
    "        #group by categorical variables and obtain the mean over the numeric variable\n",
    "        mean = data.groupby(categorical_columns)[col_name].agg(['mean'])\n",
    "        mean.columns = [f'mean_{col_name}_by_' + categorical_columns]\n",
    "\n",
    "        #joining the column mean_Annual_Premium_by_ to the main dataset (data)\n",
    "        data = pd.merge(data, mean, left_on = categorical_columns, right_index=True, how = 'left')\n",
    "\n",
    "        #difference between the numerical variable Annual_Premium and the mean grouped by the categorical variables over the numeric one.\n",
    "        data[f\"diff_{col_name}_mean_by_\" + categorical_columns] = data[col_name] - data[f\"mean_{col_name}_by_\" + categorical_columns]\n",
    "\n",
    "        #percentage of the difference\n",
    "        data[f\"prop_{col_name}_mean_by_\" + categorical_columns] = data[f\"diff_{col_name}_mean_by_\" + categorical_columns].abs() / data[f'mean_{col_name}_by_' + categorical_columns]\n",
    "    return data\n",
    "\n",
    "# Testdata\n",
    "for col in X_test.select_dtypes(include=[\"number\"], exclude=[\"bool\", \"boolean\"]):\n",
    "    print(f\"Creating features for {col}\")\n",
    "    X_test = feature_encoding(X_test, col)\n",
    "\n",
    "# Traindata\n",
    "for col in X_train.select_dtypes(include=[\"number\"], exclude=[\"bool\", \"boolean\"]):\n",
    "    print(f\"Creating features for {col}\")\n",
    "    X_train = feature_encoding(X_train, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.loc[X_train[\"mean_Age_by_Age_bins\"].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 100)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6.3 One-Hot-Encoding für kategoriale Variablen <a class=\"anchor\" id=\"section_3_6_3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Konvertieren von kategorialen Variablen in Dummy/Indikator-Variablen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "X_test = pd.concat([X_test, pd.get_dummies(X_test[\"Gender\"], prefix=\"Gender_is_\")], axis=1)\n",
    "X_test = pd.concat([X_test, pd.get_dummies(X_test[\"Vehicle_Age\"], prefix=\"Vehicle_Age_is_\")], axis=1)\n",
    "X_test = pd.concat([X_test, pd.get_dummies(X_test[\"Age_bins\"], prefix=\"Age_bins_is\")], axis=1)\n",
    "X_test = X_test.loc[:,~X_test.columns.duplicated()]\n",
    "\n",
    "# train\n",
    "X_train = pd.concat([X_train, pd.get_dummies(X_train[\"Gender\"], prefix=\"Gender_is_\")], axis=1)\n",
    "X_train = pd.concat([X_train, pd.get_dummies(X_train[\"Vehicle_Age\"], prefix=\"Vehicle_Age_is_\")], axis=1)\n",
    "X_train = pd.concat([X_train, pd.get_dummies(X_train[\"Age_bins\"], prefix=\"Age_bins_is\")], axis=1)\n",
    "X_train = X_train.loc[:,~X_train.columns.duplicated()]\n",
    "print(f\"Wir starten mit {len(X_train.columns)} Features in die Featureselektion\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.7 Feature Selection <a class=\"anchor\" id=\"section_3_7\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Bei der Feature Selection wählen wir die Features aus, die für den machine-learning-process verwendet werden. \n",
    "- Hierbei ist darauf zu achten, dass nur relevante Features zur Modellbildung verwendet werden sollten, da sonst eine Überanpassung des Modells stattfinden kann.\n",
    "- Durch die neu hinzugekommenen Features aus dem Feature Engineering umfasst der Datensatz nun 69 Spalten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 100)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Um sich eine Übersicht über die Variablen zu verschaffen wird ein Korrelationsplot genutzt, damit die Abhängigkeiten der einzelnen Variablen betrachtet werden können.\n",
    "- Variablen die eine zu hohe Korrelaton vorweisen, werden aus dem Datensatz entfernt da sich diese negativ auf die Modellierung auswirken können.\n",
    "- Der folgende Korrelationsplot berücksichtigt alle Variablen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# korrelation aller Variablen\n",
    "correlation_matrix(X_train, 24, 12, False, \"seismic\", \"pearson\")\n",
    "correlation_matrix(X_train, 24, 12, False, \"seismic\", \"spearman\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pearson = X_train.corr(method=\"pearson\")\n",
    "spearman = X_train.corr(method=\"spearman\")\n",
    "\n",
    "delta = spearman.abs() - pearson.abs()\n",
    "hm = sns.heatmap(delta, cmap=\"seismic\", center=0)\n",
    "hm.set_title(\"Abweichungen zwischen Spearman und Pearson\",\n",
    "             fontsize=24, weight=\"bold\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bei der Feature Selection wird die Spearman-Korrelation verwendet. Da diese ohne Betrachtung der Abstände der einzelnen Werte auskommt, ist sie inklusiver als die Pearson-Korrelation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection auf Basis zu hoher Korrelation\n",
    "def get_columns_with_high_correlations(data: pd.DataFrame, threshold, corr_method):\n",
    "    corr = data.corr(method=corr_method)\n",
    "\n",
    "    corr = corr.abs().unstack()\n",
    "    corr = corr.reset_index()\n",
    "    # columns have 1.0 correlation with themselves -> filter those\n",
    "    corr = corr.loc[corr[\"level_0\"] != corr[\"level_1\"]]\n",
    "    corr = corr.loc[corr[0].abs() > threshold]\n",
    "\n",
    "    return corr[\"level_0\"].drop_duplicates().to_numpy()\n",
    "\n",
    "\n",
    "def drop_columns_with_high_correlation(data: pd.DataFrame, threshold, corr_method):\n",
    "    cols = get_columns_with_high_correlations(data, threshold, corr_method)\n",
    "    data = data.drop(cols, axis=1)\n",
    "    print(f\"Removed {len(cols)} features using method: {corr_method} and threshold: {threshold}\")\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um die Feature Selection durchführen zu können, muss der Datensatz auf numerische Daten reduziert werden. Die Vorbereitungen hierzu wurden bereits im Abschnitt Data Preparation getroffen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_test = X_test.select_dtypes([\"number\", \"boolean\"])\n",
    "feature_train = X_train.select_dtypes([\"number\", \"boolean\"])\n",
    "len(feature_train.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.7.1 Feature Selection anhand von Korrelation <a class=\"anchor\" id=\"section_3_7_1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features mit zu hohen Korrelationen untereinander können als redundant betrachtet werden. Nachfolgend werden alle Features mit einer Korrelation über einem Threshold entfernt. Der Threshold wird bestimmt, indem er nach und nach (von 1 aus kommend) verringert wird.\n",
    "- Daher werden alle Variablen mit einem `threshold` von <= - 0,9 und >= 0,9 entfernt.\n",
    "- Bei der Pearson-Methode werden 36 features entfernt.\n",
    "- Bei der Spearman-Methode werden 35 features entfernt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection by highest korrelation pruning\n",
    "\n",
    "# RUN THIS ONLY FOR FINDING THRESHOLD\n",
    "# try to find propper threshold\n",
    "# for thresh in [0.9, 0.8, 0.7]:\n",
    "#     drop_columns_with_high_correlation(\n",
    "#         feature_train, thresh, \"pearson\")\n",
    "\n",
    "#     drop_columns_with_high_correlation(\n",
    "#         feature_train, thresh, \"spearman\")\n",
    "\n",
    "# perform feature selection on data with selected threshold\n",
    "corr_thresh = 0.9\n",
    "pearson = drop_columns_with_high_correlation(\n",
    "    feature_train, corr_thresh, \"pearson\")\n",
    "\n",
    "spearman = drop_columns_with_high_correlation(\n",
    "    feature_train, corr_thresh, \"spearman\")\n",
    "\n",
    "# select feature set to continue with\n",
    "pruned_feature_train = spearman\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Es verbleiben {len(pruned_feature_train.columns)} Features\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Nach der Bereinigung des Datensatzes sind alle Variablen mit einem `threshold` von <= - 0,9 und >= 0,9 entfernt worden, wie am nachfolgenden Korrelationsplot ersichtlich ist.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix(pruned_feature_train, 24, 12, False, \"seismic\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.7.2 Feature Importance durch Logistische Regression <a class=\"anchor\" id=\"section_3_7_2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bei der Ermittlung der Feature Importance werden die Features mithilfe logistischer Regression analysiert. Dabei werden die Koeffizienten der einzelnen Variablen in Abhängigkeit zu der Zielvariable `Response` betrachtet. Daraus lässt sich der R-Wert ermitteln. Auch hier wird ein Grenzwert benötigt, der zwischen unwichtigen und wichtigen Features unterscheidet. Dieser Threshold kann nach Betrachtung der Feature Importance am besten eingeschätzt werden.\n",
    "\n",
    "|    **R-Wert**          | **Erklärung**  | \n",
    "|          :-:           |         :-        |\n",
    "|       >0              |- Wenn der R-Wert >0 ist dann hat die Variable einen tendenziell positiven Einfluss darauf das eine KFZ-Versicherung abgeschlossen wird.| \n",
    "|         <0              |- Wenn der R-Wert <0 ist dann hat die Variable einen tendenziell negativen Einfluss darauf das eine KFZ-Versicherung abgeschlossen wird.| \n",
    "|  =0                 |- Wenn der R-Wert =0 ist dann hat die Variable weder einen tendenziell positiven, noch negativen Einfluss darauf, dass eine KFZ-Versicherung abgeschlossen wird.| \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "# linear regression feature importance\n",
    "\n",
    "feat_imp_thresh = 0.01\n",
    "\n",
    "# define the model\n",
    "model = LogisticRegression(max_iter=500)\n",
    "# fit the model\n",
    "model.fit(pruned_feature_train, y_train)\n",
    "\n",
    "# get importance\n",
    "importance = model.coef_[0]\n",
    "\n",
    "i = pd.DataFrame(importance)\n",
    "i[\"Feature\"] = pruned_feature_train.columns\n",
    "i = i.rename(columns={0: \"Score\"})\n",
    "\n",
    "# # summarize feature importance\n",
    "# for i, v in enumerate(importance):\n",
    "#     print('Feature: %0d %s, Score: %.5f' %\n",
    "#           (i, pruned_feature_train.columns[i], v))\n",
    "# plot feature importance\n",
    "i = i.sort_values(\"Score\", ascending=False)\n",
    "b = sns.barplot(x=\"Feature\", y=\"Score\", data=i)\n",
    "b.tick_params(axis='x', rotation=90)\n",
    "b.axhline(feat_imp_thresh, color=\"r\")\n",
    "b.axhline(-feat_imp_thresh, color=\"r\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nach der Untersuchung der Feature Importance bleiben nur wenige Features für die Modellierung übrig."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_features = i.loc[i[\"Score\"].abs() > feat_imp_thresh]\n",
    "print(relevant_features)\n",
    "\n",
    "# train\n",
    "modelling_data_train = pruned_feature_train[relevant_features[\"Feature\"]]\n",
    "\n",
    "# test\n",
    "modelling_data_test = feature_test[relevant_features[\"Feature\"]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Modeling <a class=\"anchor\" id=\"chapter4\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [None, None, None]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Modell: Random Forest mit Hyperparametertuning <a class=\"anchor\" id=\"section_4_1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# build test grid\n",
    "# USE THIS FOR QUICK FINISH RUN\n",
    "# THIS SETUP EQUALS BEST PARAMS FROM GRID BELOW\n",
    "param_grid = {\n",
    "    \"n_estimators\": [50],\n",
    "    \"max_features\": [\"auto\"],\n",
    "    \"max_depth\": [8],\n",
    "    \"min_samples_leaf\": [2],\n",
    "    \"min_samples_split\": [8],\n",
    "    \"bootstrap\": [True]\n",
    "}\n",
    "\n",
    "# Hyperparametertuning\n",
    "# param_grid = {\n",
    "#     \"n_estimators\": range(20, 60, 10),\n",
    "#     \"max_features\": [\"auto\"],\n",
    "#     \"max_depth\": range(4, 20, 2),\n",
    "#     \"min_samples_leaf\": range(2, 5, 1),\n",
    "#     \"min_samples_split\": range(1, 10, 1),\n",
    "#     \"bootstrap\": [True]\n",
    "# }\n",
    "\n",
    "# build model\n",
    "clf = RandomForestClassifier()\n",
    "# rf_Model.get_params().keys()\n",
    "\n",
    "# build Grid Search CV\n",
    "grid_tuner = GridSearchCV(\n",
    "    estimator=clf, param_grid=param_grid, cv=5, verbose=2, n_jobs=4, pre_dispatch=8)\n",
    "\n",
    "grid_tuner.fit(modelling_data_train, y_train)\n",
    "\n",
    "# predict\n",
    "y_pred = grid_tuner.predict(modelling_data_test)\n",
    "predictions[0] = {\"Prediction\": y_pred, \"Name\": f\"Random Forest (HPT)\"}\n",
    "\n",
    "print(grid_tuner.best_params_)\n",
    "print(\"\\n\")\n",
    "print(f\"Train Accuracy: {grid_tuner.score(modelling_data_train, y_train)}\")\n",
    "print(f\"Test Accuracy:  {grid_tuner.score(modelling_data_test, y_test)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Modell: Neuronales Netz <a class=\"anchor\" id=\"section_4_2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Solver: Stochastic gradient descent (SGD); iteratives Verfahren der Optimierung; besonders schnell bei großen Datensätzen\n",
    "\n",
    "* Activation: tanh; die hyperbolische tan Funktion => f(x) = tanh(x)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# USE THIS FOR QUICK FINISH RUN\n",
    "# THIS SETUP EQUALS BEST PARAMS FROM GRID BELOW\n",
    "# param_grid = {\n",
    "#       \"hidden_layer_sizes\": [(100, 100,), (100, 100, 100) ],\n",
    "#     \"activation\": [\"identity\", \"tanh\"],\n",
    "#     \"solver\": [\"lbfgs\", \"sgd\"],\n",
    "#     \"max_iter\": [100, 200, 500],\n",
    "#     \"early_stopping\": [False],\n",
    "# }\n",
    "\n",
    "# Hyperparametertuning\n",
    "param_grid = {\n",
    "    \"hidden_layer_sizes\": [(100, 100,), (100, 100, 100) ],\n",
    "    \"activation\": [\"identity\", \"tanh\"],\n",
    "    \"solver\": [\"lbfgs\", \"sgd\"],\n",
    "    \"max_iter\": [100, 200, 500],\n",
    "    \"early_stopping\": [False],\n",
    "}\n",
    "\n",
    "clf = MLPClassifier()\n",
    "\n",
    "grid_tuner = GridSearchCV(\n",
    "    estimator=clf, param_grid=param_grid, cv=5, verbose=2, n_jobs=4, pre_dispatch=8)\n",
    "\n",
    "grid_tuner.fit(modelling_data_train, y_train)\n",
    "\n",
    "# predict\n",
    "y_pred = grid_tuner.predict(modelling_data_test)\n",
    "\n",
    "# add to evaluation array\n",
    "predictions[1] = {\"Prediction\": y_pred, \"Name\": \"Neuronales Netz\"}\n",
    "\n",
    "# outcome\n",
    "print(f\"Accuracy Train: {grid_tuner.score(modelling_data_train, y_train)}\")\n",
    "print(f\"Accuracy Test:  {grid_tuner.score(modelling_data_test, y_test)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Modell: Gradient Boosting <a class=\"anchor\" id=\"section_4_3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# USE THIS FOR QUICK FINISH RUN\n",
    "# THIS SETUP EQUALS BEST PARAMS FROM GRID BELOW\n",
    "# param_grid = {\n",
    "    # \"n_estimators\": [10, 50, 100],\n",
    "    # \"loss\": [\"deviance\"],\n",
    "    # \"learning_rate\": np.linspace(0, 1, 6)[1:],  # 0,2 steps\n",
    "    # \"criterion\": [\"friedman_mse\", \"squared_error\"],\n",
    "    # \"min_samples_leaf\": [1],\n",
    "    # \"min_samples_split\": [2],\n",
    "    # \"max_depth\": [3, 5, 7],\n",
    "    # \"max_features\": [\"auto\"]\n",
    "# }\n",
    "\n",
    "# Hyperparametertuning\n",
    "param_grid = {\n",
    "    \"n_estimators\": [10, 50, 100],\n",
    "    \"loss\": [\"deviance\"],\n",
    "    \"learning_rate\": np.linspace(0, 1, 6)[1:],  # 0,2 steps\n",
    "    \"criterion\": [\"friedman_mse\", \"squared_error\"],\n",
    "    \"min_samples_leaf\": [1],\n",
    "    \"min_samples_split\": [2],\n",
    "    \"max_depth\": [3, 5, 7],\n",
    "    \"max_features\": [\"auto\"]\n",
    "}\n",
    "\n",
    "clf = GradientBoostingClassifier()\n",
    "\n",
    "grid_tuner = GridSearchCV(\n",
    "    estimator=clf, param_grid=param_grid, cv=3, verbose=2, n_jobs=4, pre_dispatch=8)\n",
    "\n",
    "grid_tuner.fit(modelling_data_train, y_train)\n",
    "\n",
    "# predict\n",
    "y_pred = grid_tuner.predict(modelling_data_test)\n",
    "predictions[2] = {\"Prediction\": y_pred, \"Name\": \"Gradient Boosting (HPT)\"}\n",
    "\n",
    "print(f\"Accuracy Train: {grid_tuner.score(modelling_data_train, y_train)}\")\n",
    "print(f\"Accuracy Test:  {grid_tuner.score(modelling_data_test, y_test)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Evaluation <a class=\"anchor\" id=\"chapter5\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_confusion_matrix(y_test, y_prediction):\n",
    "    matrix = metrics.confusion_matrix(y_test, y_prediction)\n",
    "\n",
    "    matrix = np.append(matrix, [np.sum(matrix, axis=0)], axis=0)\n",
    "    col = np.array([np.sum(matrix, axis=1)])\n",
    "    matrix = np.concatenate((matrix, col.T), axis=1)\n",
    "\n",
    "    return matrix\n",
    "\n",
    "\n",
    "def get_scores(y_test, y_prediction):\n",
    "    matrix = metrics.confusion_matrix(y_test, y_prediction)\n",
    "\n",
    "    TN = matrix[0][0]\n",
    "    FP = matrix[0][1]\n",
    "    FN = matrix[1][0]\n",
    "    TP = matrix[1][1]\n",
    "\n",
    "    # Recall / Sensitivität / True Positive Rate / Trefferquote\n",
    "    TPR = TP / (TP + FN)\n",
    "\n",
    "    # Anteil der fälschlich als negativ klassifizierten Beobachtungen\n",
    "    FNR = 1 - TPR\n",
    "\n",
    "    # Spezifizität\n",
    "    TNR = TN / (TN + FP)\n",
    "\n",
    "    # False Positive Rate\n",
    "    FPR = 1 - TNR\n",
    "\n",
    "    return matrix, TPR, FNR, TNR, FPR\n",
    "\n",
    "\n",
    "def plot_scores(data: pd.DataFrame):\n",
    "    y_ticks = np.linspace(0, 1, 11)\n",
    "    fig, ax = plt.subplots(1, 6, sharey=True)\n",
    "\n",
    "    d_real = pd.DataFrame(y_test)\n",
    "    vc = pd.DataFrame(d_real[\"Response\"].value_counts() / len(d_real))\n",
    "\n",
    "    p_real = sns.barplot(data=vc, x=\"Response\", y=\"Response\", ax=ax[0], palette=sns.color_palette('binary_r', 2))\n",
    "    p_real.set_title(\"Realität\")\n",
    "    p_real.set_xticklabels([\"True\", \"False\"])\n",
    "    p_real.set_xlabel(\"\")\n",
    "    p_real.set_ylabel(\"\")\n",
    "\n",
    "    p_TPR = sns.barplot(data=data, x=\"Name\", y=\"TPR\", ax=ax[1])\n",
    "    p_TPR.set_yticks(y_ticks)\n",
    "    p_TPR.set_title(\"True Positive Rate\")\n",
    "    p_TPR.set_xlabel(\"\")\n",
    "    p_TPR.set_ylabel(\"\")\n",
    "    p_TPR.tick_params(axis='x', rotation=90)\n",
    "\n",
    "    p_FNR = sns.barplot(data=data, x=\"Name\", y=\"FNR\", ax=ax[2])\n",
    "    p_FNR.set_title(\"False Negative Rate\")\n",
    "    p_FNR.set_xlabel(\"\")\n",
    "    p_FNR.set_ylabel(\"\")\n",
    "    p_FNR.tick_params(axis='x', rotation=90)\n",
    "\n",
    "    p_TNR = sns.barplot(data=data, x=\"Name\", y=\"TNR\", ax=ax[3])\n",
    "    p_TNR.set_title(\"True Negative Rate\")\n",
    "    p_TNR.set_xlabel(\"\")\n",
    "    p_TNR.set_ylabel(\"\")\n",
    "    p_TNR.tick_params(axis='x', rotation=90)\n",
    "\n",
    "    p_FPR = sns.barplot(data=data, x=\"Name\", y=\"FPR\", ax=ax[4])\n",
    "    p_FPR.set_title(\"False Positive Rate\")\n",
    "    p_FPR.set_xlabel(\"\")\n",
    "    p_FPR.set_ylabel(\"\")\n",
    "    p_FPR.tick_params(axis='x', rotation=90)\n",
    "\n",
    "    p_AUC = sns.barplot(data=data, x=\"Name\", y=\"AUC\", ax=ax[5])\n",
    "    p_AUC.set_title(\"Area Under Curve\")\n",
    "    p_AUC.set_xlabel(\"\")\n",
    "    p_AUC.set_ylabel(\"\")\n",
    "    p_AUC.tick_params(axis='x', rotation=90)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = pd.DataFrame(\n",
    "    columns=[\"Name\", \"TN\", \"FP\", \"FN\", \"TP\", \"TPR\", \"FNR\", \"FPR\", \"AUC\"])\n",
    "for model in predictions:\n",
    "    if model is not None:\n",
    "        matrix, TPR, FNR, TNR, FPR = get_scores(y_test, model[\"Prediction\"])\n",
    "        AUC = metrics.roc_auc_score(y_test, model[\"Prediction\"])\n",
    "        scores = scores.append({\"Name\": model[\"Name\"],\n",
    "                                \"TN\": matrix[0][0], \"FP\": matrix[0][1],\n",
    "                                \"FN\": matrix[1][0], \"TP\": matrix[1][1],\n",
    "                                \"TPR\": TPR,\n",
    "                                \"FNR\": FNR,\n",
    "                                \"TNR\": TNR,\n",
    "                                \"FPR\": FPR,\n",
    "                                \"AUC\": AUC\n",
    "                                }, ignore_index=True)\n",
    "plot_scores(scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Bestes Modell: Random Forest <a class=\"anchor\" id=\"section_5_1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_test, y_prediction, model_name, axis=None):\n",
    "    conf_matrix = get_confusion_matrix(y_test, y_prediction)\n",
    "\n",
    "    plot = sns.heatmap(conf_matrix, annot=True, fmt=\"d\", ax=axis)\n",
    "    plot.set_xticklabels([\"False\", \"True\", \"Total\"])\n",
    "    plot.set_yticklabels([\"False\", \"True\", \"Total\"])\n",
    "    plot.set_xlabel(\"Predicted\")\n",
    "    plot.set_ylabel(\"Actual\")\n",
    "    plot.set_title(f\"Konfusionsmatrix von {model_name}\")\n",
    "    # plot.axis = axis\n",
    "    return plot\n",
    "\n",
    "\n",
    "def plot_auc(y_test, y_prediction, model_name):\n",
    "    fpr, tpr, t = metrics.roc_curve(y_test, y_prediction)\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    d = metrics.RocCurveDisplay(\n",
    "        fpr=fpr, tpr=tpr, roc_auc=roc_auc, estimator_name=model_name)\n",
    "    return d\n",
    "\n",
    "\n",
    "best_model = scores.loc[scores[\"Name\"] == \"Random Forest (HPT)\"].sum()\n",
    "prediction = predictions[0]  # select Random Forest\n",
    "\n",
    "n = best_model.TP + best_model.TN + best_model.FP + best_model.FN\n",
    "\n",
    "ACC = (best_model.TP + best_model.TN) / n\n",
    "ER = 1 - ACC\n",
    "PRECISION = best_model.TP / (best_model.TP + best_model.FP)\n",
    "print(\"Korrektklassifikationsrate: %.2f\" % (ACC))\n",
    "print(\"Fehlerrate:                 %.2f\" % (ER))\n",
    "print(\"Recall (TPR):               %.2f\" % (best_model.TPR))\n",
    "print(\"Precision:                  %.2f\" % (PRECISION))\n",
    "print(\"AUC                         %.2f\" % (best_model.AUC))\n",
    "\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(30, 10))\n",
    "\n",
    "# confusion matrix\n",
    "p_conf = plot_confusion_matrix(\n",
    "    y_test, prediction[\"Prediction\"], f\"{prediction['Name']}\", ax1)\n",
    "\n",
    "# AUC\n",
    "p_auc = plot_auc(y_test, prediction[\"Prediction\"],\n",
    "                 f\"Model: {prediction['Name']}\")\n",
    "p_auc.plot(ax2)\n",
    "ax2.set_title(\"ROC Curve\")\n",
    "\n",
    "p, r, t = metrics.precision_recall_curve(y_test, prediction[\"Prediction\"])\n",
    "prc = metrics.PrecisionRecallDisplay(p, r)\n",
    "prc.plot(ax3)\n",
    "ax3.set_title(\"Precision-Recall Curve\")\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "636088ffbd2e162864942ceb92200db462cb0bed77ed962033db15e6c05a945f"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
